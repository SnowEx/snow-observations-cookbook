{"version":"1","records":[{"hierarchy":{"lvl1":"Snow Observations Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Snow Observations Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook is a compilation of tutorials and training\nmaterials in support of the NASA snow reserach community. Some tutorials\ncome from the 2020 to 2024 SnowEx Hackweek program hosted at the UW eScience\nInstitute. Other materials are drawn from the NASA Goddard “SnowPit” Science\nTask Group or STG. The purpose of the tutorials is to help people with data\naccess and to demonstrate a variety of disciplinary use cases.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Motivation"},"content":"There are numerous data products and methods for accessing and analyzing\nsnow observations. These include field, airborne, and satellite missions.\nThe goal of these tutorials is to streamline data access, reduce duplication\nof effort and build an open science community around snow research\ndatasets, algorithms and software.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Authors"},"content":"Zach Fair\n\n\nAnthony Arendt,\n\n\nAlex Lewandowski,\n\n\nJoachim Meyer","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into two main sections: “Data Access” and\n“Observations”.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 1: Data Access","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-data-access","position":10},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 1: Data Access","lvl2":"Structure"},"content":"Field Campaigns Overview\n\nSnowExSQL Database","type":"content","url":"/#section-1-data-access","position":11},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 2: Observations","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-observations","position":12},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 2: Observations","lvl2":"Structure"},"content":"GPR and Lidar\n\nTime-lapse Cameras\n\nUAVSAR\n\nMicrostructure\n\nAVIRIS-NG\n\nTerrestrial Laser Scanning","type":"content","url":"/#section-2-observations","position":13},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using\n\n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of\nhow this works are not important for now. All you need to know is how to launch\na Pythia Cookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer,\nyou will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/snow-cookbook repository: git clone https://github.com/ProjectPythia/snow-observations-cookbook.git\n\nMove into the snow-observations-cookbook directorycd snow-observations-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate snow-observations-cookbook\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"GPR and Lidar"},"type":"lvl1","url":"/notebooks/gpr-lidar-hackweektutorial","position":0},{"hierarchy":{"lvl1":"GPR and Lidar"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial","position":1},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Author: Randall Bonnell"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#author-randall-bonnell","position":2},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Author: Randall Bonnell"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#author-randall-bonnell","position":3},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Outline:"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#outline","position":4},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Outline:"},"content":"GPR Methods for the Retrieval of Snow Depth and SWE\n\nLidar Methods for Snow Depth Retrieval and SWE Estimation\n\nLeveraging Coincident GPR and Lidar Data Sets to Derive Snow Density\n\nSnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska\n\nDiscussion: Improving Density Estimation\n\nGPR SnowEx Analysis-Ready Datasets\n\nReferences\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#outline","position":5},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-1-gpr-methods-for-the-retrieval-of-snow-depth-and-swe","position":6},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-1-gpr-methods-for-the-retrieval-of-snow-depth-and-swe","position":7},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous GPR tutorial developed by Tate Meehan (CRREL) that may be of interest: https://​snowex​-2021​.hackweek​.io​/tutorials​/gpr​/gpr​.html","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#previous-gpr-tutorial-developed-by-tate-meehan-crrel-that-may-be-of-interest-https-snowex-2021-hackweek-io-tutorials-gpr-gpr-html","position":8},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous GPR tutorial developed by Tate Meehan (CRREL) that may be of interest: https://​snowex​-2021​.hackweek​.io​/tutorials​/gpr​/gpr​.html","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#previous-gpr-tutorial-developed-by-tate-meehan-crrel-that-may-be-of-interest-https-snowex-2021-hackweek-io-tutorials-gpr-gpr-html","position":9},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"SnowEx Review","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#snowex-review","position":10},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"SnowEx Review","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Ground-based, airborne, and satellite radars were operated as part of the NASA SnowEx campaigns.\n\nGround-based radars included ground-penetrating radar (GPR), frequency-modulated continuous-wave radar (FMCW), and tower mounted radars.\n\nWhat airborne and satellite radars were tasked?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#snowex-review","position":11},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Brief Blurb on Radar Physics","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-brief-blurb-on-radar-physics","position":12},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Brief Blurb on Radar Physics","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Radar is fully transmissible in dry snow, but there is frequency-dependent interaction between the radar signal and the snowpack.\n\nAt L-band frequencies (1–2 GHz, ~25 cm wavelength) there limited to no interaction with the snowpack.","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-brief-blurb-on-radar-physics","position":13},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What is GPR?","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#what-is-gpr","position":14},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What is GPR?","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"We use L-band GPR, which was operated during all SnowEx campaigns!\n\nGPR transmits a radar signal into the snowpack, which then reflects off objects/interfaces with contrasting dielectric permittivity. The GPR records the amplitude and two-way travel time (twt) of the reflections.\n\nDielectric permittivity refers to the dielectric properties of the snowpack that define how EM energy transmits through the medium.\n\nUsually, we are interested in the snow-ground interface and we measure the snowpack thickness in twt (nanoseconds).\n\nHowever, in complex vegetation, radargrams are difficult to interpret! Causes increased uncertainty.\n\nSee radargram examples below for the boreal forest GPR surveys (credit Kajsa Holland-Goon).\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#what-is-gpr","position":15},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Snow Depth, SWE, and Density Calculations","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#snow-depth-swe-and-density-calculations","position":16},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Snow Depth, SWE, and Density Calculations","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"To calculate snow depth (d_s) from twt, we need to estimate the relative permittivity (\\epsilon_s) and radar velocity (v_s) of the snowpack:\n\nv_s = \\frac{c}{\\sqrt{\\epsilon_s}}; --> Where c is the velocity of EM energy in a vacuum.\n\n\\epsilon_s = (1+\\frac{0.845\\rho_s}{1000})^2; --> Kovacs et al. (1995), but more than 19 equations exist for dry snow conditions.\n\nd_s = \\frac{twt}{2}*v_s;\n\nSWE = d_s\\rho_s;--> Where SWE is snow water equivalent.\n\nBut...If we know the snow depth, we can constrain the radar velocity and estimate relative permittivity and density!\n\n\\epsilon_s=(\\frac{c*twt}{2d_s})^2\n\n\\rho_s=(\\sqrt{\\epsilon_s}-1)\\frac{1000}{0.845}\n\nHow can we find the snow depth?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#snow-depth-swe-and-density-calculations","position":17},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Shameless Plug...","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-shameless-plug","position":18},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Shameless Plug...","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Most analysis-ready GPR products have twt, snow depth, and snow water equivalent. Some have been updated with derived snow densities. See 6. SnowEx GPR Analysis-Ready Datasets below.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-shameless-plug","position":19},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-2-lidar-methods-for-snow-depth-retrieval-and-swe-estimation","position":20},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-2-lidar-methods-for-snow-depth-retrieval-and-swe-estimation","position":21},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous lidar tutorial developed by Naheem Adebisi (ESRI) that may be of interest: https://​snowex​-2022​.hackweek​.io​/tutorials​/lidar​/index​.html","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#previous-lidar-tutorial-developed-by-naheem-adebisi-esri-that-may-be-of-interest-https-snowex-2022-hackweek-io-tutorials-lidar-index-html","position":22},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous lidar tutorial developed by Naheem Adebisi (ESRI) that may be of interest: https://​snowex​-2022​.hackweek​.io​/tutorials​/lidar​/index​.html","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#previous-lidar-tutorial-developed-by-naheem-adebisi-esri-that-may-be-of-interest-https-snowex-2022-hackweek-io-tutorials-lidar-index-html","position":23},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A (Very) General Review of Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-very-general-review-of-lidar","position":24},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A (Very) General Review of Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"Lidar emits photons and measures the twt of the returned photons\n\nThese twt are converted to elevation surfaces (e.g., DEM, DTM, DSM).\n\nLidar can be collected from a variety of platforms:\n\nTerrestrial\n\nUAV\n\nAirborne\n\nSatellite\n\nTwo acquisitions are required for snow, a snow-on acquisition and a snow-off acquisition. Snow depth can be calculated in two general ways:\n\nRaster-based approaches (see figure below, credit Airborne Snow Observatories Inc.)\n\nPoint cloud approaches","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-very-general-review-of-lidar","position":25},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"How is SWE calculated from lidar snow depths?","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#how-is-swe-calculated-from-lidar-snow-depths","position":26},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"How is SWE calculated from lidar snow depths?","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"At larger scales, SWE is calculated via modeled densities (e.g., M3 Works and ASO).\n\nAt smaller field sites, it may be appropriate to use representative in situ measurements.\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#how-is-swe-calculated-from-lidar-snow-depths","position":27},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"3. Leveraging Coincident GPR and Lidar Data Sets to Derive Snow Density"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-3-leveraging-coincident-gpr-and-lidar-data-sets-to-derive-snow-density","position":28},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"3. Leveraging Coincident GPR and Lidar Data Sets to Derive Snow Density"},"content":"Density, liquid water content, and relative permittivity are understudied relative to snow depth and/or SWE.\n\nCombined coincident snow depths and twt can yield spatially distributed measurements of relative permittivity.\n\nIn wet snow, relative permittivity can be converted to liquid water content (e.g., Webb et al., 2018, 2020, 2022; Bonnell et al., 2021).\n\nIn dry snow, density can be estimated from the relative permittivity (Yildiz et al., 2021; McGrath et al., 2022; Bonnell et al., 2023; Meehan et al., 2024).\n\nThis technique has provided an unprecedented glimpse into the spatial properties of these parameters!\n\nCritically, studies have noted a large random error in derived products that should be considered (see figure below, credit: Meehan et al., 2024).\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-3-leveraging-coincident-gpr-and-lidar-data-sets-to-derive-snow-density","position":29},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-4-snowex23-gpr-lidar-derived-permittivities-densities-in-the-boreal-forest-alaska","position":30},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-4-snowex23-gpr-lidar-derived-permittivities-densities-in-the-boreal-forest-alaska","position":31},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Here, we will use this approach to derive densities at Farmer’s Loop Creamer’s Field during the SnowEx23 Alaska Campaign","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#here-we-will-use-this-approach-to-derive-densities-at-farmers-loop-creamers-field-during-the-snowex23-alaska-campaign","position":32},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Here, we will use this approach to derive densities at Farmer’s Loop Creamer’s Field during the SnowEx23 Alaska Campaign","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"Lidar data was collected on 11 March 2023\n\nGPR data was collected on 7, 11, 13, and 16 March 2023\n\n#1.1 Load relevant packages\nimport os\nimport numpy as np \nfrom datetime import date\nfrom scipy.spatial import cKDTree\n\n#packages for figures\nimport matplotlib.pyplot as plt\nfrom rasterio.plot import show\n\n#geospatial packages\nimport geopandas as gpd #for vector data\nimport xarray as xr\nimport pandas as pd\nfrom shapely.geometry import box, Point\nimport rasterio as rio\n\n#Import SnowEx database\nfrom snowexsql.api import PointMeasurements, LayerMeasurements, RasterMeasurements\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#here-we-will-use-this-approach-to-derive-densities-at-farmers-loop-creamers-field-during-the-snowex23-alaska-campaign","position":33},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 1: Load the GPR data from the SnowEx data base","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-1-load-the-gpr-data-from-the-snowex-data-base","position":34},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 1: Load the GPR data from the SnowEx data base","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"-Huge thank you to Micah Johnson and Micah Sandusky for their support!\n\nNote that if we used the full GPR/Lidar dataset, we would need to allocate way more memory. This example focuses on a single date of collection in very dense forest.\n\nExamine the headers from the GPR csv --> what are the variables that we are interested in?\n\n# 1.2 Load GPR data\n\n#Note, memory space is fairly limited, will need to pull only one date\n\n#Set a number of dates to pull GPR for\n#dt1 = date(2023, 3, 7)\ndt2 = date(2023, 3, 11)\n#dt3 = date(2023, 3, 13)\n#dt4 = date(2023, 3, 16)\n\n#site1 = LayerMeasurements.from_filter(date=dt1, site_name='Fairbanks', site_id='FLCF', limit=1)\nsite2 = LayerMeasurements.from_filter(date=dt2, site_name='Fairbanks', site_id='FLCF', limit=1)\n#site3 = LayerMeasurements.from_filter(date=dt3, site_name='Fairbanks', site_id='FLCF', limit=1)\n#site4 = LayerMeasurements.from_filter(date=dt4, site_name='Fairbanks', site_id='FLCF', limit=1)\n\n#Use pandas ot read in csv data\n#gpr_df_dt1 = PointMeasurements.from_area(pt=site1.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt1, site_name='farmers-creamers',\n#    limit=29432)#The number of expected measurements\ngpr_df_dt2 = PointMeasurements.from_area(pt=site2.geometry[0], crs=26906, buffer=10000,\n    type='two_way_travel',\n    observers='Randall Bonnell',\n    date=dt2, site_name='farmers-creamers',\n    limit=20213)#The number of expected measurements\n#gpr_df_dt3 = PointMeasurements.from_area(pt=site3.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt3, site_name='farmers-creamers',\n#    limit=19024)\n#gpr_df_dt4 = PointMeasurements.from_area(pt=site4.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt4, site_name='farmers-creamers',\n#    limit=15785)\n\n\n#Compile into one dataframe\n#flcf_gpr_df = pd.concat([gpr_df_dt1,gpr_df_dt2,gpr_df_dt3,gpr_df_dt4],axis=0, join='outer', ignore_index=True, keys=None, levels=None,names=None,verify_integrity=False,sort=False,copy=None)\nflcf_gpr_df = gpr_df_dt2\n#Print out the csv headers and initial entries --> What's important here and what do we need?\nprint(flcf_gpr_df.head())\n\n# Let's look at the distribution of gpr two-way travel times and estimated snow depths\n#Estimate snow depths from twt by assuming a velocity of 0.25 m/ns --> Is this an appropriate velocity estimate?\nflcf_gpr_df['Depth_estimated'] = (flcf_gpr_df['value']/2)*0.25\n\nax1 = flcf_gpr_df.plot.hist(column=[\"value\"], edgecolor='black', title='two-way travel time (ns)')\nax2 = flcf_gpr_df.plot.hist(column=[\"Depth_estimated\"], edgecolor='black', title='Snow depth (m)')\n\n#Extract x/y limits from GPR data --> these will be used when loading the lidar snow depths\nbounds = flcf_gpr_df.total_bounds\n\n# Create a bounding box\ngpr_limits = box(*bounds)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-1-load-the-gpr-data-from-the-snowex-data-base","position":35},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s load in the lidar canopy heights and snow depths.","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#lets-load-in-the-lidar-canopy-heights-and-snow-depths","position":36},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s load in the lidar canopy heights and snow depths.","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"We’ll look at the canopy heights to get an idea of what kind of forest the data were collected in.\n\nThen, we’ll look at the lidar snow depths to visualize the snow distribution.","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#lets-load-in-the-lidar-canopy-heights-and-snow-depths","position":37},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions","position":38},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"What type of survey design was implemented for the GPR?\n\nDo the lidar snow depth patterns seem to exhibit any kind of dependence upon the forest cover?\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions","position":39},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Commented until we fix reading of raster data"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#commented-until-we-fix-reading-of-raster-data","position":40},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# # 1.3 Load Lidar vegetation/canopy heights --> This may take a few minutes\n# #Read in the canopy heights raster from Farmer's Loop/Creamer's Field Alaska\n# flcf_ch = RasterMeasurements.from_area(shp = gpr_limits, crs=26906,\n#     buffer=None, type='canopy_height',\n#     site_name='farmers-creamers',\n#     observers='chris larsen')\n# print(flcf_ch)\n\n# #Plot the datasets\n# fig, ax = plt.subplots()\n# show(flcf_ch, ax=ax, cmap='Greens', clim=(0,5), title = 'Canopy Height (m)')\n# #Plot the GPR points on top\n# flcf_gpr_df.plot(ax=ax, color='blue', markersize = 10)\n\n# # 1.4 Load Lidar Snow depths --> This will take a few minutes\n\n# #Read in the canopy heights raster from Farmer's Loop/Creamer's Field Alaska\n# flcf_ds = RasterMeasurements.from_area(shp = gpr_limits, crs=26906,\n#     buffer=None, type='depth',\n#     site_name='farmers-creamers',\n#     observers='chris larsen')\n\n# #Plot the datasets\n# fig, ax = plt.subplots()\n# show(flcf_ds, ax=ax, cmap='Blues', clim=(0,1.5), title='Snow Depth (m)')\n# #Plot the GPR points on top\n# flcf_gpr_df.plot(ax=ax, color='red', markersize = 10)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#commented-until-we-fix-reading-of-raster-data","position":41},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 2: Match the GPR data to the lidar grid and derive relative permittivity and density","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-2-match-the-gpr-data-to-the-lidar-grid-and-derive-relative-permittivity-and-density","position":42},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 2: Match the GPR data to the lidar grid and derive relative permittivity and density","lvl2":"Commented until we fix reading of raster data"},"content":"There are two conceptual paths forward:\n\nRasterize the GPR data or\n\nVectorize the lidar data\n\nFor simplicity, the following code:\n\nvectorizes the lidar data\n\nperforms a nearest neighbor search between the lidar and GPR coordinate vectors\n\nCalculates the median GPR twt from the nearest neighbors\n\nDerives relative permittivity and density from the lidar snow depths and median twt\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-2-match-the-gpr-data-to-the-lidar-grid-and-derive-relative-permittivity-and-density","position":43},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"We need to know the resolutions of the lidar and GPR datasets","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#we-need-to-know-the-resolutions-of-the-lidar-and-gpr-datasets","position":44},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"We need to know the resolutions of the lidar and GPR datasets","lvl2":"Commented until we fix reading of raster data"},"content":"The GPR dataset consists of points that are spaced ~0.10 m apart.\n\nWhat about the lidar? Run the code block below to answer this question.\n\nHow many GPR points would you expect to have per lidar pixel? Assume linear transects through each pixel.\n\n# #2.1 Let's learn a bit about the resolution of the lidar rasters\n\n# height, width = flcf_ds.read(1).shape #Find the height and width of the array\n\n# #Use meshgrid to create two arrays matching the height/width of the input raster\n# #The GPR dataset consists of vectors --> we will eventually need to vectorize these lidar arrays\n# cols, rows = np.meshgrid(np.arange(width), np.arange(height)) \n\n\n# #Extract the easting/northing from the raster \n# x_lidar, y_lidar = rio.transform.xy(flcf_ds.transform, rows, cols) \n\n# #What's the resolution of the lidar dataset?\n# print(\"The x resolution of the snow depth raster is:\",x_lidar[0][1]-x_lidar[0][0])\n# print(\"The y resolution of the snow depth raster is:\",y_lidar[0][0]-y_lidar[1][0])\n\n\n# # 2.2 Matching GPR to the lidar grid\n\n# #Two conceptual paths forward: rasterize the GPR data, or convert lidar data to points\n\n# #Let's vectorize the raster data\n# x_lidar_vec = np.array(x_lidar).flatten()\n# y_lidar_vec = np.array(y_lidar).flatten()\n# flcf_ds_vec = flcf_ds.read().flatten()\n\n# #Pull vectors from geo dataframe\n# gpr_arr = np.stack([flcf_gpr_df.geometry.x, flcf_gpr_df.geometry.y,flcf_gpr_df['value']], axis=1)\n# gpr_x=gpr_arr[:,0]\n# gpr_y=gpr_arr[:,1]\n# gpr_twt=gpr_arr[:,2].reshape(len(gpr_arr[:,2]),1)\n\n\n# #2.3 Create sets of coordinates for the nearest neighbors search\n# coordinates_set1 = np.column_stack((x_lidar_vec,y_lidar_vec))\n# coordinates_set2 = np.column_stack((gpr_x,gpr_y))\n\n# # Build KDTree from the second set of coordinates\n# tree = cKDTree(coordinates_set2)\n\n# # Define the radius (in meters)\n# radius = 0.25\n\n# # Function to find the median of travel times within a radius --> Credit where credit is due, this function was generated in part by chatgpt\n# def find_median_travel_time_within_radius(point, tree, coordinates_set1, gpr_twt, radius):\n#     indices = tree.query_ball_point(point, radius)\n#     if indices:\n#         # Retrieve travel times for the nearest neighbors\n#         neighbor_twt = gpr_twt[indices]\n#         median_twt = np.median(neighbor_twt)\n#         return median_twt\n#     else:\n#         return np.nan  # Return NaN if no neighbors are within the radius\n# # Find medians for each lidar point\n# medians = np.array([find_median_travel_time_within_radius(point, tree, coordinates_set2, gpr_twt, radius) for point in coordinates_set1])\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#we-need-to-know-the-resolutions-of-the-lidar-and-gpr-datasets","position":45},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"The GPR data is not as spatially continuous as the lidar data, so most of the median twt dataset consists of nan’s","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#the-gpr-data-is-not-as-spatially-continuous-as-the-lidar-data-so-most-of-the-median-twt-dataset-consists-of-nans","position":46},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"The GPR data is not as spatially continuous as the lidar data, so most of the median twt dataset consists of nan’s","lvl2":"Commented until we fix reading of raster data"},"content":"Let’s remove the nan’s to free up memory and reduce processing time.\n\n# #At this point, all lidar points should have an associated gpr twt --> most are likely nan's though. But let's check!\n# print(\"The gpr array has size:\",medians.shape)\n# print(\"The lidar array has size:\",flcf_ds_vec.shape)\n\n\n# #2.4 Before we get to the math part, let's clear out the nan's from all important vectors:\n# #Create mask for gpr medians that are nan's\n# mask = np.isnan(medians)\n\n# #Remove entries from the lidar snow depth, x, and y vectors that align with the nan twt values\n# flcf_ds_vec_clean = flcf_ds_vec[~mask]\n# coordinates_set1_clean=coordinates_set1[~mask]\n\n# #Lastly, remove entries from the twt medians\n# medians_clean = medians[~mask]\n\n# #Let's check the new size of the twt array\n# print(medians_clean.shape)\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#the-gpr-data-is-not-as-spatially-continuous-as-the-lidar-data-so-most-of-the-median-twt-dataset-consists-of-nans","position":47},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions-1","position":48},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"Commented until we fix reading of raster data"},"content":"Roughly, how many points were removed?\n\nWhen we are done, we will have derived 3788 snow density estimates. In the same area, about four snow pits were dug, resulting in four bulk density measurements. How useful do you think our data will be?\n\nIs more always better?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions-1","position":49},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s now transition to the relative permittivity and density calculations","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#lets-now-transition-to-the-relative-permittivity-and-density-calculations","position":50},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s now transition to the relative permittivity and density calculations","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# #2.5 We finally get to the math part!!\n# #Let's calculate relative permittivity first...\n# c=0.2998#The speed of light in a vacuum\n# e_s = ((c * medians_clean) / (2 * flcf_ds_vec_clean)) ** 2\n\n# #And then calculate density\n# rho_s = ((np.sqrt(e_s) - 1) / 0.845) * 1000\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#lets-now-transition-to-the-relative-permittivity-and-density-calculations","position":51},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 3: Examining the derived densities","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-3-examining-the-derived-densities","position":52},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 3: Examining the derived densities","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# # 3.1 Finally, let's take a peek at what the derived densities look like...\n# plt.figure()\n# plt.scatter(coordinates_set1_clean[:,0], coordinates_set1_clean[:,1], s=10, c=rho_s, cmap='viridis', clim=(0, 500), edgecolor=None)\n\n# # Add colorbar to show the scale of color values\n# plt.colorbar()\n# plt.title('Snow Density (kg m-3)')\n\n# # Show the plot\n# plt.show()\n\n# # 3.2 What does the histogram distribution look like??\n# # Define bin edges\n# bin_edges = np.arange(np.min(rho_s), np.max(rho_s), 25)  # Create bin edges from min(x) to max(x) with step size 25\n\n# # Create the histogram\n# plt.figure()  # Create a new figure\n# plt.hist(rho_s, bins=bin_edges, edgecolor=None)  # Plot histogram with specified bin edges\n\n# plt.title('Snow Density Histogram')\n\n# # Show the plot\n# plt.show()\n\n# #Let's zoom in a little...\n# # Define bin edges\n# bin_edges = np.arange(0, 500, 25)  # Create bin edges from min(x) to max(x) with step size 25\n\n# # Create the histogram\n# plt.figure()  # Create a new figure\n# plt.hist(rho_s, bins=bin_edges, edgecolor='black')  # Plot histogram with specified bin edges\n\n# plt.title('Snow Density Histogram')\n\n# # Show the plot\n# plt.show()\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-3-examining-the-derived-densities","position":53},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-5-discussion-improving-density-estimation","position":54},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"5. Discussion: Improving Density Estimation"},"content":"What do you think? Do the derived densities look usable at this stage?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-5-discussion-improving-density-estimation","position":55},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What contributes to the random error?","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#what-contributes-to-the-random-error","position":56},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What contributes to the random error?","lvl2":"5. Discussion: Improving Density Estimation"},"content":"There are three groups of factors that control the random error:\n\nMeasurement accuracy for lidar snow depths and GPR twt. Reduced accuracy for either or both of the techniques will lead to large errors. The boreal forest had a lot of complex vegetation that may have impeded the accuracy of these instruments.\n\nDepth of the snowpack. The accuracy of the lidar is not a function of snow depth. Thus, the random errors reduce as the snow depth increases. The boreal forest snow depths were shallow!\n\nGeolocation alignment. GPR coordinates were post-processed, but accuracy is still likely on the order of ±3 m.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#what-contributes-to-the-random-error","position":57},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Improving the derived densities","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#improving-the-derived-densities","position":58},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Improving the derived densities","lvl2":"5. Discussion: Improving Density Estimation"},"content":"Let’s say we want to learn something about snow density in the boreal forest. The derived densities offer a HUGE increase in the number of available density measurements compared to in situ. But, in situ are much more accurate. How can we improve this dataset?\n\nIncrease the footprint of the derived densities by upsampling the lidar (e.g., to 3 m).\n\nThis will reduce the impact of GPR geolocation accuracy and the lidar/GPR observation uncertainty.\n\nNeed to be careful! The GPR footprint is large, but it may not scale well past 3 m.\n\nRemove erroneous values.\n\nHow does the lidar survey time compare with the GPR survey time? Was the snow disturbed or did more snow accumulate between surveys?\n\nRelative permittivity of snow cannot be less than air (\\epsilon_a = 1.0) or greater than liquid water (\\epsilon_w = 88).\n\nFor dry snow, relative permittivity is usually between 1.0 and 2.0. The removal of values outside a certain number of standard deviations and/or the interquartile range may be warranted.\n\nRun a spatial averaging filter.\n\nOur surveys were primarily spirals --> should pair nicely with such a filter!\n\nExperiment with the window size of the filter. How would a 5 m x 5 m filter compare to a 25 m x 25 m filter?\n\nShould the data be parsed into different forest cover classes before such a filter is run?\n\nBe careful of linear transects! Large windows tend to remove any density variability along such transects.\n\nOnce you reach this point, it is likely that the densities will be analysis ready. You could run a predictive model to fill in the void spaces, use the densities to evaluate models, calculate experimental variograms, etc.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#improving-the-derived-densities","position":59},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"6. SnowEx GPR Analysis-Ready Datasets"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-6-snowex-gpr-analysis-ready-datasets","position":60},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"6. SnowEx GPR Analysis-Ready Datasets"},"content":"Grand Mesa, Colorado (SnowEx 2017, 2020)\n\nWebb et al. (2019). \n\nWebb et al. (2019)\n\nBonnell et al. (2021). \n\nBonnell et al. (2021)\n\nMeehan (2021). \n\nMeehan (2021)\n\nWebb (2021). \n\nWebb (2021)\n\nMeehan & Hojatimalekshah (2024). \n\nMeehan & Hojatimalekshah (2024)\n\nCameron Pass, Colorado (SnowEx 2020, 2021)\n\nMcGrath et al. (2021). \n\nMcGrath et al. (2021)\n\nBonnell et al. (2022). \n\nBonnell et al. (2022)\n\nBonnell et al. (2024). \n\nBonnell et al. (2024)\n\nJemez Mountains, New Mexico (SnowEx 2020)\n\nWebb (2021). \n\nWebb (2021)\n\nArctic Coastal Plains, Alaska (SnowEx 2023)\n\nWebb (2024). \n\nWebb (2024)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-6-snowex-gpr-analysis-ready-datasets","position":61},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"7. References"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-7-references","position":62},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"7. References"},"content":"Lidar Datasets\n\nLarsen (2024). \n\nLarsen (2024)\n\nRelevant GPR LWC Studies\n\nWebb et al. (2018). \n\nWebb et al. (2018)\n\nWebb et al. (2020). \n\nWebb et al. (2020)\n\nBonnell et al. (2021). \n\nBonnell et al. (2021)\n\nWebb et al. (2022). \n\nWebb et al. (2022)\n\nRelevant GPR Density Studies\n\nYildiz et al. (2021). \n\nYildiz et al. (2021)\n\nMcGrath et al. (2022). \n\nMcGrath et al. (2022)\n\nBonnell et al. (2023). \n\nBonnell et al. (2023)\n\nMeehan et al. (2024). \n\nMeehan et al. (2024)","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-7-references","position":63},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG"},"type":"lvl1","url":"/notebooks/aviris-ng-tutorial","position":0},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG"},"content":"\n\n\n\nContributors: Joachim Meyer1, Chelsea Ackroyd1, McKenzie Skiles1, Phil Dennison1, Keely Roth1\n\n1University of Utah\n\nLearning Objectives\n\nBecome familiar with hyperspectral data, including data orginiating from AVIRIS-NG\n\nUnderstand the fundamental methods for displaying and exploring hyperspectral data in Python\n\nIdentify the amount of ice in a given pixel using spectral feature fitting methodology\n\n","type":"content","url":"/notebooks/aviris-ng-tutorial","position":1},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Review of Hyperspectral Data"},"type":"lvl2","url":"/notebooks/aviris-ng-tutorial#review-of-hyperspectral-data","position":2},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Review of Hyperspectral Data"},"content":"\n\nIncoming solar radiation is either reflected, absorbed, or transmitted (or a combination of all three) depending on the surface material. This spectral response allows us to identify varying surface types (e.g. vegetation, snow, water, etc.) in a remote sensing image. The spectral resolution, or the wavelength interval, determines the amount of detail recorded in the spectral response: finer spectral resolutions have bands with narrow wavelength intervals, while coarser spectral resolutions have bands with larger wavelength intervals, and therefore, less detail in the spectral response.\n\n\n\n\n\nhttps://​www​.neonscience​.org​/resources​/learning​-hub​/tutorials​/hyper​-spec​-intro\n\n","type":"content","url":"/notebooks/aviris-ng-tutorial#review-of-hyperspectral-data","position":3},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl3":"Multispectral vs. Hyperspectral Data","lvl2":"Review of Hyperspectral Data"},"type":"lvl3","url":"/notebooks/aviris-ng-tutorial#multispectral-vs-hyperspectral-data","position":4},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl3":"Multispectral vs. Hyperspectral Data","lvl2":"Review of Hyperspectral Data"},"content":"Multispectral instruments have larger spectral resolutions with fewer bands. This level of detail can be limiting in distinguishing between surface types. Hyperspectral instruments, in comparison, typically have hundreds of bands with relatively narrow wavelength intervals. The image below illustrates the difference in spectral responses between a multispectral (Landsat 8 OLI) and a hyperspectral (AVIRIS) sensor.\n\n\n\n","type":"content","url":"/notebooks/aviris-ng-tutorial#multispectral-vs-hyperspectral-data","position":5},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Computing environment"},"type":"lvl2","url":"/notebooks/aviris-ng-tutorial#computing-environment","position":6},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Computing environment"},"content":"We’ll be using the following open source Python libraries in this notebook:\n\n","type":"content","url":"/notebooks/aviris-ng-tutorial#computing-environment","position":7},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"SnowEx21 Spectral Reflectance Dataset"},"type":"lvl2","url":"/notebooks/aviris-ng-tutorial#snowex21-spectral-reflectance-dataset","position":8},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"SnowEx21 Spectral Reflectance Dataset"},"content":"The data were collected using an airborne imaging spectrometer, AVIRIS-NG can be downloaded from here, \n\nhttps://​nsidc​.org​/data​/snex21​_ssr​/versions/1.\n\nReflectance is provided at 5 nm spectral resolution with a range of 380-2500 nm\n\nFor this dataset, the pixel resolution is 4 m\n\nData span from 19 March 2021 to 29 April 2021, and were collected in two snow-covered environments in Colorado: Senator Beck Basin and Grand Mesa\n\nEach file will have a “.img” and “.hdr”. You need to have both of these in the same directory to open data.\n\n\n\n","type":"content","url":"/notebooks/aviris-ng-tutorial#snowex21-spectral-reflectance-dataset","position":9},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Accessing AVIRIS-NG Data from S3"},"type":"lvl2","url":"/notebooks/aviris-ng-tutorial#accessing-aviris-ng-data-from-s3","position":10},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Accessing AVIRIS-NG Data from S3"},"content":"For this tutorial, we’ve hosted the AVIRIS-NG data on AWS S3 for easy access. The data is streamed directly from the cloud, so no downloads are required!\n\nThe data is stored in a public S3 bucket in the us-west-2 region:\n\nBucket: s3://snowex-tutorials/aviris-ng/\n\nRegion: us-west-2 (Oregon)\n\nWe’ll use rasterio to read ENVI format files directly from S3. This approach:\n\nWorks with the original ENVI format (no conversion needed)\n\nStreams data on-demand (only reads what you need)\n\nRequires no authentication for public buckets\n\nEnables cloud-native workflows\n\nNote\n\nIf you want to use your own local AVIRIS-NG files instead, simply replace the S3 paths with local file paths.\n\nimport rasterio\nfrom rasterio.windows import Window\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\n","type":"content","url":"/notebooks/aviris-ng-tutorial#accessing-aviris-ng-data-from-s3","position":11},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Loading AVIRIS-NG data with rasterio"},"type":"lvl2","url":"/notebooks/aviris-ng-tutorial#loading-aviris-ng-data-with-rasterio","position":12},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Loading AVIRIS-NG data with rasterio"},"content":"We’ll use rasterio to open and read the AVIRIS-NG ENVI files directly from S3.\n\n# S3 paths for AVIRIS-NG data (public bucket, no auth required)\ns3_bucket = \"snowex-tutorials\"\ns3_prefix = \"aviris-ng\"\n# ENVI format requires opening the .img data file (not .hdr)\nreflectance_file = \"SNEX21_SSR_ang20210429t191025_SBB_rfl_v2z1a_subset.img\"\n\nprint(f\"Data source: s3://{s3_bucket}/{s3_prefix}/{reflectance_file}\")\nprint(f\"Region: us-west-2\")\nprint(f\"\\nNote: This data is publicly accessible, no AWS credentials needed!\")\n\n# Configure rasterio to access S3 with anonymous (no-auth) access\nos.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\nos.environ['AWS_REGION'] = 'us-west-2'\n\n# For ENVI files on S3, we need to use GDAL's virtual file system\nvsi_path = f\"/vsis3/{s3_bucket}/{s3_prefix}/{reflectance_file}\"\n\n# Open the AVIRIS-NG ENVI subset file from S3\nwith rasterio.Env(AWS_NO_SIGN_REQUEST='YES', AWS_REGION='us-west-2'):\n    with rasterio.open(vsi_path) as src:\n        print(f\"Dataset dimensions: {src.width} x {src.height}\")\n        print(f\"Number of bands: {src.count}\")\n        print(f\"Data type: {src.dtypes[0]}\")\n        print(f\"CRS: {src.crs}\")\n        print(f\"\\nReading reflectance data from S3...\")\n        print(f\"  (Streaming ~21 MB - tutorial subset)\")\n        \n        # Read all data from the subset\n        rfl_array = src.read()\n\nprint(f\"\\nReflectance data shape: {rfl_array.shape}\")\nprint(f\"Shape interpretation: ({rfl_array.shape[0]} bands, {rfl_array.shape[1]} rows, {rfl_array.shape[2]} columns)\")\nprint(f\"\\nData successfully loaded from S3!\")\n\n# Extract wavelength information from the ENVI header metadata\nvsi_path = f\"/vsis3/{s3_bucket}/{s3_prefix}/{reflectance_file}\"\n\nwith rasterio.Env(AWS_NO_SIGN_REQUEST='YES', AWS_REGION='us-west-2'):\n    with rasterio.open(vsi_path) as src:\n        # Get wavelength metadata from ENVI header\n        metadata = src.tags()\n        \n        # ENVI headers store wavelengths as a comma-separated string\n        if 'wavelength' in metadata:\n            wavelength_str = metadata['wavelength'].strip('{}')\n            bands = np.array([float(w.strip()) for w in wavelength_str.split(',')])\n            print(f\"Extracted {len(bands)} wavelength values\")\n            print(f\"Wavelength range: {bands.min():.1f} - {bands.max():.1f} nm\")\n            print(f\"\\nFirst 10 wavelengths (nm): {bands[:10]}\")\n        else:\n            print(\"Warning: Wavelength metadata not found in ENVI header\")\n            # Create default band indices if wavelengths aren't available\n            bands = np.arange(1, rfl_array.shape[0] + 1)\n\n# Visualize a single pixel's spectral signature\n# Note: rasterio uses (bands, rows, cols) indexing, different from (rows, cols, bands)\ni = 125  # row index (middle of subset)\nj = 125  # column index (middle of subset)\n\n# Extract pixel spectrum across all bands\npixel = rfl_array[:, i, j]\n\nfig, ax = plt.subplots(1, 1, figsize=(10,5))\nplt.rcParams.update({'font.size': 18})\nax.scatter(bands, pixel, color='blue', s=20)\nax.set_xlabel('Wavelength [nm]')\nax.set_ylabel('Reflectance')\nax.set_title(f'Spectral signature at pixel ({i}, {j})')\nax.grid(True, alpha=0.3)\nplt.show()\n\n","type":"content","url":"/notebooks/aviris-ng-tutorial#loading-aviris-ng-data-with-rasterio","position":13},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Working with Terrain Data"},"type":"lvl2","url":"/notebooks/aviris-ng-tutorial#working-with-terrain-data","position":14},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl2":"Working with Terrain Data"},"content":"Note\n\nTerrain and illumination data (*obs_ort files) for this flightline are not yet available in the S3 bucket. Once uploaded, they can be accessed the same way as the reflectance data shown above.\n\nTo obtain terrain data:\n\nVisit \n\nhttps://​search​.earthdata​.nasa​.gov/\n\nSearch for “AVIRIS-NG L1B Calibrated Radiance, Facility Instrument Collection, V1”\n\nLook for granules matching timestamp ang20210429t191025 with *obs_ort* in the filename\n\nThe obs_ort files contain 11 bands with terrain and illumination information","type":"content","url":"/notebooks/aviris-ng-tutorial#working-with-terrain-data","position":15},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl3":"Terrain bands (when available):","lvl2":"Working with Terrain Data"},"type":"lvl3","url":"/notebooks/aviris-ng-tutorial#terrain-bands-when-available","position":16},{"hierarchy":{"lvl1":"Introduction to AVIRIS-NG","lvl3":"Terrain bands (when available):","lvl2":"Working with Terrain Data"},"content":"Band 1: Path length (m)\n\nBand 2: To sensor azimuth\n\nBand 3: To sensor zenith\n\nBand 4: To sun azimuth\n\nBand 5: To sun zenith\n\nBand 6: Solar phase\n\nBand 7: Slope\n\nBand 8: Aspect\n\nBand 9: cosine(i) (local solar illumination angle)\n\nBand 10: UTC Time\n\nBand 11: Earth-sun distance (AU)\n\nImportant note: Aspect follows convention from -\\pi to \\pi.\n\nNote this tutorial is incomplete. Additional content to be added from here: \n\nhttps://​snowex​-2022​.hackweek​.io​/tutorials​/aviris​-ng​/AVIRIS​-NG​_Tutorial​.html","type":"content","url":"/notebooks/aviris-ng-tutorial#terrain-bands-when-available","position":17},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Microstructure"},"type":"lvl1","url":"/notebooks/microstructure-tutorial","position":0},{"hierarchy":{"lvl1":"Microstructure"},"content":"by Mike Durand, School of Earth Sciences and Byrd Polar & Climate Research Center \n\ndurand.8@osu.edu","type":"content","url":"/notebooks/microstructure-tutorial","position":1},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Learning Objectives"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#learning-objectives","position":2},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Learning Objectives"},"content":"At the end of this tutorial you should be able to...\n\nExplain why microstructure is important for remote sensing\n\nDefine measures of microstructure, especially specific surface area\n\nAccess and visualize tree different microstructure measurements from SnowEx Grand Mesa 2020","type":"content","url":"/notebooks/microstructure-tutorial#learning-objectives","position":3},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Acknowledgments"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#acknowledgments","position":4},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Acknowledgments"},"content":"Contributions from: Micah Johnson, Mike Durand, HP Marshall, Tate Meehan, Megan Mason, Scott Henderson. This relies heavily on the snowexsqul database and example scripts created by Micah Johnson.","type":"content","url":"/notebooks/microstructure-tutorial#acknowledgments","position":5},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Caveats"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#caveats","position":6},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Caveats"},"content":"The integrating sphere and the SMP data are published at NSIDC; you can read the pages there for documentation etc. However the microCT data are not yet published; please contact Lauren Farnsworth (\n\nlauren​.b​.farnsworth@usace​.army​.mil) for questions on the CT data.","type":"content","url":"/notebooks/microstructure-tutorial#caveats","position":7},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Fun Facts About Snow Microstructure"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#fun-facts-about-snow-microstructure","position":8},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Fun Facts About Snow Microstructure"},"content":"Snow microstructure plays a super important role in snow physics and snow remote sensing, so a lot of effort went towards measuring it in SnowEx 2020!\n\nThere are several different quantities that are used to measure snow microstructure, including “grain size”. Grain size measurements are challenging to make in a repeatable way, and are also challenging to relate to the physical quantities that control remote sensing measurements. In the last ~15 years or so, a lot of effort has gone into more objective ways to measure microstructure.\n\nSnow microstructure  governs response of remote sensing to snow cover for visible, near-infrared and high-frequency microwave wavelengths. See Figure 1, below, and read \n\n, for more information.\n\nSnow microstructure governs visible and near-infrared reflectance. This is figure 2 from\n\n\n\nRadar measurements such as those made by the Ku-band SWEARR instrument are also very sensitive to snow microstructure.\n\nModeled response of radar backscatter to SWE and single-scatter albedo (which in turn is a function of snow microstructure), based on a simple model suggested by\n\n\n\nSnow microstructure is super important to efforts to launch a Ku-band SAR to measure global snow water equivalent (SWE). An important area of research right now is exploring how to use estimates of microstructure (e.g. from snowpack evolution models) to improve SWE retrievals.\n\nSnow microstructure evolves through the season, and varies a lot with depth. Snow microstructure evolution is controlled by other snow properties, such as snow temperature, snow height and snow liquid water content. A really great resource on snow microstructure is Kelly Elder’s recent talks:\n\nSnow Metamorphism\n\nSnow Grain Identification\n\n","type":"content","url":"/notebooks/microstructure-tutorial#fun-facts-about-snow-microstructure","position":9},{"hierarchy":{"lvl1":"Microstructure","lvl2":"SnowEx Microstructure Measurement Background"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#snowex-microstructure-measurement-background","position":10},{"hierarchy":{"lvl1":"Microstructure","lvl2":"SnowEx Microstructure Measurement Background"},"content":"","type":"content","url":"/notebooks/microstructure-tutorial#snowex-microstructure-measurement-background","position":11},{"hierarchy":{"lvl1":"Microstructure","lvl3":"Basic Microstructure Definitions","lvl2":"SnowEx Microstructure Measurement Background"},"type":"lvl3","url":"/notebooks/microstructure-tutorial#basic-microstructure-definitions","position":12},{"hierarchy":{"lvl1":"Microstructure","lvl3":"Basic Microstructure Definitions","lvl2":"SnowEx Microstructure Measurement Background"},"content":"Microstructure definitions take a bit of getting used to. It’s very easy to get confused. Specific surface area (SSA) is one of the most important quantity used to measure snow microstructure, so that’s the focus here. Note that SSA is not the be-all and end-all, so there’s a short table describing how to relate SSA to other quantities just below.  A couple of good reads on all of this is \n\n and \n\n.\n\nCoarse and fine snow microstructure revealed by microCT. The microCT snow renderings on the left are Figure 2 from\n\n. The colorbars indicate that fine-grained snow (a) has high SSA and low D eq , whereas coarse-grained snow (b) has low SSA and high D eq .\n\nUse Figure 3 above to ground these definitions: SSA is the surface area of the ice-air interface, normalized in some way. Confusingly, SSA is defined in a couple of different ways in the literature: sometimes, surface area within a particular volume of interest (VOI) is normalized by the mass of the ice in the VOI. As defined in this way, SSA has units of length squared per mass, usually expressed as m2/kg. Instead of normalizing by mass, SSA is sometimes defined by normalizing by the volume of the VOI (this is SSAv in \n\n), and sometimes by normalizing by the volume of the ice in the VOI (this is SSAi in \n\n, and q in \n\n). Here let’s just go with the first definition I mentioned:SSA = \\frac{\\text{Surface area of ice-air interface}}{\\text{Mass of ice}} \\quad\n\nSSA tends to take values between 5 and 150 m2/kg: fresh, fine-grained snow has high SSA, and coarse snow has low SSA. Because it takes a little while for SSA values to become intuitive, a useful derived metric is the equivalent grain diameter (Deq; note that this is identical to Dq in \n\n), which by definition is the diameter that a sphere would have if it had a particular value of SSA. This is a one-to-one relationship, so there are no assumptions involved.D_{eq} = \\frac{6}{SSA \\rho_i} \\quad\n\nRelationships of specific surface area to other metrics are given in this list if you’re curious but otherwise just skip past this bit\n\nSometimes people refer to the “optical grain diameter”, which is the same as Deq. The “optical” refers to \n\n, who showed that any snow with a particular SSA had similar (not identical) radiative transfer properties regardless of particle shape in the visible and near-infrared parts of the spectrum. But note the same is not true in the microwave spectrum.\n\nAutocorrelation length is usually one of two metrics that summarize the two-point microstructure autocorelation function of the three-dimensional ice-air matrix. Think of the probability that you change media (from ice to air or vice versa) as you move a certain distance within the snow microstructure. The length that defines the likelihood that you’ll change media is (an approximation of the correlation length). SSA is by definition (with almost no assumptions) equal to the slope of the autocorrelation function at the origin. But microwave scattering is controlled by correlations at longer lags. For more check out \n\n. The lack of closing the loop between SSA and correlation length is a significant issue when we have measurements of SSA and microwaves as we do in SnowEx.\n\nGeometric grain size is what we usually measure when we measure with a hand lens. You can try to relate it to SSA or corelation length, but it is not always possible, and will change with different observers.\n\nTime to stop this list but there are many other metrics as well.\n\n","type":"content","url":"/notebooks/microstructure-tutorial#basic-microstructure-definitions","position":13},{"hierarchy":{"lvl1":"Microstructure","lvl3":"Microstructure Instruments","lvl2":"SnowEx Microstructure Measurement Background"},"type":"lvl3","url":"/notebooks/microstructure-tutorial#microstructure-instruments","position":14},{"hierarchy":{"lvl1":"Microstructure","lvl3":"Microstructure Instruments","lvl2":"SnowEx Microstructure Measurement Background"},"content":"Now that we know what we’re trying to measure (SSA, or correlation length) how do we actually measure? let’s talk just about three techniques used in SnowEx 2020 Grand Mesa.\n\nLeft: Lauren Farnsworth transports microCT samples from field sites back to Grand Mesa Lodge in a cold storage container. Right: the microCT machine in the lab at CRREL.\n\nMicro-computed tomography (microCT) is the only laboratory-based method used here, and it is the gold standard, although it does still come with caveats. The idea of microCT is to remove a sample of snow from a snow pit face, and either cast it with a compound such as diethyl pthalate that is still a liquid at 0° C, or preserve the same at a very cold temperature. Then the sample is sent back to the laboratory, and bombared with x-rays, similar to how you get x-rays to see if a bone is broken at the doctor. For much more on microCT, check out \n\n. microCT can be used to extract a ton of information about snow microstructure, including SSA, correlation length and many others.\n\nLeft: Kehan Yang operates an IceCube unit at the Grand Mesa Lodge intercomparison snowpit. Top right: schematic showing the integrating sphere measurement principle, from\n\n. Bottom right: snow in the IceCube sampling container, from\n\n.\n\nIntegrating spheres are field-based and you make the measurements on samples extracted from the snowpit face. The principle of the measurement is based on firing a laser at the snow sample, within a special reflective hollow sphere, where one side is filled by the snow sample, and measuring how much of the laser is reflected at a sensor at a known geometry. For more information, check out \n\n.  Most integrating sphere measurements are either made by a commercial firm (A2 Photonics) known as the \n\nIceCube or a version constructed at the University of Sherbrooke known as the IRIS \n\n. These approaches are set up to measure SSA only. There were three of these at Grand Mesa - one of the Sherbrooke IRIS units, and two IceCubes, one from Finnish Meteorological Institute, and one from Ohio State University.\n\nLeft: Megan Mason operates the SMP. Right: Closeup of the SMP sensor tip.\n\nSnow micropenetrometers are also a field-based approach, but they do not require a snowpit, enabling far more observations to be made. Instead, an automated motor pushes a probe vertically downwards into the snowpack. The probe measures the force required to break snow microstructure, yielding a wealth of information. Snow density, specific surface area and correlation length can be retrieved; for background see \n\n and \n\n. The micropen effort at Grand Mesa was led by Boise State University. A key thing to be aware of is that differences in the various SMP instruments mean that the empirical relationship of \n\n will give quite poor results for the particular instrument used in SnowEx, as fully explained in \n\n.\n\nThese methods are not the only ways to measure microstructure! There are several others not mentioned here, but not used at Grand Mesa 2020. Ask if interested.","type":"content","url":"/notebooks/microstructure-tutorial#microstructure-instruments","position":15},{"hierarchy":{"lvl1":"Microstructure","lvl2":"SnowEx Microstructure Measurement Data Overview"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#snowex-microstructure-measurement-data-overview","position":16},{"hierarchy":{"lvl1":"Microstructure","lvl2":"SnowEx Microstructure Measurement Data Overview"},"content":"Of the three methods described above, microCT is by far the most expensive and most time consuming. Samples have to be transported back to the laboratory and the processing time requires a microCT machine. Thus the fewest CT sapmles are taken.\n\nThe integrating spheres require a snowpit to be dug, so we have an intermediate number of them: ~100.\n\nThe micropen measurements are by far the fastest to make, so a cross pattern of SMP measurements was made on orthogonal directions intersecting at the snowpit. There are thousands of SMP profiles from Grand Mesa 2020.\n\n","type":"content","url":"/notebooks/microstructure-tutorial#snowex-microstructure-measurement-data-overview","position":17},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Working with the data"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#working-with-the-data","position":18},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Working with the data"},"content":"We’re going to do two things! First, we’ll intercompare the three different integrating sphere instruments at four different pits where we had multiple instruments operating. We’d expect these data to be fairly self-consistent. Second, we’ll compare all three methods (integrating sphere, SMP and microCT) at a single pit where we had all of these measurements present. Here especially with the SMP we would expect to need to intercalibrate the data to match local conditions; so far SSA has only been fit to SMP force measurements in one study, and we should assume we’ll need a local calibration to get a tight fit.\n\n","type":"content","url":"/notebooks/microstructure-tutorial#working-with-the-data","position":19},{"hierarchy":{"lvl1":"Microstructure","lvl3":"0. Load needed modules","lvl2":"Working with the data"},"type":"lvl3","url":"/notebooks/microstructure-tutorial#id-0-load-needed-modules","position":20},{"hierarchy":{"lvl1":"Microstructure","lvl3":"0. Load needed modules","lvl2":"Working with the data"},"content":"\n\n# Modules needed to access snowexsql: SnowEx field data database\nfrom snowexsql.db import get_db\nfrom snowexsql.data import LayerData, PointData\nfrom snowexsql.conversions import points_to_geopandas, query_to_geopandas\n\n# Modules needed to work with data\nimport geoalchemy2.functions as gfunc\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nfrom snowmicropyn import Profile\nfrom snowmicropyn import proksch2015\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","type":"content","url":"/notebooks/microstructure-tutorial#id-0-load-needed-modules","position":21},{"hierarchy":{"lvl1":"Microstructure","lvl3":"1. Intercompare Integrating Sphere Datasets","lvl2":"Working with the data"},"type":"lvl3","url":"/notebooks/microstructure-tutorial#id-1-intercompare-integrating-sphere-datasets","position":22},{"hierarchy":{"lvl1":"Microstructure","lvl3":"1. Intercompare Integrating Sphere Datasets","lvl2":"Working with the data"},"content":"\n\nThere were three integrating spheres. The IRIS unit from University of Sherbrooke was operated by Celine Vargel. The IceCube unit from the Finnish Meteorological Institute was operated by Juha Lemmetyinen. And the IceCube unit from Ohio State was operated by Kehan Yang and Kate Hale. Carefully read the \n\ndocumentation page at NSIDC if you are interested in the data. If you are using the data for a project, please contact the authors and mention what you’re doing - they’ll appreciate it! Contact for SSA is Mike Durand (\n\ndurand.8@osu.edu).\n\nSee Micah’s tutorial on datasets for more on this! Won’t explain too much here\n\ndb_name = 'snow:hackweek@db.snowexdata.org/snowex'\nengine, session = get_db(db_name)\n\n# Grab all the equivalent diameter profiles\nq = session.query(LayerData).filter(LayerData.type == 'specific_surface_area')\ndf = query_to_geopandas(q, engine)\n\n# End our database session to avoid hanging transactions\nsession.close()\n\ndf.head() #check out the results of the query\n\nSince we want to intercompare integrating spheres, we need to isolate only the sites that actually had multiple integrating spheres measuring the same snow.\n\n# Grab all the sites with equivalent diameter data (set reduces a list to only its unique entries)\nsites = df['site_id'].unique()\n\n# Store all site names that have multiple SSA instruments\nmulti_instr_sites = []\ninstruments = []\n\nfor site in sites:\n\n    # Grab all the layers associated to this site\n    site_data = df.loc[df['site_id'] == site]\n\n    # Do a set on all the instruments used here\n    instruments_used = site_data['instrument'].unique()\n\n    if len(instruments_used) > 1:\n        multi_instr_sites.append(site)\n\n# Get a unqique list of SSA instruments that were colocated\ninstruments = df['instrument'].unique()\n\ninstruments #check out the list of instruments. note that the IceCube values are displayed as serial numbers\n\nFinally, plot all Integrating Sphere SSA profiles at all Multi-Integrating Sphere Sites\n\n# Setup the subplot for each site for each instrument\nfig, axes = plt.subplots(1, len(multi_instr_sites), figsize=(4*len(multi_instr_sites), 8))\n\n# Establish plot colors unique to the instrument\nc = ['k', 'm', 'c']\ncolors = {inst:c[i] for i,inst in enumerate(instruments)}\n\n# Loop over all the multi-instrument sites \nfor i, site in enumerate(multi_instr_sites):\n    \n    # Grab the plot for this site\n    ax = axes[i]\n    \n    # Loop over all the instruments at this site\n    for instr in instruments:\n\n        # Grab our profile by site and instrument\n        ind = df['site_id'] == site \n        ind2 = df['instrument'] == instr\n        profile = df.loc[ind & ind2].copy()\n\n        # Don't plot it unless there is data\n        if len(profile.index) > 0:\n            \n            # Sort by depth so samples that are take out of order won't mess up the plot\n            profile = profile.sort_values(by='depth')\n            \n            # Layer profiles are always stored as strings. \n            profile['value'] = profile['value'].astype(float)\n            \n            # Plot our profile\n            ax.plot(profile['value'], profile['depth'], colors[instr], label=instr)\n   \n    # Labeling and plot style choices\n    ax.legend()\n    ax.set_xlabel('SSA [m^2/kg]')\n    ax.set_ylabel('Height above snow-soil interface [cm]')\n    ax.set_title('Site {}'.format(site.upper()))\n    \n    # Set the x limits to show more detail\n    ax.set_xlim((8, 75))\n    \nplt.tight_layout()\nplt.show()\n\n\n","type":"content","url":"/notebooks/microstructure-tutorial#id-1-intercompare-integrating-sphere-datasets","position":23},{"hierarchy":{"lvl1":"Microstructure","lvl3":"2. Pull the snowmicropenetrometer data and compute SSA","lvl2":"Working with the data"},"type":"lvl3","url":"/notebooks/microstructure-tutorial#id-2-pull-the-snowmicropenetrometer-data-and-compute-ssa","position":24},{"hierarchy":{"lvl1":"Microstructure","lvl3":"2. Pull the snowmicropenetrometer data and compute SSA","lvl2":"Working with the data"},"content":"The next step is to grab some SMP data to compare to. We’re going to get the SMP at site 2N13, where we have a copule of SSA profiles from integrating spheres (as well as microCT data, to be looked at in the next step!).\n\nThe SMP measurements for SnowEx 2020 GrandMesa were all made by Megan Mason. If you’re interested in working with the SMP data, please carefully read the NSIDC \n\ndocumentation page. If you’re planning to work with the data, please reach out to the author; the contact is (Megan Mason \n\nmeganmason491@u​.boisestate​.edu). If you use a profile, consider checking out the comments which are described in the \n\nExcel sheet linked from the Technical References part of the NSIDC documentation, where there are some really useful comments.\n\nThere are a few steps here, and one reason for that is just that the SMP data is quite large, and so the full-resolution SMP could not be included in Micah’s database. The full resolution profile from SMP is resolved ever 1.25 mm! Instead, the SMP data in Micah’s database is sampled to only every 100th datapoint, so it’s every 12.5 cm. But the database is still very useful! What we’ll do is use the database to find the right profile, then go and download that full resolution dataset from the NSIDC. Easy-peasey!\n\nAs mentioned above, \n\n tested applying the relationship of \n\n and got quite poor results, explained them by the difference in hardware between generations of SMP instruments. We were unaware of that when designing the tutorial, and so set up use of the so-called official SMP processing repository, linked below, which has not yet been updated with the latest relationship. This would make a great project, as mentioned later!\n\nFirst up, we’ll visualize the location of the SMP profiles, along with the snowpit location.\n\nsite = '2N13'\nengine_smp, session_smp = get_db(db_name)\nq_smp = session_smp.query(LayerData).filter(LayerData.type == 'force').filter(LayerData.site_id.contains(site) )\ndf_smp = query_to_geopandas(q_smp, engine_smp)\n\nq_pit=session_smp.query(LayerData).filter(LayerData.type == 'hand_hardness').filter(LayerData.site_id.contains(site) )\ndf_pit = query_to_geopandas(q_pit, engine_smp)\n\nsession_smp.close()\n\n# Plot SMP profile locations with colored by the time they were taken using upside down triangles\nax = df_smp.plot(column='time', cmap='jet', marker='v', label='SMP', figsize=(5,5), markersize=100, edgecolor='black')\n\nax.plot(df_pit.easting, df_pit.northing, color='black', marker='s', markersize=15, label='Pit ({})'.format(site))\n\n# Add important labels\nax.set_xlabel('Easting [m]')\nax.set_ylabel('Northing [m]')\nplt.suptitle('SMP Locations at Site {} Showing Acquisition Order'.format(site), fontsize=16)\n\n# Avoid using Scientific notation for coords.\nax.ticklabel_format(style='plain', useOffset=False)\nax.legend()\n# plt.tight_layout()\nplt.show()\n\nNext up, let’s find the closest SMP profile to the snowpit, and then find the profile ID of that profile, which is in the comments in the database.\n\n# find closest SMP profile to the pit\n\n# No profile is taken at the same time, so we grab all the unique times and sort them\ntimes = sorted(df_smp['time'].unique())\n\nnprofiles=len(times)\n\nids=np.empty(nprofiles)\n\np=0\nfor t in times:\n    ind = df_smp['time'] == t\n    data = df_smp.loc[ind].copy()\n    ids[p]=data.iloc[0].id\n    p+=1\n    \ni_dists=df_smp['id'].isin(ids)\n\ndf_smp_dists=df_smp.loc[i_dists]\ndf_smp_dists=df_smp_dists.assign(dists=-1)\ndf_smp_dists['dists']=np.sqrt((df_smp_dists['easting']-df_pit.iloc[0].easting)**2+(df_smp_dists['northing']-df_pit.iloc[0].northing)**2)\n\n    \ndf_smp_dists.sort_values(by='dists')[['comments','dists']].head() #check out the list of profiles sorted by distance to pit\n\nSo the id of the closest SMP profile is S19M1174.  I went to the \n\nSMP page on NSIDC, and went to “Download” and searched for this ID, downloaded the profile, and then re-uploaded to my home directory here in the Jupyter hub.\n\nOk next up, we have to compute SSA from the SMP data. For this, we’ll use the “snowmicropyn” modules created by the Swiss SLF. You can read more about them \n\nat this site. The software is a little out of date on Python versions; just ignore any warnings that pop up below! Also, the use of the  \n\n relationship is also out-of-date, as mentioned above. Getting it updated for use with this tutorial would make a perfect project!\n\nThe next cell pulls in the needed modules, and then plots the profile of force measurements needed to break through the snow microstructure. Note that we have already downloaded data for this tutorial from \n\nhttps://​zenodo​.org​/record​/5504396​/files​/microstructure​.zip.\n\np = Profile.load('data/microstructure/SMP/SNEX20_SMP_S19M1174_2N13_20200206.PNT',)\nplt.plot(p.samples.distance, p.samples.force)\n# Prettify our plot a bit\nplt.title(p.name)\nplt.ylabel('Force [N]')\nplt.xlabel('Depth [mm]')\nplt.show()\n\nThe above shows the entire SMP profile; this includes the part of the force profile that is above the snow surface, and thus needs to be removed, in order to apply calculations only to the snow (not the air!).\n\n#extract the part of the profile that is in the snow (i.e. remove air)\ndepth_surf=p.detect_surface()\ndepth_ground=p.detect_ground()\nsamples_snow=p.samples_within_distance(begin=depth_surf, end=depth_ground, relativize=False)\nsamples_snow.distance-=depth_surf\nplt.plot(samples_snow.distance, samples_snow.force)\nplt.title(p.name)\nplt.ylabel('Force [N]')\nplt.xlabel('Depth [mm]')\nplt.show()\n\nThe above part of the profile is just the part that is in the snow. PLEASE NOTE that the automated functions are not infallible, and need to be used with care. For now, these need to be compared back to the notes and interpreted manually.\n\nThe next step is the actual calculation of SSA from the force data. It then displays the data and lets you see that there is now a column called SSA! Note that this function is “proksch2015”. You can read about how it works in Martin Proksch’s paper \n\n.\n\n# call using the snowmicropyn library proksch2015\np2015 = proksch2015.calc(p.samples) \np2015.head() #check out the first few values of SSA\n\n","type":"content","url":"/notebooks/microstructure-tutorial#id-2-pull-the-snowmicropenetrometer-data-and-compute-ssa","position":25},{"hierarchy":{"lvl1":"Microstructure","lvl3":"3. Read microCT data, and compare integrating sphere, SMP and CT data","lvl2":"Working with the data"},"type":"lvl3","url":"/notebooks/microstructure-tutorial#id-3-read-microct-data-and-compare-integrating-sphere-smp-and-ct-data","position":26},{"hierarchy":{"lvl1":"Microstructure","lvl3":"3. Read microCT data, and compare integrating sphere, SMP and CT data","lvl2":"Working with the data"},"content":"\n\nThe microCT samples were extracted in the field and processed at CRREL by Lauren Farnsworth, and is not yet published at NSIDC. Please contact her with questions (\n\nlauren​.b​.farnsworth@usace​.army​.mil)!\n\nThis module reads in microCT datafiles which are stored as text. Some additional data are available, showing the computer generated slices through the ice-air interface: contact Mike (\n\ndurand.8@osu.edu) if you want to look at a subset of these data that Lauren has shared.\n\nEquivalent grain size is a useful quantity to compare: because it’s proportional to 1/SSA, and because after a point as you increase SSA more and more, all fine-grained snow acts more-or-less the same (converging to e.g. the “fine-grained” curve in Figure 1, above), we’ll look at equivalent diameter instead of SSA in this comparison.\n\n# function to read all microCT data in\n#    by Mike Durand June 2021\n\ndef read_CT_txt_files(DataDir):\n        \n    filenames = (f for f in os.scandir(DataDir) if not f.name.startswith('.'))\n    n=len(list(filenames)) #to preallocate S    \n    \n    SSA=np.empty([n])\n    height_min=np.empty([n])\n    height_max=np.empty([n])\n\n    filenames = (f for f in os.scandir(DataDir) if not f.name.startswith('.'))\n    \n    count=0\n    \n    for entry in filenames:\n\n        fname=DataDir + entry.name                \n        \n        #parse depth range\n        split_name=fname.split('_')\n        height_range=split_name[1]\n        height_min_max=height_range[0:-2].split('-')            \n        height_max[count]=float(height_min_max[0])\n        height_min[count]=float(height_min_max[1])                   \n                        \n        with open(fname,\"r\",encoding='iso-8859-1') as datafile:            \n            for line in datafile:                \n                if 'Object surface / volume ratio' in line:                \n                    split_line=line.split(',')                                        \n                    SSA[count]=float(split_line[2])\n                    count+=1                    \n\n    #convert from 1/mm to m^2/kg \n    SSA*=1000./917. \n    \n    # sort data\n    isort=np.argsort(height_min)\n    height_min=height_min[isort]\n    height_max=height_max[isort]\n    SSA=SSA[isort]\n \n    return SSA,height_min,height_max\n\n","type":"content","url":"/notebooks/microstructure-tutorial#id-3-read-microct-data-and-compare-integrating-sphere-smp-and-ct-data","position":27},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Read micro CT data for 2N13"},"type":"lvl2","url":"/notebooks/microstructure-tutorial#read-micro-ct-data-for-2n13","position":28},{"hierarchy":{"lvl1":"Microstructure","lvl2":"Read micro CT data for 2N13"},"content":"The full dataset of micro CT data can be found at \n\nhttps://​zenodo​.org​/record​/5504396​/files​/microstructure​.zip. Here we have already downloaded 5 of those files, just for illustration purposes.\n\n# read micro CT for 2N13\ndata_dir='data/microstructure/microCT/txt/'\n[SSA_CT,height_min,height_max]=read_CT_txt_files(data_dir)\n\nSSA_CT #check out the SSA values read in from MicroCT\n\n# get data integrating sphere data for 2N13 and plot it \nsite='2N13'\nengine_is, session_is = get_db(db_name)\nq_is = session_is.query(LayerData).filter(LayerData.type == 'specific_surface_area').filter(LayerData.site_id.contains(site) )\ndf_is = query_to_geopandas(q_is, engine_is)\ninstruments_site = df_is['instrument'].unique()\n\n# Loop over all the integrating sphere instruments at this site. plot equivalent diameter\nfig,ax = plt.subplots()\nfor instr in instruments_site:\n\n    # Grab our profile by site and instrument\n    ind = df['site_id'] == site \n    ind2 = df['instrument'] == instr\n    profile = df.loc[ind & ind2].copy()\n\n    # Don't plot it unless there is data\n    if len(profile.index) > 0:\n\n        # Sort by depth so samples that are take out of order won't mess up the plot\n        profile = profile.sort_values(by='depth')\n\n        # Layer profiles are always stored as strings. \n        profile['value'] = 6/917/profile['value'].astype(float)*1000\n\n        # Plot our profile\n        ax.plot(profile['value'], profile['depth'], colors[instr], label=instr)\n        \n#All that's left to do is plot the CT and the SMP and label the plot!\nax.plot(6/917/SSA_CT*1000,height_min,label='microCT')        #CT data\n\nax.plot(6/917/p2015.P2015_ssa*1000,(max(p2015.distance)-p2015.distance)/10,label='SMP') #SMP data\n\n# Labeling and plot style choices\nax.legend()\nax.set_xlabel('Equivalent diameter, mm')\nax.set_ylabel('Height above snow-soil interface [cm]')\nax.set_title('Site {}'.format(site.upper()))\n    \nplt.tight_layout()\nplt.show()\n\nWow, so the datasets are so very different, with the SMP being by far the most different. Comparing with \n\n shows that the SMP is off in the same direction as diagnosed in that paper. Thus, the difference is most likely due to the difference in SMP instruments. Dr. Mel Sandells of Northumbria University has a github branch of the SMP software SnowMicropyn that has the newer fit relationship integrated in the software. It would be a nice project to loop in Mel’s branch with this notebook and see how well things compare to SnowEx data. I’d be happy to help anyone interested get rolling on that!\n\nThere’s also significant differences between the microCT and the two integrating spheres. This is science - sometimes when we start intercomparing these quantities, we do not get a perfect match. This would also be a fascinating thing to explore in a Hackweek project.\n\nSome of the ways that you could imagine connecting microstructure measurements to other quantities would be with the SWESARR radar data. Although the radar data does seem to have some orthorectification issues that haven’t been fully worked out, I can imagine these being worked around by careful choice of places you match up the microstructure to the radar. Note that places that are shallower tend to have larger Deq and vice versa, and the spatial variability in SSA was fairly low in general in Grand Mesa 2020, so looking at multiple SSA vs radar samples might not yield a great correlation. But you never know, could be fun to try! Generally speaking, we don’t expect a ton of impact of the microstructure on L-band (UAVSAR), but it would be interesting to explore that.\n\nOne thing that could be of great value is to calibrate the SMP estimates of SSA to the integrating spheres. If you’re interested in doing that, do reach out first. This could be a really interesting thing to explore!\n\nIt might also be interesting to compare the data to hand hardness measured in the snowpit, and to traditional hand lens measurements.","type":"content","url":"/notebooks/microstructure-tutorial#read-micro-ct-data-for-2n13","position":29},{"hierarchy":{"lvl1":"SNOTEL Data Access"},"type":"lvl1","url":"/notebooks/snotel-data-access","position":0},{"hierarchy":{"lvl1":"SNOTEL Data Access"},"content":"This notebook allows for easy access to snow depths and SWE from the Snow Telemetry (SNOTEL) network. A simple example is used to show quick access to SNOTEL data over Creamer’s Field, AK using the metloom package.\n\nCredit: M3Works for the metloom package, which can be found here: \n\nhttps://​github​.com​/M3Works​/metloom​/tree​/main\n\nfrom datetime import datetime\nimport pandas as pd\nimport geopandas as gpd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\nMetloom allows for easy access to several weather station types, including SNOTEL, MesoWest, and NorwayMet. The primary query function for each is SnotelPointData (replace “Snotel” with station of choice), which also allows us to view the locations of weather stations. We’ll start this example doing just that.\n\n# Import the SNOTEL pointdata classes\nfrom metloom.pointdata import SnotelPointData\n\n# Import the SNOTEL variable classes\nfrom metloom.variables import SnotelVariables\n\nWe are going to look for active SNOTEL stations near Creamer’s Field in Fairbanks, AK. The below cells search for SNOTEL stations within 0.5 degrees latitude/longitude of the provided polygon.\n\nWe will also go ahead and define the variables we want from the station, using SnotelPointData.ALLOWED_VARIABLES. Some of the allowed variables include:\n\nSNOWDEPTH: Snow depth, typically in inches.\n\nSWE: Snow water equivalent, typically in inches.\n\nPRECIPITATION: Accumulated precipitation, in inches.\n\nTMP: Air temperature, in degrees Fahrenheit.\n\n# Load FLCF lidar box from SnowEx campaigns\nsf_path = Path(\"data/cffl_lidar_box.geojson\").expanduser()\nsf = gpd.read_file(str(sf_path))\nsf[\"name\"] = [\"FLCF\"]\n\n# Load the desired variables for SNOTEL query\nvariables = [SnotelPointData.ALLOWED_VARIABLES.SNOWDEPTH]\n\n# Find SNOTEL stations within polygon with desired variables\npoints = SnotelPointData.points_from_geometry(sf, variables)\n\n# Print nearby SNOTEL stations within 0.5 degrees of polygon\nprint(SnotelPointData.points_from_geometry(sf, variables, buffer=0.5).points)\n\nLooks like we have a SNOTEL station here! Note the printed output: Metloom returns the station ID number (1302), the state it’s in (AK), and the type of weather station (SNTL).\n\nLet’s see where it’s located in Creamer’s Field, relative to the polyon we provided.\n\n# Plot lidar box over ESRI tiles\nm = sf.explore(\n    tooltip=False, color=\"grey\", highlight=False, tiles=\"Esri.WorldImagery\",\n    style_kwds={\"opacity\": 0.2}, popup=[\"name\"]\n)\n# Add plot showing location of SNOTEL station(s)\ndf = points.to_dataframe()\ndf.explore(m=m, tooltip=[\"name\", \"id\"], color=\"red\", marker_kwds={\"radius\":4})\n\nNow that we know which SNOTEL is in the area, we can query for the data.\n\n# Define SNOTEL station from FLCF\npt = SnotelPointData(\"1302:AK:SNTL\", \"Creamer's Field\")\n\nAs with other API requests, we can subset the data with a date range, given as datetime objects.\n\nNote here that we are requesting for snow depths on a daily basis. If desired, we could also obtain the hourly data instead, using pt.get_hourly_data().\n\n# Start and end date of SNOTEL query\nstart_date = datetime(2022, 3, 1)\nend_date = datetime(2023, 4, 1)\n\n# Query SNOTEL snow depths\ndf = pt.get_daily_data(start_date, end_date, variables)\n\ndf.head()\n\nEasy enough! We now have a data frame containing the basic information of the SNOTEL site, as well as the snow depth in inches.\n\nSince inches aren’t very useful in scientific analysis, and SNOWDEPTH can be a hassle to type out, let’s make a new column that shows the depth in meters.\n\n# Convert snow depth to meters\ndf['snow_depth_meters'] = df['SNOWDEPTH']*0.0254\n\nFrom there, it’s simple to plot the snow depth data as a time series.\n\n# Plot time series of daily SNOTEL data\nfig, ax = plt.subplots()\ndf.reset_index().set_index(\"datetime\")[\"snow_depth_meters\"].plot(ax=ax)\nax.set_xlabel(\"Date\", fontsize=12)\nax.set_ylabel(\"Snow depth [m]\", fontsize=12)\nax.set_title(\"SNOTEL: Creamer's Field (1302)\", fontsize=12)\nfig.tight_layout()","type":"content","url":"/notebooks/snotel-data-access","position":1},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"type":"lvl1","url":"/notebooks/snowex-data-overview","position":0},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"content":"\n\n","type":"content","url":"/notebooks/snowex-data-overview","position":1},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"type":"lvl1","url":"/notebooks/snowex-data-overview#field-campaigns-overview","position":2},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"content":"(5 minutes)\n\nBy: Megan Mason (NASA Goddard / SSAI) \n\nmegan​.a​.mason@nasa​.gov\n\nSupport by:  Carrie Vuyovich (NASA Goddard), Hans-Peter Marshall (Boise State), Svetlana Stuefer (University of Alaska Fairbanks)\n\nLearning Objectives\n\nVisual overview of the NASA SnowEx field campaigns\n\nGet a sense for the extent of data coverage\n\n\n\n","type":"content","url":"/notebooks/snowex-data-overview#field-campaigns-overview","position":3},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl2":"Data Coverage"},"type":"lvl2","url":"/notebooks/snowex-data-overview#data-coverage","position":4},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl2":"Data Coverage"},"content":"Each year we build upon our efforts to further investigate snow remote sensing science gaps identified in the NASA SnowEx Science Plan \n\n(Durand et al., 2016). The summary table lists the focus for each campaign by year and type. There are two different campaign types (IOP vs. TS); both result in the same types of measurements and data products. Depending on the  research application it may not matter at all which you choose to work with, or even combine! The important thing to grasp is the difference in spatial and temporal extent of the campaign periods. If the sampling protocols or data products change over time, it is for the sake of improvement. When possible, we aim to keep things consistent to continue to build a legacy data set.\n\nYear\n\nCampaign Type\n\nMeasurement Focus\n\n2017\n\nIOP\n\nColorado, focused on multiple instruments in a forest gradient.\n\n2020\n\nIOP, TS\n\nWestern U.S focused on Time Series of L-band InSAR, active/passive microwave for SWE and thermal IR for snow surface temp.\n\n2021\n\nTS\n\nWestern U.S, continued Time Series of L-band InSAR, also addressed prairie & snow albedo questions.\n\n2023\n\nIOP\n\nAlaska Tundra & Boreal forest, focused on addressing SWE/snow depth and albedo objectives.\n\n*IOP=Intense Observation Period (~2-3 week, daily observations) *; TS=Time Series (~3-5 month winter, weekly observations)\n\n","type":"content","url":"/notebooks/snowex-data-overview#data-coverage","position":5},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Where has SnowEx Been?","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#where-has-snowex-been","position":6},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Where has SnowEx Been?","lvl2":"Data Coverage"},"content":"Campaign efforts are focused on various snow climates in the western United States. SnowEx partnerships and expertise are spread across the U.S and international.\n\n\nFigure 1. Map showing the locations of SnowEx field campaign areas (red dot). Base map shows snow classes defined in \n\nSturm and Liston, 2021. The snow pit images show a representative pit in each of the class types visited by SnowEx.\n\nTable 1. Number of manual depths and snow pits associated with NASA SnowEx measurement periods.\n\nSnowEx\n\nField Campaign Location\n\nTemporal Coverage\n\nManual Depths\n\nSnow Pits\n\nS17\n\nGrand Mesa & Senator Beck Basin, Colorado\n\nFebruary 6-25, 2017\n\n23,432\n\n265\n\nS20\n\nGrand Mesa, ColoradoWestern U.S Time Series (13 sites)\n\nNovember 4-7, 2019January 27-February 12, 2020October 24-May 20, 2020*\n\n16,21237,921TBD\n\n21154454\n\nS21\n\nWestern U.S Time Series (7 sites)\n\nNovember 16-May 27, 2021\n\n12,536\n\n247\n\nS23\n\nTundra & Boreal Forest, Alaska (pre-campaign site visit)Tundra & Boreal Forest, AlaskaTundra & Boreal Forest, AlaskaBoreal Forest, AlaskaTundra & Boreal Forest, Alaska\n\nMarch 7-17, 2022October 22-27, 2022March 7-16, 2023April 5-May 6, 2023October 17-28, 2023\n\n10,7289,04926,750TBD6,350\n\n1818617013127\n\n*The majority of sites in 2020 have a temporal coverage of January-March due to the Covid-19 pandemic.\n\n","type":"content","url":"/notebooks/snowex-data-overview#where-has-snowex-been","position":7},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Snow Classification Coverage","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#snow-classification-coverage","position":8},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Snow Classification Coverage","lvl2":"Data Coverage"},"content":" Thanks to Sturm and Liston 2021 (and 1995), we have a global seasonal snow classification system. This is a vital mission planning tool for remote sensing snow studies. Revised from inception, the snow classification system offers improved utility of the climatological snow classes due to improved (much higher) resolution (300 m over North America). This data set can be found at NSIDC and downloaded at multiple resolutions.\n\n[NSIDC Global Seasonal-Snow Classification, Version 1](https://nsidc.org/data/NSIDC-0768/versions/1) \n\nCheck out [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml) to find out more \n    \n![](./content/01_snow-classes-sturm.png)\n**Figure 3.** Snow Classes across North America at 300 m (Sturm and Liston, 2021) \n\nAs part of the mission statement, SnowEx aims to quantify snow estimation uncertainty across a range of snow classes, terrain and vegetation types. This is important to determine what areas and time periods have high SWE uncertainty across the ensemble of instrument techniques.\n\n\nFigure 2. Map of the in situ field visits for the duration of SnowEx field campaigns (2017-2023). At this scale, points are overlapping, especially in the eastern Rocky Mountain region around Colorado. The total number of unique visits with recorded SWE are listed in the legend. Upper Right Bar chart of snow classes over the four SnowEx field campaign years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occurred in open areas such as meadows and clearings. The snow classification colors match those used in \n\nSturm and Liston, 2021. ![](./content/01_snow-classes-barchart.png)\n**Figure 2.** Bar chart of snow classes over the four SnowEx field campagin years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occured in open areas such as meadows and clearings. The snow classification colors match those used in [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml).   ![](./content/01_map-n-barchart.png)\n**Figure 2.** Bar chart of snow classes over the four SnowEx field campagin years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occured in open areas such as meadows and clearings. The snow classification colors match those used in [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml). \n\n","type":"content","url":"/notebooks/snowex-data-overview#snow-classification-coverage","position":9},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Recap","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#recap","position":10},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Recap","lvl2":"Data Coverage"},"content":"SnowEx campaigns are structured based on the objectives set out in the SnowEx Science Plan. Some of those objectives are meet by conducting an all hands-on, short and intense observation period (IOP), while others are addressed by studying the evolution of the snowpack over a much longer time series (TS) style campaign.\n\nThe coincident field and airborne campaigns are designed to directly respond to the current knowledge gaps in remote sensing of seasonal snow, thus the participant-driven SnowEx effort targets a range of snow classes, terrain and vegetation types.\n\n","type":"content","url":"/notebooks/snowex-data-overview#recap","position":11},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"References","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#references","position":12},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"References","lvl2":"Data Coverage"},"content":"SnowEx Experimental Plans: 2017, \n\n2020, \n\n2021, \n\n2023\n\nSnowEx Science Plan\n\nSturm and Liston, 2021","type":"content","url":"/notebooks/snowex-data-overview#references","position":13},{"hierarchy":{"lvl1":"SnowExSQL Database"},"type":"lvl1","url":"/notebooks/snowexsql-database","position":0},{"hierarchy":{"lvl1":"SnowExSQL Database"},"content":"Tutorial Author Micah’: \n\nMicah Sandusky\n\nTutorial Author Micah_o: \n\nMicah Johnson\n\nSnowEx has introduced a unique opportunity to study SWE in a way that’s unprecedented, but with more data comes new challenges. \n<img src=\"https://snowexsql.readthedocs.io/en/latest/_images/gallery_overview_example_12_0.png\" alt=\"Grand Mesa Overview\" width=\"1000px\"> \n\nThe SnowEx database is a resource that shortcuts the time it takes to ask cross dataset questions\n\nStandardizing diverse data\n\nCross referencing data\n\nProvenance!\n\nAdded GIS functionality\n\nConnect w/ ArcGIS or QGIS!\n\nCITABLE\n\n2022- Estimating snow accumulation and ablation with L-band interferometric synthetic aperture radar (InSAR)\n\n2024 - Thermal infrared shadow-hiding in GOES-R ABI imagery: snow and forest temperature observations from the SnowEx 2020 Grand Mesa field campaign","type":"content","url":"/notebooks/snowexsql-database","position":1},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"What’s in it?"},"type":"lvl3","url":"/notebooks/snowexsql-database#whats-in-it","position":2},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"What’s in it?"},"content":"Snow pits - Density, hardness profiles, grain types + sizes\n\nManual snow depths - TONS of depths (Can you say spirals?)\n\nSnow Micropenetrometer (SMP) profiles - (Subsampled to every 100th)\n\nSnow depth + SWE rasters from ASO Inc.\n\nGPR\n\nPit site notes\n\nCamera Derived snow depths\n\nSnow off DEM from USGS 3DEP\n\nAnd almost all the associated metadata","type":"content","url":"/notebooks/snowexsql-database#whats-in-it","position":3},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Technically, what is it?"},"type":"lvl3","url":"/notebooks/snowexsql-database#technically-what-is-it","position":4},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Technically, what is it?"},"content":"PostgreSQL database\n\nPostGIS extension\n\nSupports vector and raster data\n\nAnd a host of GIS operations\n\nAND NOW WITH API!","type":"content","url":"/notebooks/snowexsql-database#technically-what-is-it","position":5},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"So what’s the catch?","lvl3":"Technically, what is it?"},"type":"lvl4","url":"/notebooks/snowexsql-database#so-whats-the-catch","position":6},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"So what’s the catch?","lvl3":"Technically, what is it?"},"content":"New tech can create barriers...\n\n","type":"content","url":"/notebooks/snowexsql-database#so-whats-the-catch","position":7},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"TL;DR Do less wrangling, do more crunching.","lvl3":"Technically, what is it?"},"type":"lvl4","url":"/notebooks/snowexsql-database#tl-dr-do-less-wrangling-do-more-crunching","position":8},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"TL;DR Do less wrangling, do more crunching.","lvl3":"Technically, what is it?"},"content":"\n\n","type":"content","url":"/notebooks/snowexsql-database#tl-dr-do-less-wrangling-do-more-crunching","position":9},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I get at this magical box of data ?"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-do-i-get-at-this-magical-box-of-data","position":10},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I get at this magical box of data ?"},"content":"SQL\n\nsnowexsql \n\n← 😎","type":"content","url":"/notebooks/snowexsql-database#how-do-i-get-at-this-magical-box-of-data","position":11},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Welcome to API Land","lvl3":"How do I get at this magical box of data ?"},"type":"lvl4","url":"/notebooks/snowexsql-database#welcome-to-api-land","position":12},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Welcome to API Land","lvl3":"How do I get at this magical box of data ?"},"content":"\n\nfrom snowexsql.api import PointMeasurements\n\ndf = PointMeasurements.from_filter(type=\"depth\", instrument='pit ruler', limit=100)\ndf.plot(column='value', cmap='jet', vmin=10, vmax=150)\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#welcome-to-api-land","position":13},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Old Ways / Advanced Users","lvl3":"How do I get at this magical box of data ?"},"type":"lvl4","url":"/notebooks/snowexsql-database#old-ways-advanced-users","position":14},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Old Ways / Advanced Users","lvl3":"How do I get at this magical box of data ?"},"content":"Advanced queries can be made using SQL or SQAlchemy under the hood.\n\nSee previous presentations\n\nEngine objects, session objects, and a crash course in ORM, oh my!\n\nHackweek 2021\n\nHackweek 2022\n\n","type":"content","url":"/notebooks/snowexsql-database#old-ways-advanced-users","position":15},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"How is the Database Structured?"},"type":"lvl2","url":"/notebooks/snowexsql-database#how-is-the-database-structured","position":16},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"How is the Database Structured?"},"content":"The goal of the database is to hold as much of the SnowEx data in one place and make it easier to\ndo research with. With that in mind follow the steps below to see how the the data base is structured.\n\n","type":"content","url":"/notebooks/snowexsql-database#how-is-the-database-structured","position":17},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Where do datasets live (i.e. tables)?","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#where-do-datasets-live-i-e-tables","position":18},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Where do datasets live (i.e. tables)?","lvl2":"How is the Database Structured?"},"content":"Data in the database lives in 1 of 4 places.\n\n\n\nLayout of the database tables\n\nThe 4th table is a table detailing the site information. Lots and lots of metadata for which the API has not been written yet.\n\nSo how does this look in python?\n\nfrom snowexsql.api import PointMeasurements, LayerMeasurements, RasterMeasurements\n\n","type":"content","url":"/notebooks/snowexsql-database#where-do-datasets-live-i-e-tables","position":19},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How are tables structured?","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-are-tables-structured","position":20},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How are tables structured?","lvl2":"How is the Database Structured?"},"content":"Each table consists of rows and columns. Below are the available columns!\n\n# Import the class reflecting the points table in the db\nfrom snowexsql.api import PointMeasurements as measurements\n\n# Grab one measurement to see what attributes are available\ndf = measurements.from_filter(type=\"depth\", limit=1)\n\n# Print out the results nicely\nprint(\"These are the available columns in the table:\\n \\n* {}\\n\".format('\\n* '.join(df.columns)))\n\nTry this: Using what we just did, but swap out PointMeasurements for LayerMeasurements.\n\nQuestion: Did you collect any data? What is it? What table do you think it would go in?\n\nFor more detail, checkout the readthedocs page on \n\ndatabase structure to see how data gets categorized.\n\n","type":"content","url":"/notebooks/snowexsql-database#how-are-tables-structured","position":21},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#bonus-step-learning-to-help-yourself","position":22},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowexsql has a host of resources for you to  help your self. First when you are looking for something be sure to check the snowexsql’s docs.\nThere you will find notes on the database structure. datasets, and of course our new API!","type":"content","url":"/notebooks/snowexsql-database#bonus-step-learning-to-help-yourself","position":23},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Usage/Examples","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl4","url":"/notebooks/snowexsql-database#database-usage-examples","position":24},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Usage/Examples","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowexsql Code\n\nsnowexsql Documentation","type":"content","url":"/notebooks/snowexsql-database#database-usage-examples","position":25},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Building/Notes","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl4","url":"/notebooks/snowexsql-database#database-building-notes","position":26},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Building/Notes","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowex_db Code\n\nsnowex_db Documentation\n\n","type":"content","url":"/notebooks/snowexsql-database#database-building-notes","position":27},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap","position":28},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"How is the Database Structured?"},"content":"You just explored the database structure and discussed how they differ.\n\nYou should know:\n\nWhich table a dataset might live in\n\nWhat columns you can work with (or how to get the available columns)\n\nSome resources to begin helping yourself.\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!\n\n","type":"content","url":"/notebooks/snowexsql-database#recap","position":29},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Forming Queries through the API!"},"type":"lvl2","url":"/notebooks/snowexsql-database#forming-queries-through-the-api","position":30},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Forming Queries through the API!"},"content":"Get familiar with the tools available for querying the database. The simplest way is to use the api classes\n\nsnowexsql.api.PointMeasurements\n\nsnowexsql.api.LayerMeasurements\n\nEach class has to very useful functions\n\nfrom_filter\n\nfrom_area","type":"content","url":"/notebooks/snowexsql-database#forming-queries-through-the-api","position":31},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_filter","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#useful-function-from-filter","position":32},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_filter","lvl2":"Forming Queries through the API!"},"content":"Use the from filter function to find density profiles\n\n# Import in our two classes to access the db\nfrom snowexsql.api import LayerMeasurements\nfrom datetime import datetime \n\n# Find some density pit measurements at the Boise site in december 2019.\ndf = LayerMeasurements.from_filter(\n    type=\"density\",\n    site_name=\"Boise River Basin\",\n    date_less_equal=datetime(2020, 1, 1),\n    date_greater_equal=datetime(2019, 12, 1),\n)\n\n# Plot Example!\ndf.plot()\n\n# Show off the dataframe\ndf\n\n# Analysis Example - Find the bulk density \ndf['value'] = df['value'].astype(float)\nprint(df[['site_id', 'value']].groupby(by='site_id').mean())\n\n","type":"content","url":"/notebooks/snowexsql-database#useful-function-from-filter","position":33},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_area","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#useful-function-from-area","position":34},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_area","lvl2":"Forming Queries through the API!"},"content":"Find specific surface area within a certain distance of a pit.\n\n# Import our api class\nfrom snowexsql.api import LayerMeasurements\nfrom datetime import datetime\nimport geopandas as gpd \n\n# import some gis functionality \nfrom shapely.geometry import Point \n\n# Find some SSA measurements within a distance of a known point\npnt = Point(740820.624625,4.327326e+06)\ndf = LayerMeasurements.from_area(pt=pnt, crs=26912, buffer=500,\n    type='specific_surface_area')\n\n# plot up the results\nax = df.plot()\n\n# plot the site so we can see how close everything is.\nsite = gpd.GeoDataFrame(geometry=[pnt], crs=26912)\nsite.plot(ax=ax, marker='^', color='magenta')\n\n# show off the dataframe\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#useful-function-from-area","position":35},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-do-i-know-what-to-filter-on","position":36},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"content":"We got tools for that! Each class has a host of functions that start with all_* these function return the unique value in that column.\n\nall_types - all the data types e.g. depth, swe, density...\n\nall_instruments - all instruments available in the table\n\nall_dates - all dates listed in the table\n\nall_site_names - all the site names available in the table. e.g. Grand Mesa\n\nfrom snowexsql.api import PointMeasurements\n\n# Instantiate the class to use the properties!\nmeasurements = PointMeasurements()\n\n# Get the unique data names/types in the table\nresults = measurements.all_types\nprint('Available types = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique instrument in the table\nresults = measurements.all_instruments\nprint('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique dates in the table\nresults = measurements.all_dates\nprint('\\nAvailable Dates = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique site names in the table\nresults = measurements.all_site_names\nprint('\\nAvailable sites = {}'.format(', '.join([str(r) for r in results])))\n\n","type":"content","url":"/notebooks/snowexsql-database#how-do-i-know-what-to-filter-on","position":37},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"More specific filtering options","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#more-specific-filtering-options","position":38},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"More specific filtering options","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"content":"Sometimes we need a bit more filtering to know more about what I can filter on. Questions like “What dates was the SMP used?” are a bit more complicated than “Give me all the dates for snowex”\n\nThe good news is, we have tool for that! from_unique_entries is your friend!\n\n# import layer measurements\nfrom snowexsql.api import LayerMeasurements\n\n# Query dates where SMP was used\nLayerMeasurements.from_unique_entries(['date'], instrument='snowmicropen')\n\n","type":"content","url":"/notebooks/snowexsql-database#more-specific-filtering-options","position":39},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#query-nuances","position":40},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"","type":"content","url":"/notebooks/snowexsql-database#query-nuances","position":41},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Limit size","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#limit-size","position":42},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Limit size","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"To avoid accidental large queries, we have added some bumper rails. By default if you ask for more than 1000 records then an error will pop up unless you explicitly say you want more.\n\nTry This: Do a large query. Run the code block below without the limit keyword argument (“kwarg”):\n\n# Import PointMeasurements\nfrom snowexsql.api import PointMeasurements\n\n# Query db using a vague filter or on a huge dataset like GPR but remove the limit kwarg\ndf = PointMeasurements.from_filter(type='two_way_travel', limit=100)\n\n# Show the dataframe\ndf\n\n\n\nWe have added this on the db to allow you to explore without accidentally pulling the entire SnowEx universe down. If you know you want a large query (defined as > 1000) then use the limit = #### option in the from_filter or from_area function.\n\nWarning - It is better to filter using other things besides the limit because the limit is not intelligent. It will simply limit the query by the order of entries that were submitted AND fits your filter. So if you encounter this then consider how to tighten up the filter.","type":"content","url":"/notebooks/snowexsql-database#limit-size","position":43},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"List of Criteria","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#list-of-criteria","position":44},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"List of Criteria","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"You can use lists in your requests too!\n\n# Import layer measurements\nfrom snowexsql.api import LayerMeasurements\n\n# Grab all the data that used the one of these instruments (hint hint SSA)\nssa_instruments = [\"IS3-SP-15-01US\", \"IRIS\",  \"IS3-SP-11-01F\"]\n\n# Query the DB (throw a limit for safety)\nLayerMeasurements.from_filter(instrument=ssa_instruments, limit=100)\n\n","type":"content","url":"/notebooks/snowexsql-database#list-of-criteria","position":45},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Greater than or Less than","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#greater-than-or-less-than","position":46},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Greater than or Less than","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"Sometimes we want to isolate certain ranges of value or even dates. The greater_equal and less_equal terms can be added on to value or dates.\n\ndate_greater_equal\n\ndate_less_equal\n\nvalue_greater_equal\n\nvalue_less_equal\n\n# Import the point measurements class\nfrom snowexsql.api import PointMeasurements\n\n# Filter values > 100 cm from the pulse ecko GPR\ndf = PointMeasurements.from_filter(value_greater_equal=100, type='depth', instrument='pulse EKKO Pro multi-polarization 1 GHz GPR', limit=100)\n\n# Show off the dataframe\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#greater-than-or-less-than","position":47},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap-1","position":48},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Forming Queries through the API!"},"content":"You just came in contact with the new API tools. We can use each API class to pull from specific tables and filter the data.\nYou should know:\n\nHow to build queries using from_filter, from_area, from_unique_entries\n\nDetermine what values to filter on\n\nManage the limit error\n\nFiltering on greater and less than\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!\n\n","type":"content","url":"/notebooks/snowexsql-database#recap-1","position":49},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl2","url":"/notebooks/snowexsql-database#exercise-visualize-a-manual-depth-spiral","position":50},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"During the SnowEx campaigns a TON of manual snow depths were collected, past surveys for hackweek showed an overhelming interest in the manual\nsnow depths dataset. This tutorial shows how easy it is to get at that data in the database while learning how to build queries\n\nGoal: Visualize a small subset of snow depth, ideally a full spiral (mostly cause they are cool!)\n\nApproach:\n\nDetermine the necessary details for isolating manual depths\n\nFind a pit where many spirals were done.\n\nBuffer on the pit location and grab all manual snow depths\n\n","type":"content","url":"/notebooks/snowexsql-database#exercise-visualize-a-manual-depth-spiral","position":51},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl3","url":"/notebooks/snowexsql-database#process","position":52},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\nfrom snowexsql.api import LayerMeasurements\ndata_type = 'depth'\n\n","type":"content","url":"/notebooks/snowexsql-database#process","position":53},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 1: Find a pit of interest","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-1-find-a-pit-of-interest","position":54},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 1: Find a pit of interest","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# Pick the first one we find\nsite_id = LayerMeasurements().all_site_ids[0]\n\n# Query the database, we only need one point to get a site id and its geometry\nsite_df = LayerMeasurements.from_filter(site_id=site_id, limit=1)\n\n# Print it out \nsite_df\n\n","type":"content","url":"/notebooks/snowexsql-database#step-1-find-a-pit-of-interest","position":55},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 2: Collect Snow Depths","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-2-collect-snow-depths","position":56},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 2: Collect Snow Depths","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# We import the points measurements because snow depths is a single value at single location and date\nfrom snowexsql.api import PointMeasurements \n\n# Filter the results to within 100m within the point from our pit\ndf = PointMeasurements.from_area(pt=site_df.geometry[0], type=data_type, buffer=200)\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#step-2-collect-snow-depths","position":57},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 3: Plot it!","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-3-plot-it","position":58},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 3: Plot it!","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# Get the Matplotlib Axes object from the dataframe object, color the points by snow depth value\nax = df.plot(column='value', legend=True, cmap='PuBu')\nsite_df.plot(ax=ax, marker='^', color='m')\n\n# Use non-scientific notation for x and y ticks\nax.ticklabel_format(style='plain', useOffset=False)\n\n# Set the various plots x/y labels and title.\nax.set_title(f'{len(df.index)} Manual Snow depths collected at {site_id}')\nax.set_xlabel('Easting [m]')\nax.set_ylabel('Northing [m]');\n\n\nTry This:\n\nA. Go back and add a filter to reduce to just one spiral. What would you change to reduce this?\n\nB. Try to filtering to add more spirals. What happens?","type":"content","url":"/notebooks/snowexsql-database#step-3-plot-it","position":59},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap-2","position":60},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"You just plotted snow depths and reduce the scope of the data by using from_area on it\n\nYou should know:\n\nManual depths are neat.\n\nfilter using from area is pretty slick.\n\nWe can use LayerMeasurements to get site details easily.\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!","type":"content","url":"/notebooks/snowexsql-database#recap-2","position":61},{"hierarchy":{"lvl1":"Thermal Infrared"},"type":"lvl1","url":"/notebooks/thermal-ir-tutorial","position":0},{"hierarchy":{"lvl1":"Thermal Infrared"},"content":"Learning Objectives\n\nAt the conclusion of this tutorial, you will be able to:\n\nunderstand the differences between sources of thermal IR observations, the advantages and disadvantages of each, and types of research questions we can address with those observations\n\nvisualize point and raster thermal infrared datasets together, then compute error statistics between point and raster datasets\n\naccess and visualize airborne and satellite thermal infrared imagery, then scale imagery of different spatial resolutions for comparison\n\nDownload the sample datasets for this tutorial\n\nFor ease of access during the hackweek, sample files are available for download for running the command in the cell below. (See the bonus notebook “\n\nthermal​-ir​-data​-download​.ipynb” for more details about data access methods)\n\n# S3 base URL for tutorial data\nS3_BASE_URL = \"https://snowex-tutorials.s3.us-west-2.amazonaws.com/thermal-ir/\"\n\nImport the packages we’ll need for this tutorial\n\n# Import some general-purpose packages for handling different data structures\nimport numpy as np # for working with n-D arrays\nimport pandas as pd # for reading our csv data file and working with tabular data\n\n# Import matplotlib which we'll use for plotting images and graphs\nimport matplotlib.pyplot as plt\n\n# Import these packages for working with raster data\nimport xarray as xr # xarray lets us work with n-D arrays and labeled data, such as NetCDF files\nimport rioxarray # rioxarray provides capabilities of the rasterio package to xarray, letting us easily work with files such as GeoTIFFs\nimport fsspec\n\n# Import some packages for working with the SnowEx SQL database\nfrom snowexsql.db import get_db # Import the connection function from the snowexsql library\nfrom  snowexsql.data import SiteData # Import the table classes from our data module which is where our ORM classes are defined \nfrom datetime import datetime # Import some tools to build dates \nfrom snowexsql.conversions import query_to_geopandas # Import a useful function for plotting and saving queries! See https://snowexsql.readthedocs.io/en/latest/snowexsql.html#module-snowexsql.conversions\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial","position":1},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl2","url":"/notebooks/thermal-ir-tutorial#part-1-comparing-airborne-ir-imagery-with-ground-truth-observations","position":2},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"","type":"content","url":"/notebooks/thermal-ir-tutorial#part-1-comparing-airborne-ir-imagery-with-ground-truth-observations","position":3},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Airborne IR imagery","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#airborne-ir-imagery","position":4},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Airborne IR imagery","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"\n\nThe Naval Postgraduate School Twin Otter aircraft carried the UW APL thermal infrared imager and SWESARR instrument over Grand Mesa for SnowEx 2020. (Photo by Chris Chickadel)\n\nLoad IR image mosaic geotiff file\n\nairborne_ir = rioxarray.open_rasterio(S3_BASE_URL + 'SNOWEX2020_IR_PLANE_2020Feb08_mosaicked_2020-02-08T181915.tif')\n\nInspect the contents of the file we just opened\n\nairborne_ir\n\nairborne_ir.rio.crs # original CRS\n\nUnder the dataarray’s attributes we can see that we have a coordinate reference system already defined (crs) as \n\nEPSG:32612. We can also find this through da.rio.crs.\n\nHowever, we would like to reproject this into the common projection used by datasets on the SnowEx SQL database: \n\nEPSG:26912. We can do that using rioxarray’s \n\nreproject method (see an example \n\nhere).\n\nNOTE: Reprojections typically require a lot of processing time, so expect this cell to run for up to 1 minute.\n\nairborne_ir = airborne_ir.rio.reproject('EPSG:26912') # overwrite itself with new reprojected data array\n\nairborne_ir.rio.crs # new CRS\n\nNext, the filename shows us when this imagery was taken in UTC time, “2020-02-08T181915”\n\nWe can create a pandas timestamp variable in local time for comparison with other datasets:\n\n# Create a pandas timestamp, subtract 7 hours from UTC time to get local time (MST, UTC-7)\nairborne_ir_timestamp = pd.Timestamp(2020,2,8,18,19,15) - pd.Timedelta(hours=7)\n\nWhat color scale should we use for temperature?\n\nCommon advice you may have heard is to \n\navoid using rainbow color scales. Luckily \n\nmatplotlib gives us lots of options to choose from.\n\nWhen representing images of temperature, sometimes we want to pick colors that intuitively suggest temperature, such as the “magma” colorbar below. Other times we might be interested in both magnitude and sign, such as temperatures above or below melting point, in which case we could use something like “RdBu_r” below. I often pick simple greyscale, though less visually interesting, it is sometimes easier to pick out details in a continuous color scale like they “Greys” scale below. Make sure to include a labeled colorbar so your plot can be correctly interpreted!\n\nSome matplotlib color scale options (top to bottom): “magma”, “RdBu_r”, “Greys”\n\nPlot the airborne TIR image.\n\nWhat does our chosen colorscale tell us about temperatures here?\n\nWhat can we see?\n\nfig, ax = plt.subplots(figsize=(20,10)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10,ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\nax.set_title('Airborne TIR imagery of Grand Mesa, CO (Feb. 8, 2020)');\n\nImage interpretation\n\nWhat does our chosen colorscale tell us about temperatures here?\n\nThe colorbar on the right shows us that colder temperatures are represented with dark purple to black colors.\n\nWarmer temperatures are represented with lighter orange/yellow.\n\nWhat can we see?\n\nWe see a narrow stripe of imagery, this is a mosaic of individual camera images taken from the aircraft along a single flight line over Grand Mesa.\n\nOn the left (west) side of the image we see warmer but varied temperatures (yellow, orange, and purple), then an abrupt transition to uniformly cold temperatures (purple). This is the westernmost edge of the mesa where the snow on top is much colder than the lower elevation slopes of the mountain.\n\nContinuing to move from left (west) to right (east) we see patches of lighter colors, corresponding with warmer temperatures. These are patches of forest on the central and eastern portions of the mesa.\n\nFinally near the easternmost side of the image we see a very dark region that means it is much colder than the rest of the scene. What might this cold area or object be?\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#airborne-ir-imagery","position":5},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Bonus activity:","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#bonus-activity","position":6},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Bonus activity:","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"To help with our image interpretation, we can load visible imagery taken concurrently from the UW-APL airborne instrument. (Note: this example image is a single band black and white image, though we also have full RGB images available through NSIDC)\n\nairborne_vis = rioxarray.open_rasterio(S3_BASE_URL + 'SNOWEX2020_EO_PLANE_2020Feb08_mosaicked_2020-02-08T181915.tif')\n\n# note that the filename is identical with the same timestamp, but is labeled \"EO\" (electro-optical) rather than \"IR\" (infrared)\n\n# Also reproject the airborne visible imagery into EPSG:26912\nairborne_vis = airborne_vis.rio.reproject('EPSG:26912') # overwrite itself with new reprojected data array\n\nairborne_vis\n\nPlot the visible and infrared images side by side. This time, we will change the x and y axes limits (\n\nset_xlim, and \n\nset_ylim) to zoom in closer.\n\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(20,10), tight_layout=True)\n\n# Plot the IR imagery\nairborne_ir.plot(ax=axs[0], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('Airborne IR')\n\n# Plot the visible imagery\nairborne_vis.plot(ax=axs[1], \n                  cmap='Greys_r',\n                  cbar_kwargs={'label': 'DN'})\naxs[1].set_title('Airborne Vis')\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # give each axis a label\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_ylabel('Northings UTM 12N (m)')\n    \n    # set the axes limits, units in meters UTM Zone 12N (I chose these values by just looking at the plot above)\n    ax.set_xlim((735000, 760000)) # x axis limits\n    ax.set_ylim((4320000, 4325000)) # y axis limits\n\nImage interpretation\n\nThe visible imagery camera covers a slightly narrower width along the flight path than the IR cameras.\n\nNow what do you think the cold object on the eastern side of the image is?\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#bonus-activity","position":7},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Ground-based temperature observations","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#ground-based-temperature-observations","position":8},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Ground-based temperature observations","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"To provide a source of “ground truth” for the airborne and satellite thermal infrared images during the SnowEx 2020 Grand Mesa campaign, we can use ground-based snow surface temperature measurements. On February 5, 2020, we installed a thermal infrared radiometer pointing at the snow surface at snow pit #2S10 (left), and buried temperature sensors beneath the snow surface (right). These logged observations at 5-minute intervals until we removed the instrumentation a week later on February 12.\n\nSnow temperature sensor setup at snow pit 2S10: (left) tripod-mounted thermal ifrared radiometer to measure snow surface, (right) temperature probes to be buried beneath the snow surface.(Photos by Steven Pestana)\n\nWhat are some of the differences we might expect to see between the ground-based surface temperature data and the thermal IR images?\n\nEmissivity differences?\n\nOur ground-based radiometer was looking at 45 deg off nadir, versus nadir ASTER versus variable view angle airborne (snow emissivity changes off-nadir)\n\nDifferent TIR bandwidths (broad versus narrow)?\n\nGround-based radiometer: 8-14 μm, Airborne IR cameras: 8-14 μm, ASTER band 14: 10.95-11.65 µm\n\nDifferent atmospheric path lengths?\n\nFrom <1 meter, to 1 km, to entire atmospheric column (~100 km)\n\n“Point” versus area, and geolocation accuracy\n\nThe ground-based radiometer is measuring temperature for a spot (not really a single point) maybe ~1m in diameter. The airborne and ASTER imagers have spatial resolutions of 5m and 90m respectively. How confident are we in the geolocation of individual pixels in the imagery?\n\nWhere is snow pit 2S10?\n\nWe can find this information through a query to the SnowEx SQL database. First, set up the connection:\n\n# This is what you will use for all of hackweek to access the db\ndb_name = 'snow:hackweek@db.snowexdata.org/snowex'\n# Using the function get_db, we receive 2 ways to interact with the database\nengine, session = get_db(db_name)\n\nThen, query \n\nSiteData using \n\nfilter_by to find the entry with the site ID that we want (2S10). Preview the resulting geodataframe.\n\n# Form the query to receive site_id='2S10' from the sites table\nqry = session.query(SiteData).filter_by(site_id='2S10')\n\n# Convert the record received into a geopandas dataframe\nsiteData_df = query_to_geopandas(qry, engine)\n\n# Preview the resulting geopandas dataframe\nsiteData_df\n\nInspect of the geodatframe’s metadata\n\n# What is the coordinate reference system used here?\nsiteData_df.crs\n\n# Preview the geometry of this geodataframe, we should see that it is a POINT\nsiteData_df.geometry\n\nWe can now plot our snow pit site from this \n\ngeodataframe on top of the airborne IR image. (See more tips about plotting geodataframes \n\nhere)\n\nfig, ax = plt.subplots(figsize=(20,5)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10, ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\n# set the axes limits, units in meters UTM Zone 12N (I chose these values by just looking at the plot above)\nax.set_xlim((735000, 760000)) # x axis limits\nax.set_ylim((4320000, 4325000)) # y axis limits\n\n# set plot title\nax.set_title('Location of Snow Pit 2S10\\nwith Airborne TIR imagery of Grand Mesa, CO (Feb. 8, 2020)');\n\nChange the x and y axes limits (\n\nset_xlim, and \n\nset_ylim) to zoom in to our point of interest. In this case we can use \n\ndf​.geometry​.total​_bounds to get the x and y values that define the area our geometry takes up. (In this case we have a point so it will return just the point’s location, but this would work if we had a polygon as well)\n\nfig, ax = plt.subplots(figsize=(10,10)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10, ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n\n# set axes limits\nxmin, ymin, xmax, ymax = siteData_df.geometry.total_bounds # get the \"total bounds\" for our geometry\nax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\nax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\n# set plot title\nax.set_title('Location of Snow Pit 2S10\\nAirborne TIR imagery of Grand Mesa, CO (Feb. 8, 2020)');\n\nImport the snow temperature timeseries dataset\n\nThis data is \n\navailable through NSIDC, but we have already downloaded a local copy for this tutorial. (See the bonus notebook \n\nthermal​-ir​-data​-download​.ipynb for more details about data access methods)\n\nThe raw data file doesn’t include the column names, so we need to set the column headers following the dataset’s README file.\n\n!cat data/snow-temperature-README.txt\n\nCreate a list of column headers according to the readme above (for “GM1” which we can read was the datalogger at snowpit 2S10)\n\ncolumn_headers = ['table', 'year', 'doy', 'time', # year, day of year, time of day (local time, UTC-7)\n                  'rad_avg', 'rad_max', 'rad_min', 'rad_std', # radiometer surface temperature\n                  'sb_avg', 'sb_max', 'sb_min', 'sb_std', # radiometer sensor body temperature (for calibration)\n                  'temp1_avg', 'temp1_max', 'temp1_min', 'temp1_std', # temperature at 5 cm below snow surface\n                  'temp2_avg', 'temp2_max', 'temp2_min', 'temp2_std', #               10 cm\n                  'temp3_avg', 'temp3_max', 'temp3_min', 'temp3_std', #               15 cm\n                  'temp4_avg', 'temp4_max', 'temp4_min', 'temp4_std', #               20 cm\n                  'temp5_avg', 'temp5_max', 'temp5_min', 'temp5_std', #               30 cm\n                  'batt_a','batt_b', # battery voltage data\n                 ]\n\nOpen the file as a pandas data frame with \n\nread_csv\n\ndf = pd.read_csv(f'data/CR10X_GM1_final_storage_1.dat',\n                 header = None, names = column_headers) \n\n# After the filepath we specify header=None because the file doesn't contain column headers, \n# then we specify names=column_headers to give our own names for each column.\n\nWe need to do some formatting of the data fields, but we can preview what we just loaded fist\n\ndf.head() # show the first 5 rows of the dataframe\n\nData cleanup and formatting\n\n# Create a zero-padded time string (e.g. for 9:30 AM we are changing '930' into '0930')\ndf['time_str'] = [('0' * (4 - len(str(df.time[i])))) + str(df.time[i]) for i in range(df.shape[0])]\n\n# locate where rows have time_str == 2400 (midnight), and the whole column 'doy'\n# where we are at midnight, we need to shift one day forward\ndf.loc[df['time_str'] == '2400','doy'] += 1\n\n# and then change midnight from '2400' to '0000'\ndf.time_str.replace('2400', '0000', inplace=True)\n\nThis function lets us convert year and day of year (the format that the datalogger uses) to a pandas \n\ndatetime index:\n\ndef compose_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n                 seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    '''Compose a datetime object from various datetime components. This clever solution is from:\n        https://stackoverflow.com/questions/34258892/converting-year-and-day-of-year-into-datetime-index-in-pandas'''\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',\n             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\n# Create a datetime value from the date field and zero-padded time_str field, set this as our dataframe's index\ndf.index = compose_date(df['year'], \n                        days=df['doy'], \n                        hours=df['time_str'].str[:2],\n                        minutes=df['time_str'].str[2:])\n\n# Remove entries that are from table \"102\" (this contains datalogger battery information we're not interested in at the moment)\ndf = df[df.table != 102]\n\n# drop the columns we no longer need\ndf.drop(columns=['table','year','doy','time','time_str','batt_a','batt_b'], inplace=True)\n\nInspect the contents\n\ndf.head()\n\nMake a simple plot of the data. We are interested in the variable rad_avg which is the average temperature measured by the radiometer over each 5 minute period.\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n\n# set axes limits\nplt.ylim((-35,5))\nplt.xlim((pd.Timestamp(2020,2,5,11,0),pd.Timestamp(2020,2,12,16,0)))\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel(r'Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\nBonus plot: look at snow temperatures below the snow surface\n\nAdd the following to the above plot to add lines for temperature recorded at each depth interval below the snow surface:# plot the snow temperature at each depth it was measured\ndf.temp1_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.8,0.8,1], label='Ts @ -5 cm')\ndf.temp2_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.6,0.6,1], label='Ts @ -10 cm')\ndf.temp3_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.4,0.4,1], label='Ts @ -15 cm')\ndf.temp4_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.2,0.2,1], label='Ts @ -20 cm')\ndf.temp5_avg.plot(linestyle='-', marker='.', markersize=1, c=[0,0,1], label='Ts @ -30 cm')\n\nBut then we want to focus on the date/time when our IR image was from, so zoom in on Feb 8th by changing our plot’s \n\nxlim (using pandas \n\nTimestamps for the x axis values).\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n# set axes limits\nplt.ylim((-15,0)) # set some temperature y-axis limits for our plot\nplt.xlim((pd.Timestamp(2020,2,8,6,0),pd.Timestamp(2020,2,8,20,0))) # zoom in to daytime hours on Feb. 8, 2020\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel(r'Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#ground-based-temperature-observations","position":9},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Compare Airborne IR against the “ground truth” snow surface temperature","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#compare-airborne-ir-against-the-ground-truth-snow-surface-temperature","position":10},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Compare Airborne IR against the “ground truth” snow surface temperature","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"What is the temperature at this point in the airborne IR image?\n\nUse rioxarray’s \n\nclip function to extract the raster values that intersect with the point’s geometry. Because we have a point, this will return a single value for the pixel that overlaps this point.\n\n# clip using our point's geometry\nairborne_ir_point_temperature = airborne_ir.rio.clip(siteData_df.geometry)\n\n# preview the result\nairborne_ir_point_temperature\n\nOur result is a DataArray with a single data value at one set of x and y coordinates.\n\nPixel = Point ?\n\nShould we expect that the temperature measured for an image pixel would be the same for an individual point on the ground? The airborne imagery is at 5 meter spatial resolution, whereas our ground-based radiometer measured a spot maybe only ~1 m in diameter. Additionally, the geolocation of the airborne imagery is less accurate than 5 meters (closer to 10-15 meters) meaning that if we picked a single pixel to overlap our ground point, it may be the wrong pixel. Let’s instead look at the average and distribution of temperatures from the airborne imagery in an area around this point.\n\nAdd a 100 m radius \n\nbuffer around this point and get the temperature from the airborne imagery for a larger area around the snow pit.\n\nr = 100 # radius of the buffer in meters (this is in meters because we are working in a UTM coordinate reference system)\n\n# create the buffered geometry\nsiteData_df_buffer = siteData_df.buffer(r)\n\n# preview the resulting geometry, we should see this is a POLYGON now\nsiteData_df_buffer\n\nWhat does this polygon look like when we plot it on top of the airborne IR image now?\n\nfig, ax = plt.subplots(figsize=(10,10)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10, ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n\n# set the same axes limits as above\nax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\nax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\n# set plot title\nax.set_title('Location of Snow Pit 2S10, and 100 m radius buffer\\nwith ASTER Band 14 TIR imagery');\n\nClip the airborne IR raster again, now with our 200 m diameter polygon around the snow pit site.\n\n# clip using our new geometry\nairborne_ir_area_temperature = airborne_ir.rio.clip(siteData_df_buffer.geometry)\n\n# preview the result\nairborne_ir_area_temperature\n\nThe result of clipping is again a DataArray, this time though it is 40x40. We can plot this to see what it looks like, and to see the distribution of temperatures in the area.\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5), tight_layout=True)\n\n# plot the portion of the airborne TIR image we selected within the buffer area geometry\nairborne_ir_area_temperature.plot(cmap='magma', vmin=-7, vmax=-4, ax=ax[0], \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\nax[0].set_title('Airborne TIR image within\\n100 m radius buffer (2S10)\\n')\nax[0].set_aspect('equal')\nax[0].set_xlabel('Eastings UTM 12N (m)')\nax[0].set_ylabel('Northings UTM 12N (m)')\nax[0].set_xlim((xmin-150, xmax+150)) # x axis limits to +/- 150 m from our point's \"total bounds\"\nax[0].set_ylim((ymin-150, ymax+150)) # y axis limits to +/- 150 m from our point's \"total bounds\"\n\n# plot the location of the snow pit of interest to the plot\nsiteData_df.plot(ax=ax[0], color='c', marker='x')\n\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax[0], edgecolor='c', facecolor='none')\n\n# plot a histogram of image temperature data within the buffer area geometry\nairborne_ir_area_temperature.plot.hist(ax=ax[1],\n                                       color='k', \n                                       zorder=1, # use zorder to make sure this plots below the point\n                                       label='zonal $T_S$ histogram') \n\n# plot a vertical line for the single-pixel temperature we think is right at the snow pit\nax[1].axvline(airborne_ir_point_temperature, \n              color='c',linestyle='--',  # set color and style\n              zorder=2, # use zorder to make sure this plots on top of the histogram\n              label='$T_S$ single pixel') \n\n# plot a vertical line for the mean temperature within the buffer area geometry\nax[1].axvline(airborne_ir_area_temperature.mean(), \n              color='m',linestyle='--',  # set color and style\n              zorder=2, # use zorder to make sure this plots on top of the histogram\n              label='zonal mean $T_S$') \n\nax[1].legend(loc='upper left') # add a legend\nax[1].set_xlim((-7,-4)) # set xlim to same values as colorbar in image plot\nax[1].set_ylim((0,400)) # set ylim\nax[1].set_title('Snow surface temperatures\\nfrom Airborne TIR image (snow pit 2S10)')\nax[1].set_ylabel('Number of pixels');\n\nWhat do these plots tell us about the surface temperature around the snow pit as measured by the airborne IR cameras?\n\nIs the snow surface temperature more variable or uniform in this area?\n\nNote that we changed the minimum and maximum values of our colorbar!\n\nTry computing the standard deviation of temperatures in this area\n\nHow does our single pixel at the center compare with the rest of this area?\n\nTry taking the mean or median of all temperatures in the area and compare against the single point. What is the difference?\n\nSee \n\nLundquist et al., 2018 for an application of these methods with airborne and MODIS thermal infrared imagery\n\nPlot the airborne IR temperature data on top of the ground-based timeseries\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n# plot the mean airborne IR temperature from the area around the snow pit:\nplt.plot(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n         marker='o', c='r', linestyle='none',\n         label='Airborne IR mean $T_s$ for 100 m radius area')\n\n# plot an error bar showing the maximum and minimum airborne IR temperature around the snow pit\nplt.errorbar(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n             yerr=[[airborne_ir_area_temperature.mean()-airborne_ir_area_temperature.min()], \n                   [airborne_ir_area_temperature.max()-airborne_ir_area_temperature.mean()]],\n            capsize=3, fmt='none', ecolor='r',\n            label='Airborne IR $T_s$ range for 100 m radius area')\n\n\n# set axes limits\nplt.ylim((-15,0))\nplt.xlim((pd.Timestamp(2020,2,8,6,0),pd.Timestamp(2020,2,8,20,0))) # zoom in to daytime hours on Feb. 8, 2020\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel(r'Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\nContinuing with this analysis:\n\nIn the above plot we’ve added “error bars” to represent the full range of temperatures within the 100 m radius area around the snow pit.\n\nIs this a fair comparison?\n\nShould we make the area smaller based on our confidence in the image’s geolocation accuracy (10-15 m)?\n\nWhat is the difference between the “ground truth” data and the airborne IR data at this point in time?\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#compare-airborne-ir-against-the-ground-truth-snow-surface-temperature","position":11},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"type":"lvl2","url":"/notebooks/thermal-ir-tutorial#part-2-satellite-ir-remote-sensing-obsevations","position":12},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"content":"","type":"content","url":"/notebooks/thermal-ir-tutorial#part-2-satellite-ir-remote-sensing-obsevations","position":13},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#satellite-ir-imagery-with-aster","position":14},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"content":"Advantages of satellite IR images: We don’t always have airplanes with IR cameras flying around. Satellites can provide images at more regular intervals for long-term studies, and can see areas that are difficult to access on the ground or by air.\n\nWhat might be some diadvantages of satellite IR imagery compared to airborne IR imagery?\n\nLower spatial resolution because they’re further away from the Earth’s surface\n\nMixed pixel problem: with lower image resolutions, each pixel contains a more heterogeneous mixtures of surfaces and temperatures, meaning that temperature information is more blurred together\n\nWhat other disadvantages can you think of?\n\nHow might these differences (advantages or disadvantages) change the type of research questions you can investigate?\n\nFor this tutorial, we will look at an image from NASA’s \n\nAdvanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) imager, which is onboard the Terra satellite along with a MODIS imager. We can compare an ASTER IR image of Grand Mesa that was taken at roughly the same time as the airborne IR image. The ASTER image we will be working with is from ASTER’s \n\nband 14 which is sensitive to radiance in the 10.95-11.65 µm wavelength range.\n\nLoad an ASTER geotiff that we’ve downloaded for this tutorial, and inspect its contents.\n\naster_ir = rioxarray.open_rasterio(S3_BASE_URL + 'AST_L1T_00302082020180748_20200209065849_17218_ImageData14.tif')\n\nInspect the ASTER file we just opened\n\naster_ir\n\nWhat is its CRS?\n\naster_ir.rio.crs\n\n# Reproject this ASTER image into our common coordinate system\naster_ir = aster_ir.rio.reproject('EPSG:26912') # overwrite itself with new reprojected data array\n\nWhen was this image taken?\n\naster_ir_timestamp = pd.Timestamp(2020,2,8,18,7,48) - pd.Timedelta(hours=7)\n\nPlot the image. What are the units of the values on the colorbar?\n\naster_ir.plot()\n\nIt’s necessary to read the product documentation to understand what we are looking at here.\n\nWe are using the ASTER Level 1 Precision Terrain Corrected Registered At-Sensor Radiance (AST_L1T) product. \n\nProduct documentation is available here. Also helpful is the ** (AST_L1B) \n\nproduct documentation here from which AST_L1T is derived.\n\nThe values here are stored as scaled “digital number” (DN) values rather than the actual radiance values. The product documentation also provides information about how to unscale these values back into radiance units, and from radiance to brightness temperature, using laboratory calibrated constants.\n\nI’ve written two functions here to do this unit conversion for the five ASTER TIR bands in two steps (DN to radiance, radiance to brightness temperature). The function takes as its arguments the DN or radiance values respectively, and the band number (in our case band number 14, not the band wavelengths).\n\ndef tir_dn2rad(DN, band):\n    '''Convert AST_L1T Digital Number values to At-Sensor Radiance for the TIR bands (bands 10-14).'''\n    ucc = [6.822e-3, 6.780e-3, 6.590e-3, 5.693e-3, 5.225e-3]\n    rad = (DN-1.) * ucc[band-10]\n    return rad\n\ndef tir_rad2tb(rad, band):\n    '''Convert AST_L1T At-Sensor Radiance to Brightness Temperature [K] for the TIR bands (bands 10-14).'''\n    k1 = [3047.47, 2480.93, 1930.80, 865.65, 649.60]\n    k2 = [1736.18, 1666.21, 1584.72,1349.82, 1274.49]\n    tb = k2[band-10] /  np.log((k1[band-10]/rad) + 1)\n    return tb\n\nUse the above functions to convert from DN to radiance, radiance to brightness temperature (assume and emissivity of 1 for all surfaces, note that the airborne imagery also assumed emissivity of 1).\n\nThen convert from degeees K to degrees C by subtracting 273.15.\n\naster_band14_rad = tir_dn2rad( aster_ir, band=14 ) # convert from DN to radiance\naster_band14_tb_k = tir_rad2tb( aster_band14_rad, band=14 ) # convert from radiance to brightness temperature (K)\naster_band14_tb_c = aster_band14_tb_k - 273.15 # convert from K to C\n\n# Note that an \"invalid value encountered...\" warning may pop up here. This is because the above function tries to take the log of \"nan\" values that are outside the imaged area\n# we can ignore this warning and proceed\n\nDuring this unit conversion, xarray dropped the coordinate reference system attributes, so here we add the original crs to the new ASTER degrees celsius dataarray.\n\naster_band14_tb_c.rio.set_crs(aster_ir.rio.crs, inplace=True);\n\nPlot our image again, this time setting our colorscale and colorbar values. We should see “realistic” surface temperature values in degrees C now.\n\nfig, ax = plt.subplots(figsize=(15,10))\nax.set_aspect('equal')\naster_band14_tb_c.plot(ax=ax,\n                       cmap='magma', \n                       vmin=-20, vmax=20, # note that we have a wider temperature range on our colorbar for this image, -20 to +20 C instead of -10 to +10 C\n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\nImage interpretation\n\nWhat does our chosen colorscale tell us about temperatures here?\n\nWhat can we see?\n\nWhat do you think that cold linear feature across the image is? (Hint: think about the cold object we saw in the airborne IR image)\n\n\n\nPlot ASTER next to Airborne IR to see spatial resolution differences\n\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12,6), tight_layout=True)\n\naster_band14_tb_c.plot(ax=axs[0], \n                       cmap='magma', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('ASTER IR')\naxs[0].set_aspect('equal')\n\n\nairborne_ir.plot(ax=axs[1], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[1].set_title('Airborne IR')\naxs[1].set_aspect('equal')\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # plot the location of the snow pit of interest\n    siteData_df.plot(ax=ax, color='r', marker='x')\n    # plot the area of the buffer we made around the snow pit\n    siteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n    \n    # set axes labels and limits\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_xlim((735000, 760000))\n    ax.set_ylabel('Northings UTM 12N (m)')\n    ax.set_ylim((4320000, 4325000))\n\nMake another plot to zoom in on snow pit 2S10:\n\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,4), tight_layout=True)\n\naster_band14_tb_c.plot(ax=axs[0], \n                       cmap='magma', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('ASTER IR')\naxs[0].set_aspect('equal')\n\n\nairborne_ir.plot(ax=axs[1], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[1].set_title('Airborne IR')\naxs[1].set_aspect('equal')\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # plot the location of the snow pit of interest\n    siteData_df.plot(ax=ax, color='r', marker='x')\n    # plot the area of the buffer we made around the snow pit\n    siteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n    \n    # set axes labels\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_ylabel('Northings UTM 12N (m)')\n    # set the same axes limits as above\n    ax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\n    ax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\nGet the temperature of the ASTER pixel at the snow pit point using rioxarray \n\nclip.\n\n# First clip to the single point\naster_band14_tb_c_point_temperature = aster_band14_tb_c.rio.clip(siteData_df.geometry)\n\n# Second clip to the 100 m radius buffered area\naster_band14_tb_c_area_temperature = aster_band14_tb_c.rio.clip(siteData_df_buffer.geometry)\n\n# preview the result\naster_band14_tb_c_area_temperature\n\nHow many ASTER pixels in the area did we select?\n\nPlot the clipped area:\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5), tight_layout=True)\n\n# plot the portion of the airborne TIR image we selected within the buffer area geometry\naster_band14_tb_c_area_temperature.plot(cmap='magma', vmin=-7, vmax=-4, ax=ax[0], \n                 cbar_kwargs={'label': 'Temperature $\\degree C$'})\nax[0].set_title('ASTER TIR image within\\n100 m radius buffer (2S10)\\n')\nax[0].set_aspect('equal')\nax[0].set_xlabel('Eastings UTM 12N (m)')\nax[0].set_ylabel('Northings UTM 12N (m)')\nax[0].set_xlim((xmin-150, xmax+150)) # x axis limits to +/- 150 m from our point's \"total bounds\"\nax[0].set_ylim((ymin-150, ymax+150)) # y axis limits to +/- 150 m from our point's \"total bounds\"\n\n# plot the location of the snow pit of interest to the plot\nsiteData_df.plot(ax=ax[0], color='r', marker='x')\n\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax[0], edgecolor='r', facecolor='none')\n\n# plot a histogram of image temperature data within the buffer area geometry\naster_band14_tb_c_area_temperature.plot.hist(ax=ax[1], color='k');\nax[1].set_xlim((-7,-4)) # set xlim to same values as colorbar in image plot\nax[1].set_title('Histogram of temperatures from ASTER TIR image\\n100 m radius buffer (2S10)')\nax[1].set_ylabel('Number of pixels');\n\nPlot the ASTER IR temperature data on top of the ground-based timeseries and airborne IR temperature\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n# plot the mean airborne IR temperature from the area around the snow pit:\nplt.plot(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n         marker='o', c='r', linestyle='none',\n         label='Airborne IR mean $T_s$ for 100 m radius area')\n# plot an error bar showing the maximum and minimum airborne IR temperature around the snow pit\nplt.errorbar(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n             yerr=[[airborne_ir_area_temperature.mean()-airborne_ir_area_temperature.min()], \n                   [airborne_ir_area_temperature.max()-airborne_ir_area_temperature.mean()]],\n            capsize=3, fmt='none', ecolor='r',\n            )#label='Airborne IR $T_s$ range for 100 m radius area')\n\n# plot the mean ASTER IR temperature from the area around the snow pit:\nplt.plot(aster_ir_timestamp, aster_band14_tb_c_area_temperature.mean(),\n         marker='o', c='b', linestyle='none',\n        label='ASTER IR mean $T_s$ for 100 m radius area')\n# plot an error bar showing the maximum and minimum ASTER IR temperature around the snow pit\nplt.errorbar(aster_ir_timestamp, aster_band14_tb_c_area_temperature.mean(),\n             yerr=[[aster_band14_tb_c_area_temperature.mean()-aster_band14_tb_c_area_temperature.min()], \n                   [aster_band14_tb_c_area_temperature.max()-aster_band14_tb_c_area_temperature.mean()]],\n            capsize=3, fmt='none', ecolor='b',\n            )#label='ASTER IR $T_s$ range for 100 m radius area')\n\n\n# set axes limits\nplt.ylim((-15,0))\nplt.xlim((pd.Timestamp(2020,2,8,6,0),pd.Timestamp(2020,2,8,20,0))) # zoom in to daytime hours on Feb. 8, 2020\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel('Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#satellite-ir-imagery-with-aster","position":15},{"hierarchy":{"lvl1":"Thermal Infrared","lvl4":"Bonus activity: comparing two thermal IR rasters","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"type":"lvl4","url":"/notebooks/thermal-ir-tutorial#bonus-activity-comparing-two-thermal-ir-rasters","position":16},{"hierarchy":{"lvl1":"Thermal Infrared","lvl4":"Bonus activity: comparing two thermal IR rasters","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"content":"How does the finer spatial resolution airborne IR image compare with the coarser resolution ASTER IR image?\n\nOne way to compare these two images is to “upscale” the finer resolution airborne IR image to the same spatial resolution as ASTER.\n\nWe can use the rioxarray \n\nreproject_match function to do this. (\n\nalso see this example)\n\nNote that this function has \n\nmultiple options for how we want to resample the image data to the new spatial resolution. We will use resampling=5 which corresponds to taking the mean value.\n\nairborne_ir_repr = airborne_ir.rio.reproject_match(aster_ir, resampling=5)\n\nPreview the result.\n\nWhat are the image dimensions of the reprojected airborne IR image compared with the original?\n\nairborne_ir_repr\n\nPlot the ASTER image, original airborne IR image, and resampled airborne IR image next to each other to visualize these spatial resolution differences.\n\nfig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,4), tight_layout=True)\n\n# ASTER IR image\naster_band14_tb_c.plot(ax=axs[0], \n                       cmap='magma', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('ASTER IR')\naxs[0].set_aspect('equal')\n\n# Original airborne IR image\nairborne_ir.plot(ax=axs[1], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[1].set_title('Airborne IR')\naxs[1].set_aspect('equal')\n\n# Resampled airborne IR image\nairborne_ir_repr.plot(ax=axs[2], \n                      cmap='magma', \n                      vmin=-10, vmax=10, \n                      cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[2].set_title('Airborne IR resampled (mean)\\nto ASTER resolution (90m)')\naxs[2].set_aspect('equal')\n\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # plot the location of the snow pit of interest\n    siteData_df.plot(ax=ax, color='r', marker='x')\n    # plot the area of the buffer we made around the snow pit\n    siteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n    \n    # set axes labels\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_ylabel('Northings UTM 12N (m)')\n    # set the same axes limits as above\n    ax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\n    ax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\nFinally, compute the difference between the ASTER IR image and resampled airborne IR image, then plot the result:\n\n# Subtract reprojected airborne IR image from ASTER IR image\ndifference_image = aster_band14_tb_c - airborne_ir_repr\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6,5), tight_layout=True)\n\n# Difference image\ndifference_image.plot(ax=ax, \n                       cmap='RdBu_r', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': 'Temperature $\\degree C$'})\nax.set_title('Temperature Difference\\n(ASTER IR - Reprojected Airborne IR)\\n')\nax.set_aspect('equal')\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n# set the same axes limits as above\nax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\nax.set_ylim((ymin-1000, ymax+1000)); # y axis limits to +/- 1 km from our point's \"total bounds\"\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#bonus-activity-comparing-two-thermal-ir-rasters","position":17},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Next steps:"},"type":"lvl2","url":"/notebooks/thermal-ir-tutorial#next-steps","position":18},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Next steps:"},"content":"","type":"content","url":"/notebooks/thermal-ir-tutorial#next-steps","position":19},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Project ideas with these data:","lvl2":"Next steps:"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#project-ideas-with-these-data","position":20},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Project ideas with these data:","lvl2":"Next steps:"},"content":"Compare more snow pit temperature data (using snowexsql queries) against airborne and satellite IR imagery\n\nInvestigate spatial patterns of snow temperature from open areas to forested areas on the mesa, differences between ASTER and airborne IR imagery\n\nImproved data visualization using \n\nhvplot or something similar to create interactive plots of IR and/or visible imagery\n\nCompare thermal infrared and SAR imagery, or snow temperature observations and snow model outputs\n\nNote\n\nContact Steven Pestana during the hackweek for help accessing more airborne IR or visible imagery and related datasets","type":"content","url":"/notebooks/thermal-ir-tutorial#project-ideas-with-these-data","position":21},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Data access/download and pre-processing","lvl2":"Next steps:"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#data-access-download-and-pre-processing","position":22},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Data access/download and pre-processing","lvl2":"Next steps:"},"content":"See the jupyter notebook \n\nthermal​-ir​-data​-download​.ipynb for more details about data access methods through the NASA EarthData API, and pre-processing ASTER data into geotiff images.","type":"content","url":"/notebooks/thermal-ir-tutorial#data-access-download-and-pre-processing","position":23},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Additional learning resources:","lvl2":"Next steps:"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#additional-learning-resources","position":24},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Additional learning resources:","lvl2":"Next steps:"},"content":"NumPy learning resources:\n\nNumPy and the ndarray\n\nNumPy: the absolute basics for beginners\n\nNumPy: creating and manipulating numerical data\n\nAdvanced NumPy\n\nNumPy for MATLAB users\n\nXarray and \n\nrioxarray learning resources:\n\nIntroduction to xarray\n\nGeoHackWeek 2019 raster tools\n\nrasterio\n\ncartopy\n\nASTER resources:\n\nASTER L1T Scripts and Tutorials\n\nValidating ASTER Thermal Infrared Imaging for use in Snow Models\n\nOpen an airborne TIR mosaic NetCDF file\n\n# Open airborne TIR mosaic NetCDF file\nwith fsspec.open(S3_BASE_URL + 'SNOWEX2020_IR_PLANE_2020Feb08_mosaicked_APLUW.nc') as f:\n    ds = xr.open_dataset(f, decode_times=False)\n    ds = ds.load()\n\nInspect the dataset and its dimensions\n\n# Preview the dataset\nds\n\n# Take a look at the dimensions in the dataset\nds.dims\n\nThere is an extra dimension (“na”) that we will want to drop, we will want to rename some of the dims, assign coordinates to those dims, and add a coordinate reference system for plotting.\n\n# Drop the extra \"na\" dimension from E_UTM, N_UTM, and time\nds['E_UTM'] = ds['E_UTM'].isel(na=0, drop=True)\nds['N_UTM'] = ds['N_UTM'].isel(na=0, drop=True)\nds['time'] = ds['time'].isel(na=0, drop=True)\n\nRename the dimensions to some easier to use names\n\n# Rename dims\nds = ds.rename({\"pass\" : \"time\", \n                \"easting, x\" : \"easting\", \n                \"northing, y\" : \"northing\"})\n\nThis NetCDF file was generated in MATLAB, and the dates/times are in an epoch format. Use \n\nutcfromtimestamp() and \n\nisoformat() to convert and reformat into a more convenient format.\n\n# Decode matlab (epoch) format times\nutctime = [datetime.utcfromtimestamp(this_time).isoformat() for this_time in ds.time.values]\n\nAssign and then transpose coordinates in our dataset\n\n# Assign coordinates to the \"northing\",  \"easting\", and \"time\" dimensions\nds = ds.assign_coords({\"time\": utctime, \"northing\": ds.N_UTM, \"easting\": ds.E_UTM})\n\n# Transpose coords\nds = ds.transpose(\"time\", \"northing\", \"easting\")\n\nSet spatial dimensions then define which coordinate reference system the spatial dimensions are in\n\n# Write the coordinate reference system for the spatial dims with rioxarray\n# https://github.com/corteva/rioxarray/issues/379\nds.rio.write_crs('epsg:32612', inplace=True,\n                ).rio.set_spatial_dims('easting', 'northing', inplace=True,\n                                      ).rio.write_coordinate_system(inplace=True)","type":"content","url":"/notebooks/thermal-ir-tutorial#additional-learning-resources","position":25},{"hierarchy":{"lvl1":"Time-lapse Cameras"},"type":"lvl1","url":"/notebooks/timelapse-camera-tutorial","position":0},{"hierarchy":{"lvl1":"Time-lapse Cameras"},"content":"Learning Objectives\n\nAt the conclusion of this tutorial, you will...:\n\nKnow about all the time-lapse images available from the SnowEx 2017 and 2020 field campaigns\n\nView example time-lapse images from SnowEx 2020 and visualize their locations\n\nAccess snow depth measurements extracted from the SnowEx 2020 time-lapse images\n\nCompare snow depths from different SnowEx 2020 time-lapse cameras\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial","position":1},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#time-lapse-cameras-on-grand-mesa-during-snowex-field-campaigns","position":2},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"Time-lapse cameras were installed in both the SnowEx 2017 and 2020 field campaigns on Grand Mesa in similar locations.\n\nSnowEx 2017 Time-lapse Cameras\n\n28 Total Time-lapse Cameras\n\nCapturing the entire winter season (September 2016-June 2017)\n\nTaking 4 photos/day at 8AM, 10AM, 12PM, 2PM, 4PM\n\nAn orange pole was installed in front of 15 cameras for snow depth measurements\n\nTime-lapse images have been submitted to the NSIDC by Mark Raleigh with all the required metadata (e.g., locations, naming convention, etc.) for use.\n\nSnowEx 2020 Time-lapse Cameras\n\n29 Total Time-lapse Cameras\n\nCapturing the entire winter season (September 2019-June 2020)\n\nTaking 3 photos/day at 11AM, 12PM, 1PM or 2 photos/day at 11AM and 12PM\n\nA red pole was installed in front of each camera for snow depth measurements.\n\nCameras were installed on the east and west side of the Grand Mesa, across a vegetation scale of 1-9, using the convention XMR:\n\nX = East (E) or West (W) areas of the Mesa\n\nM = number 1-9, representing 1 (least vegetation) to 9 (most vegetation). Within each vegetation class, there were three sub-classes of snow depths derived from 2017 SnowEx lidar measurements.\n\nR = Replicate of vegetation assignment, either A, B, C, D, or E.\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#time-lapse-cameras-on-grand-mesa-during-snowex-field-campaigns","position":3},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl3","url":"/notebooks/timelapse-camera-tutorial#an-automated-way-of-viewing-and-mapping-time-lapse-photos","position":4},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"\n\nFirst, we will procedurally import the necessary packages to access the data. To access the snow depths at each camera station, we will use the SnowEx database (snowexsql) to access the depths as PointMeasurements.\n\nfrom snowexsql.api import PointMeasurements\n\n# Import information for all point measurement types\nmeasurements = PointMeasurements()\n\n# List unique instruments\nresults = measurements.all_instruments\nprint('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n\n# Packages for data analysis \nimport geopandas as gpd # geopandas library for data analysis and visualization\nimport pandas as pd # pandas as to read csv data and visualize tabular data\nimport numpy as np # numpy for data analysis \n\n# Packages for data visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt # matplotlib.pyplot for plotting images and graphs\n\nplt.rcParams['figure.figsize']  = (10, 4) # figure size\nplt.rcParams['axes.titlesize']  = 14 # title size \nplt.rcParams['axes.labelsize']  = 12 # axes label size \nplt.rcParams['xtick.labelsize'] = 11 # x tick label size \nplt.rcParams['ytick.labelsize'] = 11 # y tick label size \nplt.rcParams['legend.fontsize'] = 11 # legend size \nmpl.rcParams['figure.dpi'] = 100\n\n# Query the database for camera-based snow depths\ncamera_depths = measurements.from_filter(\n    type=\"depth\",\n    site_name=\"Grand Mesa\",\n    instrument=\"camera\",\n    limit = 13371\n)\n\ncamera_depths.head()\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#an-automated-way-of-viewing-and-mapping-time-lapse-photos","position":5},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl4":"Plot the camera locations, using snow pit locations for reference.","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl4","url":"/notebooks/timelapse-camera-tutorial#plot-the-camera-locations-using-snow-pit-locations-for-reference","position":6},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl4":"Plot the camera locations, using snow pit locations for reference.","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"\n\ncamera_depths.explore(tooltip=['equipment','date','latitude','longitude','value','type','units'])\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#plot-the-camera-locations-using-snow-pit-locations-for-reference","position":7},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Viewing the time-lapse photos"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#viewing-the-time-lapse-photos","position":8},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Viewing the time-lapse photos"},"content":"Thanks to the SnowEx database, we were able to easily access snow depths at each site. However, if we wish to examine the camera imagery, we will need to be a bit more creative.\n\nThe images are available through NSIDC, so we will use earthaccess to grab one of the image archives.\n\nEarthdata Login Authentication\n\nThis tutorial requires NASA Earthdata Login credentials to access NSIDC data.\n\nRegister for free if you don’t have an account\n\nOnce you have a username and password, you can either enter these in manually\nin the strategy=\"interactive\" mode (as coded below), or you can configure your\nlocal envrionment as follows:\n\nHere’s how to configure your local system for this to work:\n\nFirst time: Run earthaccess.login() without the strategy parameter to authenticate interactively\n\nThis creates a .netrc file for future sessions\n\nAfter making those changes, you should switch to strategy=\"environment\" below!\n\nimport earthaccess\n\n# Authenticate with Earthdata Login servers\ntry:\n    auth = earthaccess.login(strategy=\"environment\")\n    print(\"✓ Successfully authenticated with Earthdata Login\")\n# Search for camera imagery (only if authenticated)\n    granules = earthaccess.search_data(\n        doi = \"10.5067/WYRNU50R9L5R\"\n    )\n    print(granules[0].data_links())\nexcept Exception as e:\n    print(f\"⚠ Authentication failed: {e}\")\n    print(\"This is expected in automated builds. \\\n           Interactive users should run earthaccess.login() to authenticate.\")\n    granules = None\n\n# Load the files into memory (only if authenticated)\nif granules:\n    files = earthaccess.open(granules)\nelse:\n    print(\"⚠ Skipping remote data access - using local sample data instead\")\n    files = None\n\nLarge Downloads Ahead!\n\nLooking at the above data links, one will notice that the images are saved in .tar.gz format. We can read files through earthaccess in this format, but it will require some more work than simply downloading the data.\n\nUsers may download the files if they wish, but they are on the larger side (900+ Mb). If you wish to avoid large data downloads, then the below code will help with the process. However, be aware that the code can be rather memory intensive. If running this code on CryoCloud, then consider using larger memory allocations (4+ Gb).\n\nHere is how you would read in every file in the large tar.gz from earthaccess into memory:\n\nfile_content = files[0].read()\n\nSimplifying the download for learning purposes\n\nFor the sake of this tutorial we will create a synthetic tar.gz file with just three images we want to show here.\n\nfile_content = 'data/sample-data.tar.gz'\n\n\nimport tarfile\nfrom io import BytesIO\nfrom datetime import datetime\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\njpg_files = []\n# Open the tarfile remotely\nwith tarfile.open(file_content, mode=\"r:gz\") as tar:\n    # Identify contents of tarfile\n    members = tar.getmembers()\n\n    # Loop through tarfile contents for images of interest\n    fig, ax = plt.subplots(1,3, figsize=(12,12))\n    ax.flatten()\n    for member in members:\n        if member.name.lower().endswith('.jpg'):\n            jpg_file = tar.extractfile(member).read()\n            \n            # Estimate datetime from image\n            creationTime = member.mtime\n            dt_c = datetime.fromtimestamp(creationTime)\n            formatted_datetime = dt_c.strftime(\"%m/%d/%Y %H:%M\")\n\n            desired_datetimes = ['09/27/2016 15:13',\n                                 '11/08/2016 14:00',\n                                 '12/10/2016 14:00']\n            \n            # Append files with desired datetime\n            for idx,dt in enumerate(desired_datetimes):\n                if formatted_datetime == dt:\n                    image = Image.open(BytesIO(jpg_file))\n                    ax[idx].imshow(image)\n                    ax[idx].set_title(desired_datetimes[idx])\n                    ax[idx].axis('off')\n\n    plt.tight_layout()\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#viewing-the-time-lapse-photos","position":9},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Camera Applications"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#time-lapse-camera-applications","position":10},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Camera Applications"},"content":"Installing snow poles in front of time-lapse camera provides low-cost, long-term snow depth timeseries. Snow depths from the 2020 SnowEx time-lapse imagery have been manually processed with estimation of submission to the NSIDC database in summer 2021.\n\nThe snow depth is the difference between the number of pixels in a snow-free image and an image with snow, with a conversion from pixels to centimeters (Figure 1).\n\n\n\nFigure 1: Equation to extract snow depth from camera images. For each image, take the difference in pixels between the length of a snow-free stake and the length of the stake and multiply by length(cm)/pixel. The ratio can be found by dividing the full length of the stake (304.8 cm) by the length of a snow-free stake in pixels.\n\nSnow depth can be obtained in this manner manually, but it is now easier to determine the pixel size of the stakes through machine learning. For the sake of completeness, we will provide a brief example using the camera imagery above. Otherwise, users interested in using the camera imagery with machine learning are encouraged to check out the following resources by Katherine Breen and others:\n\nPublication on methodBreen C. M., W. R. Currier, C. Vuyovich, et al. 2024. “Snow Depth Extraction From Time‐Lapse Imagery Using a Keypoint Deep Learning Model.” Water Resources Research 60 (7): [10.1029/2023wr036682]\n\nGithub page for algorithm\n\nhttps://​github​.com​/catherine​-m​-breen​/snowpoles\n\nIn the example images above, we use the red pole in the fully snow-off and snow-on images for estimation.\n\nFor the snow-off image, the length of the red pole is 136 pixels. If we assume that the pole is 304.8 cm in length, then each pixel is approximately 2.24 cm in length.\n\nFor the snow-on image, the length of the red pole is 72 pixels, much shorter than the snow-off length. So, there is a ~64 pixel difference between the snow-on and snow-off lengths. Using the equation in Figure 1, we can calculate snow depth:\n\nDepth = 2.24 * (136-72) = 143.36 cm\n\nAcknowledgements: Anthony Arendt, Scott Henderson, Micah Johnson, Carrie Vuyovich, Ryan Currier, Megan Mason, Mark Raleigh\n\nAdditional ReferencesDickerson-Lange et al., 2017. Snow disappearance timing is dominated by forest effects on snow accumulation in warm winter climates of the Pacific Northwest, United States. Hydrological Processes. Vol 31, Issue 10. 13 February 2017. \n\nDickerson‐Lange et al. (2017)\n\nRaleigh et al., 2013. Approximating snow surface temperature from standard temperature and humidity data: New possibilities for snow model and remote sensing evaluation. Water Resources Research. Vol 49, Issue 12. 07 November 2013.  \n\nRaleigh et al. (2013)","type":"content","url":"/notebooks/timelapse-camera-tutorial#time-lapse-camera-applications","position":11},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning"},"type":"lvl1","url":"/notebooks/tls-data-access","position":0},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning"},"content":"This notebook is designed to take terrestrial laser scanner (TLS) data from the SnowEx Alaska Campaigns and derive snow depth. The TLS data is provided in both a raw point cloud format and a processed DEM format. For this example, we will be focusing on the TLS DEMs.\n\nThe TLS data is available through the cloud on NSIDC and can be accessed using the earthaccess package. For this tutorial, we’ll use pre-selected data hosted on S3 for simplicity, which allows the notebook to run without authentication. We’ll also show you how to access the full dataset using earthaccess if you want to explore more data on your own.\n\nThe first example will involve a single TLS image for simplicity, then we will have a second example that examines multiple TLS scans from the campaigns.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport rioxarray as rxr\nimport xarray as xr\n\nThe TLS data was gathered in Bonanza Creek near Fairbanks, AK in two months: October 2022 and March 2023. These months correspond to the snow-off and snow-on seasons, respectively. We will start by getting some sample snow-on TLS data from a single day.","type":"content","url":"/notebooks/tls-data-access","position":1},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl3":"Data Access"},"type":"lvl3","url":"/notebooks/tls-data-access#data-access","position":2},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl3":"Data Access"},"content":"For this tutorial, we’ll stream data directly from an S3 bucket, which doesn’t require authentication. If you want to access the full dataset from NSIDC using earthaccess, see the section at the end of this notebook.\n\n# Define S3 URLs for TLS data\nS3_BASE_URL = \"https://snowex-tutorials.s3.us-west-2.amazonaws.com/tls\"\n\n# Single scan example - snow-on (March 15, 2023) and snow-off (October 25, 2022)\n# Using CRS3 site which has data from both periods\nsnow_on_url = f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230315_CRS3_V01.0.tif\"\nsnow_off_url = f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221025_CRS3_V01.0.tif\"\n\nprint(\"✓ S3 URLs configured for streaming TLS data\")\n\nBecause the TLS data is available on-demand through the cloud, we do not need to download it. Instead, we can stream it directly with rioxarray!\n\n# Load a single TLS scan from S3\nsnow_on = rxr.open_rasterio(snow_on_url)\n\nsnow_on.rio.width\n\n# Visualize the snow-on data\nfig, ax = plt.subplots()\nsnow_on.plot(ax=ax, vmin=123, vmax=126,\n             cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")\n\nTwo things are noticeable from this TLS data:\n\nIt has a very high resolution (0.15 m).\n\nThe signal attenutates after ~60 m, so we have a small field of view.\n\nThis suggests that we will be able to obtain very fine-scale measurements of snow depth, but we will need scans from multiple locations to better characterize snow in Bonanza Creek.\n\nIn any case, let’s grab the snow-off data from the same location, and try to derive snow depth.\n\n# Load the corresponding snow-off scan from S3\nsnow_off = rxr.open_rasterio(snow_off_url)\n\nfig, ax = plt.subplots()\nsnow_off.plot(vmin=123, vmax=126,\n              cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")\n\nAlthough the snow-on/-off data look similar to each other, there are slight differences, meaning that we cannot perform a difference right away. We must first interpolate the data, ensuring that fill values are accounted for, then perform the difference.\n\n# Interpolate snow-on data onto the x/y grid of snow-off data\nsnow_on_interp = snow_on.interp(\n    x=snow_off.x,\n    y=snow_off.y,\n    kwargs={\"fill_value\": snow_on.attrs.get('_FillValue', np.nan)}\n)\n\n# Calculate the difference (snow depth)\ndifference = snow_on_interp - snow_off\n\n# Define fill values in data\nfill = snow_off.attrs.get('_FillValue', -9999.0)\n\n# Include only data that is not equal to the fill value\ndifference = difference.where((snow_off != fill) & (snow_on_interp != fill))\n\n# Plot snow depth over the TLS scene\nfig, ax = plt.subplots()\ndifference.plot(vmin=0, vmax=1.5,\n                cbar_kwargs={'label': \"Snow depth [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")\n\nAlthough not perfect, this provides a very reasonable snow depth DEM for the TLS data gathered in this location. If we want, we can perform basic statistics on the derived snow depths.\n\n# Calculate median snow depth over the scene\nmedian_depth = difference.where(difference>=0).median()\n\n# Make histogram plot of snow depth\nfig, ax = plt.subplots()\ndifference.where(difference>=0).plot.hist(ax=ax, bins=50)\nax.axvline(x=median_depth, color='black', linewidth=2, linestyle='--') # Median depth line\nax.set_xlim([0, 2.5])\nax.set_ylabel(\"Counts\")\nax.set_xlabel(\"Snow depth [m]\")\nax.set_title(' ')\nax.text(1, 8000, f'Median depth = {median_depth:.2f} m', fontsize=12)\n\n","type":"content","url":"/notebooks/tls-data-access#data-access","position":3},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl2":"Multiple Scans Example"},"type":"lvl2","url":"/notebooks/tls-data-access#multiple-scans-example","position":4},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl2":"Multiple Scans Example"},"content":"For the multiple scans example, we’ll work with data from several sites across Bonanza Creek. The files are pre-selected and hosted on S3 for convenient streaming without authentication.\n\n# Define file lists for multiple scan example\n# Using cross-section (CRS) sites and control sites (DEC, CRE) that have both snow-on and snow-off data\nsnow_on_files = [\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230313_CRS1_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230315_CRS2_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230315_CRS3_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230314_CRS4_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230310_CRS5_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230310_CRS6_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230314_CRS7_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_N_20230316_DEC_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20230315_CRE_V01.0.tif\",\n]\n\nsnow_off_files = [\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221026_CRS1_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221026_CRS2_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221025_CRS3_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221025_CRS4_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221025_CRS5_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221024_CRS6_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221024_CRS7_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_N_20221023_DEC_V01.0.tif\",\n    f\"{S3_BASE_URL}/SNEX23_BCEF_TLS_SW_20221027_CRE_V01.0.tif\",\n]\n\nprint(f\"Found {len(snow_on_files)} snow-on files\")\nprint(f\"Found {len(snow_off_files)} snow-off files\")\n\n# Create list of snow-on DataArrays by streaming from S3\nsnow_on_rasters = [rxr.open_rasterio(f) for f in snow_on_files]\n\n# Create list of snow-off DataArrays\nsnow_off_rasters = [rxr.open_rasterio(f) for f in snow_off_files]\n\nprint(f\"Loaded {len(snow_on_rasters)} snow-on rasters\")\nprint(f\"Loaded {len(snow_off_rasters)} snow-off rasters\")\n\nTo make the final plot of this example cleaner, we will assign each TLS scan a label based on the site ID at Bonanza Creek.\n\nsnon_site_ids = []\nsnoff_site_ids = []\n\n# Get site IDs for each snow-on file from URL\nfor url in snow_on_files:\n    # Extract filename from URL\n    filename = url.split('/')[-1]\n    # Use regex to extract the site ID from filename, given pattern _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', filename)\n    if m:\n        snon_site_ids.append(m.group(2))\n    else:\n        snon_site_ids.append(\"unknown\")\n\n# Get site IDs for each snow-off file\nfor url in snow_off_files:\n    filename = url.split('/')[-1]\n    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', filename)\n    if m:\n        snoff_site_ids.append(m.group(2))\n    else:\n        snoff_site_ids.append(\"unknown\")\n\nprint(\"Snow-on site IDs:\", snon_site_ids)\nprint(\"Snow-off site IDs:\", snoff_site_ids)\n\n# Add site ID to attributes of DataArrays\nfor r, site in zip(snow_on_rasters, snon_site_ids):\n    r.attrs['site_id'] = site\n\nfor r, site in zip(snow_off_rasters, snoff_site_ids):\n    r.attrs['site_id'] = site\n\n# Create dictionaries linking each DataArray to a site ID\nsnow_on_dict = {r.attrs['site_id']: r for r in snow_on_rasters}\nsnow_off_dict = {r.attrs['site_id']: r for r in snow_off_rasters}\n\nNow each TLS scan is linked to a site ID. However, we can see that the snow-on data has many more scans than the snow-off data. Because snow depth data is our priority, we will only consider snow-on scans that share a site ID with the snow-off data.\n\n# Determine site IDs with recorded data for both snow-off and snow-on season\ncommon_site_ids = sorted(set(snow_on_dict).intersection(snow_off_dict))\nprint(\"Common site IDs:\", common_site_ids)\n\n# Create lists of DataArrays for the common sites only\nsnow_on_paired = [snow_on_dict[sid] for sid in common_site_ids]\nsnow_off_paired = [snow_off_dict[sid] for sid in common_site_ids]\n\nNow that the site IDs are matched, deriving snow depth is the same as the first example, only with looping to make the calculation (and plotting) easier.\n\nsnow_depths = []\n# Interpolate DataArrays and derive snow depth, as before\nfor so, soff, site in zip(snow_on_paired, snow_off_paired, common_site_ids):\n    # Interpolate snow-on data onto the x/y grid of snow-off data\n    tmp_interp = so.interp(\n        x=soff.x,\n        y=soff.y,\n    )\n\n    tmp_diff = tmp_interp - soff\n    tmp_diff.attrs['site_id'] = site\n\n    tmp_diff = tmp_diff.where((tmp_diff[0]>0)&(tmp_diff[0]<=2))\n    snow_depths.append(tmp_diff)\n\n# Plot the derived snow depths in a 3x3 figure\nfig, axes = plt.subplots(3, 3, figsize=(12, 12))\naxes = axes.flatten()\n\nfor idx, data_array in enumerate(snow_depths):\n    data_array.plot(ax=axes[idx], vmin=0, vmax=2)\n    axes[idx].set_title(f\"{snow_depths[idx].attrs['site_id']}\")\n\nplt.tight_layout()\nplt.show()\n\nThat’s all there is to it! Some of the coverage is a bit sparse, and the depths over some sites look variable, but we have reasonable snow depths over 9 sites in Bonanza Creek. These could then be compared to other ground based efforts or airborne data to cross-calibrate observation methods.","type":"content","url":"/notebooks/tls-data-access#multiple-scans-example","position":5},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"type":"lvl3","url":"/notebooks/tls-data-access#working-with-the-full-dataset-using-earthaccess","position":6},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"content":"This tutorial uses a subset of TLS data hosted on S3 for convenience and to avoid authentication requirements in automated builds. If you want to access the complete dataset from NSIDC or explore additional dates and locations, you can use the earthaccess package.","type":"content","url":"/notebooks/tls-data-access#working-with-the-full-dataset-using-earthaccess","position":7},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Installation","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"type":"lvl4","url":"/notebooks/tls-data-access#installation","position":8},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Installation","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"content":"First, install earthaccess if you haven’t already:pip install earthaccess\n\norconda install -c conda-forge earthaccess","type":"content","url":"/notebooks/tls-data-access#installation","position":9},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Authentication and Data Access","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"type":"lvl4","url":"/notebooks/tls-data-access#authentication-and-data-access","position":10},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Authentication and Data Access","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"content":"import earthaccess\n\n# Authenticate with NASA Earthdata Login\n# On first use, you'll be prompted for your Earthdata credentials\n# or you can set EARTHDATA_USERNAME and EARTHDATA_PASSWORD environment variables\nauth = earthaccess.login(strategy=\"interactive\")\n\n# Search for TLS data by DOI and date range\nresults = earthaccess.search_data(\n    doi=\"10.5067/R466GRXNA61S\",  # SnowEx 2023 Bonanza Creek TLS dataset\n    temporal=('2022-10-01', '2023-03-31'),  # Full campaign period\n)\n\nprint(f\"Found {len(results)} granules\")\n\n# Option 1: Stream data directly (no download needed)\nfiles = earthaccess.open(results)\nsnow_data = rxr.open_rasterio(files[0])\n\n# Option 2: Download data locally\ndownloaded_files = earthaccess.download(results, \"./data\")","type":"content","url":"/notebooks/tls-data-access#authentication-and-data-access","position":11},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Key Points","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"type":"lvl4","url":"/notebooks/tls-data-access#key-points","position":12},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Key Points","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"content":"Authentication: You’ll need a free NASA Earthdata Login account (register at \n\nhttps://​urs​.earthdata​.nasa​.gov/)\n\nStrategy options:\n\nstrategy=\"interactive\" - Best for local development, prompts for credentials\n\nstrategy=\"environment\" - Reads credentials from environment variables (good for automated workflows)\n\nData streaming: earthaccess.open() allows you to work with data without downloading\n\nSearch options: You can filter by temporal range, bounding box, and other parameters","type":"content","url":"/notebooks/tls-data-access#key-points","position":13},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Dataset Information","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"type":"lvl4","url":"/notebooks/tls-data-access#dataset-information","position":14},{"hierarchy":{"lvl1":"Terrestrial Laser Scanning","lvl4":"Dataset Information","lvl3":"Working with the Full Dataset Using earthaccess","lvl2":"Multiple Scans Example"},"content":"Dataset: SnowEx 2023 Bonanza Creek Terrestrial Laser Scanning (TLS)\n\nDOI: 10.5067/R466GRXNA61S\n\nNSIDC Page: \n\nhttps://​nsidc​.org​/data​/snex23​_bcef​_tls\n\nTemporal Coverage: October 2022 (snow-off) and March 2023 (snow-on)\n\nSpatial Coverage: Bonanza Creek Experimental Forest, Alaska\n\nSites: Cross-section transects (CRS1-20), control sites (DEC, CRE, SPR)\n\nFor more information about the earthaccess package, visit: \n\nhttps://​earthaccess​.readthedocs​.io/","type":"content","url":"/notebooks/tls-data-access#dataset-information","position":15},{"hierarchy":{"lvl1":"UAVSAR"},"type":"lvl1","url":"/notebooks/uavsar-tutorial","position":0},{"hierarchy":{"lvl1":"UAVSAR"},"content":"\n\nDevelopers: Jack Tarricone, University of Nevada, Reno Zach Keskinen, Boise State University\n\nOther contributors: Ross Palomaki, Montana State UniversityNaheem Adebisi, Boise State University\n\n","type":"content","url":"/notebooks/uavsar-tutorial","position":1},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What is UAVSAR?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-is-uavsar","position":2},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What is UAVSAR?"},"content":"UAVSAR is a low frequency plane-based synthetic aperture radar. UAVSAR stands for “Uninhabited Aerial Vehicle Synthetic Aperture Radar”. It captures imagery using a L-band radar. This low frequency means it can penetrate into and through clouds, vegetation, and snow.\n\nfrequency (cm)\n\nresolution (rng x azi m)\n\nSwath Width (km)\n\nPolarizations\n\nLaunch date\n\nL-band 23\n\n1.8 x 5.5\n\n16\n\nVV, VH, HV, HH\n\n2007","type":"content","url":"/notebooks/uavsar-tutorial#what-is-uavsar","position":3},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"NASA SnowEx 2020 and 2021 UAVSAR Campaigns","lvl3":"What is UAVSAR?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#nasa-snowex-2020-and-2021-uavsar-campaigns","position":4},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"NASA SnowEx 2020 and 2021 UAVSAR Campaigns","lvl3":"What is UAVSAR?"},"content":"During the winter of 2020 and 2021, NASA conducted an L-band InSAR timeseries across the Western US with the goal of tracking changes in SWE. Field teams in 13 different locations in 2020, and in 6 locations in 2021, deployed on the date of the flight to perform calibration and validation observations.\n\nThe site locations from the above map along with the \n\nUAVSAR defined campaign name and currently processed pairs of InSAR images for each site. Note that the image pair count may contain multiple versions of the same image and may increase as more pairs of images are processed by JPL. Also note that the Lowman campaign name is the wrong state when searching.\n\nSite Location\n\nCampaign Name\n\nImage Pairs\n\nGrand Mesa\n\nGrand Mesa, CO\n\n13\n\nBoise River Basin\n\nLowman, CO\n\n17\n\nFrazier Experimental Forest\n\nFraser, CO\n\n16\n\nSenator Beck Basin\n\nIronton, CO\n\n9\n\nEast River\n\nPeeler Peak, CO\n\n4\n\nCameron Pass\n\nRocky Mountains NP, CO\n\n15\n\nReynold Creek\n\nSilver City, ID\n\n1\n\nCentral Agricultral Research Center\n\nUtica, MT\n\n2\n\nLittle Cottonwoody Canyon\n\nSalt Lake City, UT\n\n21\n\nJemez River\n\nLos Alamos, NM\n\n3\n\nAmerican River Basin\n\nEldorado National Forest, CA\n\n4\n\nSagehen Creek\n\nDonner Memorial State Park, CA\n\n4\n\nLakes Basin\n\nSierra National Forest, CA\n\n3\n\n","type":"content","url":"/notebooks/uavsar-tutorial#nasa-snowex-2020-and-2021-uavsar-campaigns","position":5},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Why would I use UAVSAR?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar","position":6},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Why would I use UAVSAR?"},"content":"UAVSAR works with low frequency radar waves. These low frequencies (< 3 GHz) can penetrate clouds and maintain coherence (a measure of radar image quality) over long periods. For these reasons, time series was captured over 13 sites as part of the winter of 2019-2020 and 2020-2021 for snow applications. Additionally the UAVSAR is awesome!\n\n","type":"content","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar","position":7},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Accessing UAVSAR Images"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#accessing-uavsar-images","position":8},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Accessing UAVSAR Images"},"content":"UAVSAR imagery can be downloaded from both the \n\nJPL and \n\nAlaska Satellite Facility. However both provide the imagery in a binary format that is not readily usable or readable by GIS software or python libraries.","type":"content","url":"/notebooks/uavsar-tutorial#accessing-uavsar-images","position":9},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#data-download-and-conversion-with-uavsar-pytools","position":10},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"uavsar_pytools (\n\nGithub) is a Python package developed out of work started at SnowEx Hackweek 2021. It nativiely downloads, formats, and converts this data in analysis ready rasters projected in WSG-84 Lat/Lon (\n\nEPSG:4326. The data traditionally comes in a binary format, which is not injestible by traditional geospatial analysis software (Python, R, QGIS, ArcGIS). It can download and convert either individual images - UavsarScene or entire collections of images - UavsarCollection.","type":"content","url":"/notebooks/uavsar-tutorial#data-download-and-conversion-with-uavsar-pytools","position":11},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Netrc Authorization","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#netrc-authorization","position":12},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Netrc Authorization","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"In order to download uavsar images you will need a \n\nnetrc file that contains your earthdata username and password. If you need to register for a NASA earthdata account use this \n\nlink. A netrc file is a hidden file, it won’t appear in the your file explorer, that is in your home directory and that programs can access to get the appropriate usernames and passwords. While you’ll have already done this for the Hackweek virtual machines, uavsar_pytools has a tool to create this netrc file on a local computer. You only need to create this file once and then it should be permanently stored on your computer.\n\n# ## Creating .netrc file with Earthdata login information\n# from uavsar_pytools.uavsar_tools import create_netrc\n\n# # This will prompt you for your username and password and save this\n# # information into a .netrc file in your home directory. You only need to run\n# # this command once per computer. Then it will be saved.\n# create_netrc()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#netrc-authorization","position":13},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a single UAVSAR interferogram scene","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-single-uavsar-interferogram-scene","position":14},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a single UAVSAR interferogram scene","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"You can find urls for UAVSAR images at the \n\nASF vertex website. Make sure to change the platform to UAVSAR and you may also want to filter to ground projected interferograms.\n\ntry:\n    from uavsar_pytools import UavsarScene\nexcept ModuleNotFoundError:\n    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n\n## This is the directory you want to download and convert the images in.\nwork_dir = '/tmp/uavsar_data'\n\n## This is a url you want to download. Can be obtained from vertex\nurl = 'https://datapool.asf.alaska.edu/INTERFEROMETRY_GRD/UA/\\\nlowman_23205_21009-004_21012-000_0007d_s01_L090_01_int_grd.zip'\n\n## clean = True will delete the binary and zip files leaving only the tiffs\nscene = UavsarScene(url = url, work_dir=work_dir, clean= True)\n\n## After running url_to_tiffs() you will download the zip file, unzip the binary \n## files, and convert them to geotiffs in the directory with the scene name in\n## the work directory. It also generate a .csv pandas dictionary of metadata.\n# scene.url_to_tiffs()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-single-uavsar-interferogram-scene","position":15},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a full UAVSAR collection","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-full-uavsar-collection","position":16},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a full UAVSAR collection","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"If you want to download and convert an entire Uavsar collection for a larger analysis you can use UavsarCollection. The collection names for the SnowEx campaign are listed in the table in the introduction. The UavsarCollection can download either InSAR pairs and PolSAR images.\n\nfrom uavsar_pytools import UavsarCollection\n## Collection name, the SnowEx Collection names are listed above. These are case \n## and space sensitive.\ncollection_name = 'Grand Mesa, CO'\n\n## Directory to save collection into. This will be filled with directory with \n## scene names and tiffs inside of them.\nout_dir = '/tmp/collection_ex/'\n\n## This is optional, but you will generally want to at least limit the date\n## range between 2019 and today.\ndate_range = ('2019-11-01', 'today')\n\n# Keywords: to download incidence angles with each image use `inc = True`\n# For only certain pols use `pols = ['VV','HV']`\n\ncollection = UavsarCollection(collection = collection_name, work_dir = out_dir, dates = date_range)\n\n## You can use this to check how many image pairs have at least one image in\n## the date range.\n\n#collection.find_urls()\n\n## When you are ready to download all the images run:\n\n# collection.collection_to_tiffs()\n\n## This will take a long time and a lot of space, ~1-5 gB and 10 minutes per \n## image pair depending on which scene, so run it if you have the space and time.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-full-uavsar-collection","position":17},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"UAVSAR Data Products"},"type":"lvl2","url":"/notebooks/uavsar-tutorial#uavsar-data-products","position":18},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"UAVSAR Data Products"},"content":"UAVSAR has a variety of different type of images:\n\nRepeat Pass Interferometric images contain:\n\nInSAR Data Types\n\nANN file (.ann): a text annotation file with metadata\n\nAMP files (.amp1 and .amp2): amplitude products for flight 1 and flight 2\n\nCOR files (.cor): coherence a measure of the noise level of the phase\n\nINT files (.int): wrapped phase difference between the two images\n\nUNW files (.unw): unwrapped phase difference between the two images\n\nINC files (.inc): incidence angle in radians\n\nHGT file  (.hgt): the DEM that was used in the InSAR processing\n\nUAVSAR repeat pass interferometry uses two images of the same place but separated in time. Phase changes between the two aquistions are calculated,  creating a wrapped interferogram. These phase changes are due to either the wave traveling a longer distance (ground movement or refraction) or change wave speeds (atmospheric water vapor and snow).\n\nGRD files (.grd): products projected to the ground in geographic coordinates (latitude, longitude)\nFinally all images can be in radar slant range or projected into WGS84. Images that have already been projected to ground range will have the extension .grd appended to their file type extension.\n\nFor instance a image of unwrapped phase that has not been georefenced would end with .unw, while one that was georeferenced would end with .unw.grd. You will generally want to use .grd files for most analysis.\n\nPolarimetric PolSAR images contain:\n\nANN file (.ann): a text annotation file with metadata\n\nPolsar file (HHVV.grd): all the rest of the files will be a pair of polarizations pushed together\n\nPolsar files have a pair of polarizations (VV, VH, HV, HH) combined in their file name. These files are the phase difference between polarization XX and polarization YY. For instance HHHV is the phase difference between HH and HV polarizations. HVVV is the phase difference between HV and VV and so one. There are 6 of these pairs since order is irrelevant. These 6 images are combined to calculate various metrics that tell you about the types of scattering occurring.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#uavsar-data-products","position":19},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Import Libraries","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#import-libraries","position":20},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Import Libraries","lvl2":"UAVSAR Data Products"},"content":"\n\ntry:\n    from uavsar_pytools import UavsarScene\n    from uavsar_pytools.snow_depth_inversion import depth_from_phase, phase_from_depth\nexcept ModuleNotFoundError:\n    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n\nimport os\nfrom os.path import join, basename\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport holoviews as hv\nimport rioxarray as rxa\nimport rasterio as rio\nfrom bokeh.plotting import show\nimport datashader as ds\nfrom datashader.mpl_ext import dsshow\nhv.extension('bokeh', logo=False)\nimport earthpy.plot as ep\nimport earthpy.spatial as es\nimport contextily as cx\nfrom datetime import date\nfrom shapely.geometry import box\nimport requests\n%config InlineBackend.figure_format='retina'\n\n# Database imports\nfrom snowexsql.db import get_db\nfrom snowexsql.data import PointData, ImageData, LayerData, SiteData\nfrom snowexsql.conversions import query_to_geopandas\n\nimport warnings\nwarnings.filterwarnings('ignore', category=UserWarning, module='rasterio')\nimport logging\nlogging.getLogger('rasterio._env').setLevel(logging.ERROR)\nlogging.getLogger('rasterio._filepath').setLevel(logging.ERROR)\nos.environ['CPL_CURL_VERBOSE'] = 'NO'\n\n","type":"content","url":"/notebooks/uavsar-tutorial#import-libraries","position":21},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#interferometric-imagery","position":22},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"\n\n","type":"content","url":"/notebooks/uavsar-tutorial#interferometric-imagery","position":23},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Banner Summit","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#banner-summit","position":24},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Banner Summit","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"\n\nIn this section we’ll be plotting and comparing dirrerent types of SAR and InSAR data with optical imagery and a digital elevation model. For this example we’ll be taking a subet of the Lowman flight (Boise, ID) line encompassing Banner Summit.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#banner-summit","position":25},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Access Tutorial Data from S3","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#access-tutorial-data-from-s3","position":26},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Access Tutorial Data from S3","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"The tutorial data is hosted on AWS S3 and can be accessed directly without downloading. The data will be streamed as needed using rioxarray.\n\n# S3 base URL for tutorial data\nS3_BASE_URL = \"https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/\"\n\n","type":"content","url":"/notebooks/uavsar-tutorial#access-tutorial-data-from-s3","position":27},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Load in Rasters","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#load-in-rasters","position":28},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Load in Rasters","lvl2":"UAVSAR Data Products"},"content":"Here we’ll load our rasters into the environemtns using rioxarray or rxa, we will then convert to a np.array to be able to use matplotlib.pyplot or plt for plotting\n\n","type":"content","url":"/notebooks/uavsar-tutorial#load-in-rasters","position":29},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Optical Data","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#optical-data","position":30},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Optical Data","lvl2":"UAVSAR Data Products"},"content":"We will be using \n\nHaromized Landsat Sentinel (HLS) dataset from January 13th, 2021. This date was selected because it is mostly cloud free, which is uncommon in mountain environments during the winter.\n\n# Define S3 URLs for the three RGB bands and stack them in memory\nred_path = S3_BASE_URL + 'lowman_red.tif'\ngreen_path = S3_BASE_URL + 'lowman_green.tif'\nblue_path = S3_BASE_URL + 'lowman_blue.tif'\n\n# Load and stack RGB bands directly from S3 (no local files needed)\nimport xarray as xr\nred = rxa.open_rasterio(red_path)\ngreen = rxa.open_rasterio(green_path)\nblue = rxa.open_rasterio(blue_path)\n\n# Stack the bands into a single array\nrgb = xr.concat([red, green, blue], dim='band')\nrgb['band'] = [1, 2, 3]  # Label bands as 1, 2, 3\n\n","type":"content","url":"/notebooks/uavsar-tutorial#optical-data","position":31},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What do we see in this image? Any notable features?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-do-we-see-in-this-image-any-notable-features","position":32},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What do we see in this image? Any notable features?","lvl2":"UAVSAR Data Products"},"content":"\n\n# plot rgb image\nep.plot_rgb(rgb.values,\n            figsize=(15, 15),\n            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n            title = \"HLS Optical 2/18/2021\", \n            stretch=True)\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-do-we-see-in-this-image-any-notable-features","position":33},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"InSAR and SAR Data","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#insar-and-sar-data","position":34},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"InSAR and SAR Data","lvl2":"UAVSAR Data Products"},"content":"Here we’ll be using five different data products related to InSAR and SAR: unwrapped phase (unw), coherence (cor), amplitude (amp), elevation (dem), and incidence angle (inc).\n\n# Open rasters directly from S3 and inspect metadata using xarray\nunw_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_unw.tif')\nunw = unw_rast[0].values # np.array for plotting\n    \n# coherence\ncor_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_cor.tif')\ncor = cor_rast[0].values\n\n# amplitude\namp_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_amb_db.tif')\namp = amp_rast[0].values # np.array for plotting\n\n# dem\ndem_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_dem.tif')\ndem = dem_rast[0].values\n\n# incidence angle\ninc_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_inc_deg.tif')\ninc = inc_rast[0].values # np.array for plotting\n\n# plot unwrapped phase\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"UNW (radians)\", fontsize= 20) #title and font size\nimg = ax.imshow(unw, interpolation = 'nearest', cmap = 'viridis', vmin = -3, vmax = 2)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot coherence\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Coherence\", fontsize= 20) #title and font size\nimg = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot amplitude\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Amplitude (dB)\", fontsize= 20) #title and font size\nimg = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot dem\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Elevation (m)\", fontsize= 20) #title and font size\nimg = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot incidence angle\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Incidence Angle (deg)\", fontsize= 20) #title and font size\nimg = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#insar-and-sar-data","position":35},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison Plot","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#comparison-plot","position":36},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison Plot","lvl2":"UAVSAR Data Products"},"content":"\n\n# plot all InSAR products\nfig = plt.figure(figsize=(30,19))\n\nax = fig.add_subplot(1,3,1)\ncax=ax.imshow(unw, cmap='viridis', interpolation = 'nearest', vmin = -3, vmax = 2)\nax.set_title(\"UNW (radians)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[-3,0,2],orientation='horizontal', fraction=0.03, pad=0.04)\ncbar.ax.set_xticklabels([-3,0,2])\n\nax = fig.add_subplot(1,3,2)\ncax = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\nax.set_title(\"Coherence\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[0,.5,1], orientation='horizontal',fraction=0.03, pad=0.04)\n\n\nax = fig.add_subplot(1,3,3)\ncax = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\nax.set_title(\"Amplitude (dB)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[-20,-10,0], orientation='horizontal',fraction=0.03, pad=0.04)\ncbar.ax.set_xticklabels([-20,-10,0])\n\nax = fig.add_subplot(2,3,1)\ncax = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\nax.set_title(\"Incidence Angle (deg)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[20,90], orientation='horizontal', pad=0.07)\ncbar.ax.set_xticklabels([20,90])\n\nax = fig.add_subplot(2,3,2)\ncax = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\nax.set_title(\"Elevation (m)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[1800,2800], orientation='horizontal', pad=0.07)\ncbar.ax.set_xticklabels([1800,2800])\n\ndone = None\n\nep.plot_rgb(rgb.values,\n            figsize=(7, 7),\n            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n            title = \"HLS Optical 2/18/2021\", \n            stretch=True)\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#comparison-plot","position":37},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What are some notable similarities between images? Differences?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-are-some-notable-similarities-between-images-differences","position":38},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What are some notable similarities between images? Differences?","lvl2":"UAVSAR Data Products"},"content":"In the next section we’ll go into more detail about the features that impact coherence, phase, and how they’re related\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-are-some-notable-similarities-between-images-differences","position":39},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Sagehen Creek Example","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#sagehen-creek-example","position":40},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Sagehen Creek Example","lvl2":"UAVSAR Data Products"},"content":"\n\n# Load Sagehen Creek data directly from S3\nsage_files = ['cor.tif', 'hgt.tif', 'unw.tif']\nimgs = {}\nfor filename in sage_files:\n    name = filename.split('.')[0]\n    s3_path = S3_BASE_URL + 'sage/' + filename\n    imgs[name] = rxa.open_rasterio(s3_path, parse_coordinates=True, default_name=name)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#sagehen-creek-example","position":41},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What topographic features seem to impact coherence?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-topographic-features-seem-to-impact-coherence","position":42},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What topographic features seem to impact coherence?","lvl2":"UAVSAR Data Products"},"content":"Take a moment to chat with the people around you about this. Some features to get you thinking:\n\nlakes\n\naspect (south vs north, east vs west)\n\nelevation\n\ntrees\n\nroads\n\nothers?\n\ntiles = hv.element.tiles.EsriUSATopo().opts()\ncor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\nhgt = hv.Image(hv.Dataset(imgs['hgt'], kdims=['x','y'])).opts(cmap = 'terrain', colorbar=True, xaxis = None, yaxis = None, title= 'DEM', alpha = 0.4)\nhgt_trans = hv.Image(hv.Dataset(imgs['hgt'][0,::100,::100], kdims=['x','y'])).opts(alpha = 0, xaxis = None, yaxis = None, title = 'Topo')\ncor_tile = tiles  * cor\nhgt_tile = tiles  * hgt\nimagery = hv.element.tiles.EsriImagery()  * hgt_trans\n\nhv.Layout([cor_tile, hgt_tile, imagery]).opts(width = 400, height = 900)\n\nimport seaborn as sns\nxna = imgs['hgt'].data.ravel()\nyna = imgs['cor'].data.ravel()\nx = xna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\ny = yna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\n\ndf = pd.DataFrame(dict(x=x, y=y))\ndf['x_cat'] = pd.qcut(df.x, q= 6, precision = 0)\nf, ax = plt.subplots(figsize = (12,8))\nsns.violinplot(y = df.y[::100], x = df.x_cat[::100], scale = 'count')\nplt.xlabel('Elevation Bands (m)')\nplt.ylabel('Coherence')\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-topographic-features-seem-to-impact-coherence","position":43},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"UNW vs. Coherence","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#unw-vs-coherence","position":44},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"UNW vs. Coherence","lvl2":"UAVSAR Data Products"},"content":"\n\ntiles = hv.element.tiles.EsriUSATopo().opts()\ncor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\nunw = hv.Image(hv.Dataset(imgs['unw'], kdims=['x','y'])).opts(cmap = 'magma', colorbar=True, xaxis = None, yaxis = None, title= 'Unwrapped Phase', clim = (0, 2*np.pi))\ncor_tile = tiles  * cor\nunw_tile = tiles  * unw\n\nhv.Layout([cor_tile, unw_tile]).opts(width = 400, height = 900)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#unw-vs-coherence","position":45},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl2","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar-for-snow","position":46},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"Why would I use UAVSAR for snow?"},"content":"L-band SAR penetrates through the snowpack. However when it crosses into the snowpack from the air it refracts at an angle, similar to light entering water. This refraction leads to a phase shift relative to an image with no or less snow. Using this difference in phase between two images we can calculate the change in snow height between flights using:\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWhere \\Delta d is the change in snow height, \\Delta \\phi is the phase shift between two SAR images, \\lambda is the radar wavelength, \\alpha is the incidence angle, and \\epsilon_{s} is the dielectric constant of snow which is dependent on the density and liquid water content.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar-for-snow","position":47},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Set variables","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#set-variables","position":48},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Set variables","lvl2":"Why would I use UAVSAR for snow?"},"content":"\n\n# Mesa Lake Snotel Coordinates\nsnotel_coords = (-108.05, 39.05)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#set-variables","position":49},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Phase Change between February 1st and 13th UAVSAR Image Pairs","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#phase-change-between-february-1st-and-13th-uavsar-image-pairs","position":50},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Phase Change between February 1st and 13th UAVSAR Image Pairs","lvl2":"Why would I use UAVSAR for snow?"},"content":"You learned in the first section how to access and download UAVSAR imagery. For this section the data has already been downloaded, converted to GeoTiffs and cropped down to an area of interest that overlaps the main field sites of Grand Mesa. Lets take a look at the coherence and unwrapped phase between these two flights. If you don’t remember what these two represent check out the previous section of this tutorial.\n\n# Create figures and subplots\nfig, axes = plt.subplots(2, 1, figsize = (12,8))\n\n# Select colormap for each image type\nvis_dic = {'cor': 'Blues', 'unw':'magma'}\n\n# Loop through coherence and unwrapped phase images\nfor i, type in enumerate(vis_dic.keys()):\n    # select correct axis\n    ax = axes[i]\n    # open image directly from S3 with rioxarray\n    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n    # calculate visualization parameters\n    vmin, vmax = img.quantile([0.1,0.9])\n    # plot images\n    img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n    # zoom out a bit\n    ax.set_xlim(-108.28,-108)\n    ax.set_ylim(38.98, 39.08)\n    # add topo basemap\n    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n    # turn off labels\n    ax.xaxis.label.set_visible(False)\n    ax.yaxis.label.set_visible(False)\n# set titles\naxes[0].set_title('Coherence')\naxes[1].set_title('Unwrapped Phase Change')\n\nplt.show()\n\nfig, ax = plt.subplots(figsize = (12,8))\n\n# Plot the snotel location\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n\n# Plot bounding box of uavsar - stream from S3\nuavsar_bounds = rxa.open_rasterio(S3_BASE_URL + 'cor.tif').rio.bounds()\nx,y = box(*uavsar_bounds).exterior.xy\nax.plot(x,y, color = 'blue')\n\n# Set overview bounds\nax.set_xlim(-108.4,-107.75)\nax.set_ylim(38.75, 39.3)\n\n# Add background map\ncx.add_basemap(ax, crs='EPSG:4326', alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\nplt.title('Overview Map')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#phase-change-between-february-1st-and-13th-uavsar-image-pairs","position":51},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Using the SnowEx SQL Database to collect snow depth and lidar datasets","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#using-the-snowex-sql-database-to-collect-snow-depth-and-lidar-datasets","position":52},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Using the SnowEx SQL Database to collect snow depth and lidar datasets","lvl2":"Why would I use UAVSAR for snow?"},"content":"Lets explore how many overlapping depth observations we have between these two days.\n\n# This is what you will use for all of hackweek to access the db\ndb_name = 'snow:hackweek@db.snowexdata.org/snowex'\n\n# Using the function get_db, we receive 2 ways to interact with the database\nengine, session = get_db(db_name)\n\n# Its convenient to store a query like the following \nqry = session.query(PointData)\n\n# Filter to snow depths\nqry = qry.filter(PointData.type == 'depth')\nqry = qry.filter(PointData.site_name == 'Grand Mesa')\nqry = qry.filter(PointData.instrument != 'Mala 800 MHz GPR')\n\n# Then filter on it first date. We are gonna get one day either side of our flight date\nqry_feb1 = qry.filter(PointData.date >= date(2020, 1, 31))\nqry_feb1 = qry_feb1.filter(PointData.date <= date(2020, 2, 2))\ndf_feb_1 = query_to_geopandas(qry_feb1, engine)\n\n# Get depths from second flight date\nqry_feb12 = qry.filter(PointData.date >= date(2020, 2, 11))\nqry_feb12 = qry_feb12.filter(PointData.date <= date(2020, 2, 13))\ndf_feb_12 = query_to_geopandas(qry_feb12, engine)\n\n# Get depths that were captured on both days\ndf_both = df_feb_1.overlay(df_feb_12, how = 'intersection')\n\n# Convert crs to match our uavsar images\ndf_both = df_both.to_crs(epsg = 4326)\n\n# Calculate the snow depth change for each point\ndf_both['sd_diff'] = df_both.value_2 - df_both.value_1\n\nfig, ax = plt.subplots(figsize = (12,4))\n\n# Plot depth measurements\ndf_both.plot(ax = ax, column = 'sd_diff', legend = True, legend_kwds = {'label': 'Snow Depth Change [cm]'}, cmap = 'magma')\n\n# Plot the snotel location\nsnotel_coords = (-108.05, 39.05)\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n\n# Plot bounding box of uavsar - stream from S3\nimg = rxa.open_rasterio(S3_BASE_URL + 'cor.tif')\nuavsar_bounds = img.rio.bounds()\nx,y = box(*uavsar_bounds).exterior.xy\nax.plot(x,y, color = 'blue')\n\n# Set same bounds as uavsar image plot\nax.set_xlim(-108.28,-108)\nax.set_ylim(38.98, 39.08)\n\n# Add background map\ncx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\nplt.title('Database Snow Depth Measurements')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#using-the-snowex-sql-database-to-collect-snow-depth-and-lidar-datasets","position":53},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#getting-the-remaining-parameters","position":54},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"","type":"content","url":"/notebooks/uavsar-tutorial#getting-the-remaining-parameters","position":55},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Incidence Angle","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#incidence-angle","position":56},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Incidence Angle","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"We can recall the formula to calculate snow depth change from incidence angle, phase change, and the snow permittivity.\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWe have two of these variables already: incidence angle and phase change.\n\n# Create figures and subplots\nfig, axes = plt.subplots(2, 1, figsize = (12,8))\n\n# Select colormap for each image type\nvis_dic = {'inc': 'Greys', 'unw':'magma'}\n\n# Loop through each image type\nfor i, type in enumerate(vis_dic.keys()):\n    ax = axes[i]\n    # Open image directly from S3 with rioxarray\n    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n    # convert incidence angle from radians to degrees\n    if type == 'inc':\n        img = np.rad2deg(img)\n    # this is a great convenience feature to calculate good visualization levels\n    vmin, vmax = img.quantile([0.1,0.9])\n    # plot the image\n    im = img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n    # Zoom out a big\n    ax.set_xlim(-108.28,-108)\n    ax.set_ylim(38.98, 39.08)\n    # Add a topo basemap\n    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n    # Remove unnecessary 'x' 'y' labels\n    ax.xaxis.label.set_visible(False)\n    ax.yaxis.label.set_visible(False)\n\n# Add titles\naxes[0].set_title('Incidence Angle')\naxes[1].set_title('Unwrapped Phase Change')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#incidence-angle","position":57},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Getting Permittivity","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#getting-permittivity","position":58},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Getting Permittivity","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"We have two ways of getting the e_{s}, or the real part of the snow’s dielectric permittivity. One is by estimating from the snow density. For dry snow we can estimate the permittivity using the density. There are a number of equations for calculating this value, but we will use the equation from \n\nGuneriussen et al. 2001:e_{s} = 1 + 0.0016 \\rho + 1.8 1\\mathrm{e}{-9} \\rho^{3}\n\nwhere e_{s} is the real part of the snow’s dielectric permittivity and \\rho is the density of the new snow accumulated between the two images in \\frac{kg}{m^{3}}.\n\nThe other method is to use the directly measured values for permittivity from the field and averaging the top layer.\n\n# Its convenient to store a query like the following \nqry = session.query(LayerData)\n\n# Then filter on it first date. We are gonna get one day either side of second flight date\nqry = qry.filter(LayerData.date >= date(2020, 1, 31))\nqry = qry.filter(LayerData.date <= date(2020, 2, 2))\nqry = qry.filter(LayerData.site_name == 'Grand Mesa')\n# Filter to snow density\nqry_p = qry.filter(LayerData.type == 'density')\n# Change the qry to a geopandas dataframe\ndf = query_to_geopandas(qry_p, engine)\n# create a list to hold the density values\np_values = []\n# Loop through each snowpit (each unique site-id is a snowpit) \nfor id in np.unique(df.site_id):\n    sub = df[df.site_id == id]\n    # get the density for the top layer identified in each snowpit\n    p = float(sub.sort_values(by = 'depth', ascending = False).iloc[0]['value'])\n    # add it our list\n    p_values.append(p)\n# calculate the mean density of the top layer for each snowpit\nmean_new_density = np.nanmean(p_values)\n# Use our equation above to estimate our new snow permittivity\nes_estimate = 1 + 0.0016*mean_new_density + 1.8e-09*mean_new_density**3\n\n## We can also use snowpits where permittivity was directly observed to compare to\n# our density estimates\nqry = qry.filter(LayerData.type == 'permittivity')\ndf = query_to_geopandas(qry, engine)\nes_values = []\nfor id in np.unique(df.site_id):\n    sub = df[df.site_id == id]\n    es_str = sub.sort_values(by = 'depth', ascending = False).iloc[0]['value']\n    if es_str != None:\n        es = float(es_str)\n        if es != None:\n            es_values.append(es)\nes_measured = np.nanmean(es_values)\n\nprint(f'New snow measured permittivity: {es_measured}. Permittivity from density: {es_estimate}')\n\n","type":"content","url":"/notebooks/uavsar-tutorial#getting-permittivity","position":59},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Now we have a new snow permittivity (either from density or directly measured) and we can use that along with our unwrapped phase to calculate the Uavsar snow depth change.","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#now-we-have-a-new-snow-permittivity-either-from-density-or-directly-measured-and-we-can-use-that-along-with-our-unwrapped-phase-to-calculate-the-uavsar-snow-depth-change","position":60},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Now we have a new snow permittivity (either from density or directly measured) and we can use that along with our unwrapped phase to calculate the Uavsar snow depth change.","lvl2":"Why would I use UAVSAR for snow?"},"content":"Take a moment to code up the formula for snow depth change from phase and incidence angle:\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWhere \\Delta d is the change in snow height, \\Delta \\phi is the phase shift between two SAR images, \\lambda is the radar wavelength, \\alpha is the incidence angle, and \\epsilon_{s} is the dielectric constant of snow which is dependent on the density and liquid water content.\n\n# Open rasters directly from S3 (unwrapped phase and incidence angle)\nunw = rxa.open_rasterio(S3_BASE_URL + 'unw.tif')\ninc = rxa.open_rasterio(S3_BASE_URL + 'inc.tif')\n\n# This uses the pytool's function to directly give you snow depth change\n# feel free to rerun with this to check your results\n# https://github.com/SnowEx/uavsar_pytools/blob/main/uavsar_pytools/snow_depth_inversion.py\nsd_change = depth_from_phase(unw, inc, density = mean_new_density)\n\n# convert to centimeters from meters\nsd_change = sd_change*100\n\n# Now we can plot the results!\nf, ax = plt.subplots(figsize = (12,8))\n\n# Plot our uavsar snow depth change\nsd_change.plot(ax = ax, cmap = 'Blues', vmin = -10, vmax = 10)\n# plot black shadow for field observations\ndf_both.plot(ax = ax, color = 'black', markersize = 90)\n# plot field observed snow depth difference\ndf_both.plot(ax = ax, column = 'sd_diff', legend = True, cmap = 'Blues', vmin = -10, vmax = 10)\n# add snotel coordinates\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n# turn off labels\nax.xaxis.label.set_visible(False)\nax.yaxis.label.set_visible(False)\n# set title\nax.set_title('Uavsar Snow Depth Inversion vs Field Observations')\n\n## Uncomment this to zoom in on the measured results\n# ax.set_xlim(-108.14, -108.23)\n# ax.set_ylim(39, 39.05)\n\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#now-we-have-a-new-snow-permittivity-either-from-density-or-directly-measured-and-we-can-use-that-along-with-our-unwrapped-phase-to-calculate-the-uavsar-snow-depth-change","position":61},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Numerical Comparison","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#numerical-comparison","position":62},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Numerical Comparison","lvl2":"Why would I use UAVSAR for snow?"},"content":"We can now extract the snow depth change at each measured point and compare them\nto the pit values of snow depth change.\n\n# Sample UAVSAR snow depth change at field measurement points (in memory, no file I/O)\ncoord_list = [(x, y) for x, y in zip(df_both['geometry'].x, df_both['geometry'].y)]\n\n# Use rioxarray to sample values directly from the in-memory array\nfrom rasterio.transform import rowcol\ndf_both['uavsar_sd'] = [\n    float(sd_change.sel(x=x, y=y, method='nearest').values) \n    for x, y in coord_list\n]\n\nf, ax = plt.subplots(figsize = (12,8))\ndf_both['geometry-str'] = df_both['geometry'].astype(str)\ndf_dis = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'mean', 'uavsar_sd': 'mean'})\nfield_sd_std = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'std'})['sd_diff'].values\nax.errorbar(x = df_dis.uavsar_sd, y = df_dis.sd_diff, yerr = field_sd_std, fmt=\"o\")\n\nlims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n]\ndef rmse(predictions, targets):\n    return np.sqrt(((predictions - targets) ** 2).mean())\nrmse_sd = rmse(df_both['sd_diff'], df_both['uavsar_sd'])\nprint(f'RMSE between uavsar and field observations is {rmse_sd} cm')\n\n# now plot both limits against each other\nax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\nax.set_xlabel('Uavsar Snow Depth Change')\nax.set_ylabel('Field Measured Snow Depth Change')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#numerical-comparison","position":63},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison to Lidar","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#comparison-to-lidar","position":64},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison to Lidar","lvl2":"Why would I use UAVSAR for snow?"},"content":"\n\n# Create figures and subplots\nfig, axes = plt.subplots(3, 1, figsize = (12,8))\n\n# Load lidar data from S3\nlidar = rxa.open_rasterio(S3_BASE_URL + 'sd_lidar.tif')\n\ndiff = lidar.copy()\ndiff = diff - sd_change\n\nvmin, vmax = sd_change.quantile([0.1,0.9])\nsd_change_masked = sd_change.copy()\nsd_change_masked.data[np.isnan(lidar).data] = np.nan\nsd_change_masked.plot(ax = axes[0], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\nlidar.plot(ax = axes[1], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\ndiff.plot(ax = axes[2], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\n\nfor ax in axes:\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n\naxes[0].set_title('Uavsar Snow Depth Change')\naxes[1].set_title('Lidar Snow Depth Change')\naxes[2].set_title('Snow Depth Difference')\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize = (12,8))\ndiffs = diff.values.ravel()\ndiffs = diffs[diffs < 100]\ndiffs = diffs[diffs > -100]\nplt.hist(diffs, bins = 100, density = True, label = 'Uavsar sd change')\n# plt.axvline(sd_change_masked.mean().values, label = 'Uavsar Mean Snow Depth Change', color = 'green')\nlidar_vals = lidar.astype(np.float64).values[~lidar.isnull().values]\nlidar_vals = lidar_vals[lidar_vals < 100]\nlidar_vals = lidar_vals[lidar_vals > -100]\nmean_lidar = np.nanmean(lidar_vals)\nplt.axvline(mean_lidar, color = 'red', linewidth = 5, label = 'mean lidar sd change')\n# plt.axvline(mean_lidar, label = 'Lidar Mean Snow Depth Change', color = 'red')\nrmse = np.sqrt(((diffs) ** 2).mean())\nprint(f'Lidar mean depth change: {sd_change_masked.mean().values} cm, uavsar mean depth change: {mean_lidar} cm')\nprint(f'Mean difference: {np.nanmean(diffs)} cm, rmse = {rmse} cm')\nplt.legend(loc = 'lower left')\nplt.xlabel('Snow Depth Change (cm)')\nplt.show()","type":"content","url":"/notebooks/uavsar-tutorial#comparison-to-lidar","position":65}]}