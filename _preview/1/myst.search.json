{"version":"1","records":[{"hierarchy":{"lvl1":"Snow Observations Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Snow Observations Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook is a compilation of tutorials and training\nmaterials in support of the NASA snow reserach community. Some tutorials\ncome from the 2020 to 2024 SnowEx Hackweek program hosted at the UW eScience\nInstitute. Other materials are drawn from the NASA Goddard “SnowPit” Science\nTask Group or STG. The purpose of the tutorials is to help people with data\naccess and to demonstrate a variety of disciplinary use cases.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Motivation"},"content":"There are numerous data products and methods for accessing and analyzing\nsnow observations. These include field, airborne, and satellite missions.\nThe goal of these tutorials is to streamline data access, reduce duplication\nof effort and build an open science community around snow research\ndatasets, algorithms and software.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Authors"},"content":"Zach Fair\n\n\nAnthony Arendt,\n\n\nMark Welden-Smith\n\nmore to be added","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into three main sections: “Data Access”, “Observations”, and “Analysis and Machine Learning”. The current listing of subtopics is currently a work in progress.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 1: Data Access","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-data-access","position":10},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 1: Data Access","lvl2":"Structure"},"content":"Field Campaigns Overview\n\nSnowExSQL Database","type":"content","url":"/#section-1-data-access","position":11},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 2: Observations","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-observations","position":12},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 2: Observations","lvl2":"Structure"},"content":"GPR and Lidar\n\nTime-lapse Cameras\n\nUAVSAR\n\nMicrostructure\n\nAVIRIS-NG\n\nTerrestrial Laser Scanning","type":"content","url":"/#section-2-observations","position":13},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 3: Analysis and Machine Learning","lvl2":"Structure"},"type":"lvl3","url":"/#section-3-analysis-and-machine-learning","position":14},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 3: Analysis and Machine Learning","lvl2":"Structure"},"content":"Neural Networks with PyTorch\n\nSnow Modeling\n\nUCLA Reanalysis\n\nMERRA-2\n\nERA5","type":"content","url":"/#section-3-analysis-and-machine-learning","position":15},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":16},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using\n\n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":17},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":18},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of\nhow this works are not important for now. All you need to know is how to launch\na Pythia Cookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":19},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":20},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer,\nyou will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/snow-cookbook repository: git clone https://github.com/ProjectPythia/snow-cookbook.git\n\nMove into the snow-cookbook directorycd snow-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate snow-cookbook\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":21},{"hierarchy":{"lvl1":"GPR and Lidar"},"type":"lvl1","url":"/notebooks/gpr-lidar-hackweektutorial","position":0},{"hierarchy":{"lvl1":"GPR and Lidar"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial","position":1},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Author: Randall Bonnell"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#author-randall-bonnell","position":2},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Author: Randall Bonnell"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#author-randall-bonnell","position":3},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Outline:"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#outline","position":4},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Outline:"},"content":"GPR Methods for the Retrieval of Snow Depth and SWE\n\nLidar Methods for Snow Depth Retrieval and SWE Estimation\n\nLeveraging Coincident GPR and Lidar Data Sets to Derive Snow Density\n\nSnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska\n\nDiscussion: Improving Density Estimation\n\nGPR SnowEx Analysis-Ready Datasets\n\nReferences\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#outline","position":5},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-1-gpr-methods-for-the-retrieval-of-snow-depth-and-swe","position":6},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-1-gpr-methods-for-the-retrieval-of-snow-depth-and-swe","position":7},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous GPR tutorial developed by Tate Meehan (CRREL) that may be of interest: https://​snowex​-2021​.hackweek​.io​/tutorials​/gpr​/gpr​.html","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#previous-gpr-tutorial-developed-by-tate-meehan-crrel-that-may-be-of-interest-https-snowex-2021-hackweek-io-tutorials-gpr-gpr-html","position":8},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous GPR tutorial developed by Tate Meehan (CRREL) that may be of interest: https://​snowex​-2021​.hackweek​.io​/tutorials​/gpr​/gpr​.html","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#previous-gpr-tutorial-developed-by-tate-meehan-crrel-that-may-be-of-interest-https-snowex-2021-hackweek-io-tutorials-gpr-gpr-html","position":9},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"SnowEx Review","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#snowex-review","position":10},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"SnowEx Review","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Ground-based, airborne, and satellite radars were operated as part of the NASA SnowEx campaigns.\n\nGround-based radars included ground-penetrating radar (GPR), frequency-modulated continuous-wave radar (FMCW), and tower mounted radars.\n\nWhat airborne and satellite radars were tasked?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#snowex-review","position":11},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Brief Blurb on Radar Physics","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-brief-blurb-on-radar-physics","position":12},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Brief Blurb on Radar Physics","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Radar is fully transmissible in dry snow, but there is frequency-dependent interaction between the radar signal and the snowpack.\n\nAt L-band frequencies (1–2 GHz, ~25 cm wavelength) there limited to no interaction with the snowpack.","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-brief-blurb-on-radar-physics","position":13},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What is GPR?","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#what-is-gpr","position":14},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What is GPR?","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"We use L-band GPR, which was operated during all SnowEx campaigns!\n\nGPR transmits a radar signal into the snowpack, which then reflects off objects/interfaces with contrasting dielectric permittivity. The GPR records the amplitude and two-way travel time (twt) of the reflections.\n\nDielectric permittivity refers to the dielectric properties of the snowpack that define how EM energy transmits through the medium.\n\nUsually, we are interested in the snow-ground interface and we measure the snowpack thickness in twt (nanoseconds).\n\nHowever, in complex vegetation, radargrams are difficult to interpret! Causes increased uncertainty.\n\nSee radargram examples below for the boreal forest GPR surveys (credit Kajsa Holland-Goon).\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#what-is-gpr","position":15},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Snow Depth, SWE, and Density Calculations","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#snow-depth-swe-and-density-calculations","position":16},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Snow Depth, SWE, and Density Calculations","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"To calculate snow depth (d_s) from twt, we need to estimate the relative permittivity (\\epsilon_s) and radar velocity (v_s) of the snowpack:\n\nv_s = \\frac{c}{\\sqrt{\\epsilon_s}}; --> Where c is the velocity of EM energy in a vacuum.\n\n\\epsilon_s = (1+\\frac{0.845\\rho_s}{1000})^2; --> Kovacs et al. (1995), but more than 19 equations exist for dry snow conditions.\n\nd_s = \\frac{twt}{2}*v_s;\n\nSWE = d_s\\rho_s;--> Where SWE is snow water equivalent.\n\nBut...If we know the snow depth, we can constrain the radar velocity and estimate relative permittivity and density!\n\n\\epsilon_s=(\\frac{c*twt}{2d_s})^2\n\n\\rho_s=(\\sqrt{\\epsilon_s}-1)\\frac{1000}{0.845}\n\nHow can we find the snow depth?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#snow-depth-swe-and-density-calculations","position":17},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Shameless Plug...","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-shameless-plug","position":18},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Shameless Plug...","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Most analysis-ready GPR products have twt, snow depth, and snow water equivalent. Some have been updated with derived snow densities. See 6. SnowEx GPR Analysis-Ready Datasets below.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-shameless-plug","position":19},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-2-lidar-methods-for-snow-depth-retrieval-and-swe-estimation","position":20},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-2-lidar-methods-for-snow-depth-retrieval-and-swe-estimation","position":21},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous lidar tutorial developed by Naheem Adebisi (ESRI) that may be of interest: https://​snowex​-2022​.hackweek​.io​/tutorials​/lidar​/index​.html","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#previous-lidar-tutorial-developed-by-naheem-adebisi-esri-that-may-be-of-interest-https-snowex-2022-hackweek-io-tutorials-lidar-index-html","position":22},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous lidar tutorial developed by Naheem Adebisi (ESRI) that may be of interest: https://​snowex​-2022​.hackweek​.io​/tutorials​/lidar​/index​.html","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#previous-lidar-tutorial-developed-by-naheem-adebisi-esri-that-may-be-of-interest-https-snowex-2022-hackweek-io-tutorials-lidar-index-html","position":23},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A (Very) General Review of Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-very-general-review-of-lidar","position":24},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A (Very) General Review of Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"Lidar emits photons and measures the twt of the returned photons\n\nThese twt are converted to elevation surfaces (e.g., DEM, DTM, DSM).\n\nLidar can be collected from a variety of platforms:\n\nTerrestrial\n\nUAV\n\nAirborne\n\nSatellite\n\nTwo acquisitions are required for snow, a snow-on acquisition and a snow-off acquisition. Snow depth can be calculated in two general ways:\n\nRaster-based approaches (see figure below, credit Airborne Snow Observatories Inc.)\n\nPoint cloud approaches","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-very-general-review-of-lidar","position":25},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"How is SWE calculated from lidar snow depths?","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#how-is-swe-calculated-from-lidar-snow-depths","position":26},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"How is SWE calculated from lidar snow depths?","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"At larger scales, SWE is calculated via modeled densities (e.g., M3 Works and ASO).\n\nAt smaller field sites, it may be appropriate to use representative in situ measurements.\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#how-is-swe-calculated-from-lidar-snow-depths","position":27},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"3. Leveraging Coincident GPR and Lidar Data Sets to Derive Snow Density"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-3-leveraging-coincident-gpr-and-lidar-data-sets-to-derive-snow-density","position":28},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"3. Leveraging Coincident GPR and Lidar Data Sets to Derive Snow Density"},"content":"Density, liquid water content, and relative permittivity are understudied relative to snow depth and/or SWE.\n\nCombined coincident snow depths and twt can yield spatially distributed measurements of relative permittivity.\n\nIn wet snow, relative permittivity can be converted to liquid water content (e.g., Webb et al., 2018, 2020, 2022; Bonnell et al., 2021).\n\nIn dry snow, density can be estimated from the relative permittivity (Yildiz et al., 2021; McGrath et al., 2022; Bonnell et al., 2023; Meehan et al., 2024).\n\nThis technique has provided an unprecedented glimpse into the spatial properties of these parameters!\n\nCritically, studies have noted a large random error in derived products that should be considered (see figure below, credit: Meehan et al., 2024).\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-3-leveraging-coincident-gpr-and-lidar-data-sets-to-derive-snow-density","position":29},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-4-snowex23-gpr-lidar-derived-permittivities-densities-in-the-boreal-forest-alaska","position":30},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-4-snowex23-gpr-lidar-derived-permittivities-densities-in-the-boreal-forest-alaska","position":31},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Here, we will use this approach to derive densities at Farmer’s Loop Creamer’s Field during the SnowEx23 Alaska Campaign","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#here-we-will-use-this-approach-to-derive-densities-at-farmers-loop-creamers-field-during-the-snowex23-alaska-campaign","position":32},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Here, we will use this approach to derive densities at Farmer’s Loop Creamer’s Field during the SnowEx23 Alaska Campaign","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"Lidar data was collected on 11 March 2023\n\nGPR data was collected on 7, 11, 13, and 16 March 2023\n\n#1.1 Load relevant packages\nimport os\nimport numpy as np \nfrom datetime import date\nfrom scipy.spatial import cKDTree\n\n#packages for figures\nimport matplotlib.pyplot as plt\nfrom rasterio.plot import show\n\n#geospatial packages\nimport geopandas as gpd #for vector data\nimport xarray as xr\nimport pandas as pd\nfrom shapely.geometry import box, Point\nimport rasterio as rio\n\n#Import SnowEx database\nfrom snowexsql.api import PointMeasurements, LayerMeasurements, RasterMeasurements\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#here-we-will-use-this-approach-to-derive-densities-at-farmers-loop-creamers-field-during-the-snowex23-alaska-campaign","position":33},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 1: Load the GPR data from the SnowEx data base","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-1-load-the-gpr-data-from-the-snowex-data-base","position":34},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 1: Load the GPR data from the SnowEx data base","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"-Huge thank you to Micah Johnson and Micah Sandusky for their support!\n\nNote that if we used the full GPR/Lidar dataset, we would need to allocate way more memory. This example focuses on a single date of collection in very dense forest.\n\nExamine the headers from the GPR csv --> what are the variables that we are interested in?\n\n# 1.2 Load GPR data\n\n#Note, memory space is fairly limited, will need to pull only one date\n\n#Set a number of dates to pull GPR for\n#dt1 = date(2023, 3, 7)\ndt2 = date(2023, 3, 11)\n#dt3 = date(2023, 3, 13)\n#dt4 = date(2023, 3, 16)\n\n#site1 = LayerMeasurements.from_filter(date=dt1, site_name='Fairbanks', site_id='FLCF', limit=1)\nsite2 = LayerMeasurements.from_filter(date=dt2, site_name='Fairbanks', site_id='FLCF', limit=1)\n#site3 = LayerMeasurements.from_filter(date=dt3, site_name='Fairbanks', site_id='FLCF', limit=1)\n#site4 = LayerMeasurements.from_filter(date=dt4, site_name='Fairbanks', site_id='FLCF', limit=1)\n\n#Use pandas ot read in csv data\n#gpr_df_dt1 = PointMeasurements.from_area(pt=site1.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt1, site_name='farmers-creamers',\n#    limit=29432)#The number of expected measurements\ngpr_df_dt2 = PointMeasurements.from_area(pt=site2.geometry[0], crs=26906, buffer=10000,\n    type='two_way_travel',\n    observers='Randall Bonnell',\n    date=dt2, site_name='farmers-creamers',\n    limit=20213)#The number of expected measurements\n#gpr_df_dt3 = PointMeasurements.from_area(pt=site3.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt3, site_name='farmers-creamers',\n#    limit=19024)\n#gpr_df_dt4 = PointMeasurements.from_area(pt=site4.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt4, site_name='farmers-creamers',\n#    limit=15785)\n\n\n#Compile into one dataframe\n#flcf_gpr_df = pd.concat([gpr_df_dt1,gpr_df_dt2,gpr_df_dt3,gpr_df_dt4],axis=0, join='outer', ignore_index=True, keys=None, levels=None,names=None,verify_integrity=False,sort=False,copy=None)\nflcf_gpr_df = gpr_df_dt2\n#Print out the csv headers and initial entries --> What's important here and what do we need?\nprint(flcf_gpr_df.head())\n\n# Let's look at the distribution of gpr two-way travel times and estimated snow depths\n#Estimate snow depths from twt by assuming a velocity of 0.25 m/ns --> Is this an appropriate velocity estimate?\nflcf_gpr_df['Depth_estimated'] = (flcf_gpr_df['value']/2)*0.25\n\nax1 = flcf_gpr_df.plot.hist(column=[\"value\"], edgecolor='black', title='two-way travel time (ns)')\nax2 = flcf_gpr_df.plot.hist(column=[\"Depth_estimated\"], edgecolor='black', title='Snow depth (m)')\n\n#Extract x/y limits from GPR data --> these will be used when loading the lidar snow depths\nbounds = flcf_gpr_df.total_bounds\n\n# Create a bounding box\ngpr_limits = box(*bounds)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-1-load-the-gpr-data-from-the-snowex-data-base","position":35},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s load in the lidar canopy heights and snow depths.","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#lets-load-in-the-lidar-canopy-heights-and-snow-depths","position":36},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s load in the lidar canopy heights and snow depths.","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"We’ll look at the canopy heights to get an idea of what kind of forest the data were collected in.\n\nThen, we’ll look at the lidar snow depths to visualize the snow distribution.","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#lets-load-in-the-lidar-canopy-heights-and-snow-depths","position":37},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions","position":38},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"What type of survey design was implemented for the GPR?\n\nDo the lidar snow depth patterns seem to exhibit any kind of dependence upon the forest cover?\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions","position":39},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Commented until we fix reading of raster data"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#commented-until-we-fix-reading-of-raster-data","position":40},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# # 1.3 Load Lidar vegetation/canopy heights --> This may take a few minutes\n# #Read in the canopy heights raster from Farmer's Loop/Creamer's Field Alaska\n# flcf_ch = RasterMeasurements.from_area(shp = gpr_limits, crs=26906,\n#     buffer=None, type='canopy_height',\n#     site_name='farmers-creamers',\n#     observers='chris larsen')\n# print(flcf_ch)\n\n# #Plot the datasets\n# fig, ax = plt.subplots()\n# show(flcf_ch, ax=ax, cmap='Greens', clim=(0,5), title = 'Canopy Height (m)')\n# #Plot the GPR points on top\n# flcf_gpr_df.plot(ax=ax, color='blue', markersize = 10)\n\n# # 1.4 Load Lidar Snow depths --> This will take a few minutes\n\n# #Read in the canopy heights raster from Farmer's Loop/Creamer's Field Alaska\n# flcf_ds = RasterMeasurements.from_area(shp = gpr_limits, crs=26906,\n#     buffer=None, type='depth',\n#     site_name='farmers-creamers',\n#     observers='chris larsen')\n\n# #Plot the datasets\n# fig, ax = plt.subplots()\n# show(flcf_ds, ax=ax, cmap='Blues', clim=(0,1.5), title='Snow Depth (m)')\n# #Plot the GPR points on top\n# flcf_gpr_df.plot(ax=ax, color='red', markersize = 10)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#commented-until-we-fix-reading-of-raster-data","position":41},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 2: Match the GPR data to the lidar grid and derive relative permittivity and density","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-2-match-the-gpr-data-to-the-lidar-grid-and-derive-relative-permittivity-and-density","position":42},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 2: Match the GPR data to the lidar grid and derive relative permittivity and density","lvl2":"Commented until we fix reading of raster data"},"content":"There are two conceptual paths forward:\n\nRasterize the GPR data or\n\nVectorize the lidar data\n\nFor simplicity, the following code:\n\nvectorizes the lidar data\n\nperforms a nearest neighbor search between the lidar and GPR coordinate vectors\n\nCalculates the median GPR twt from the nearest neighbors\n\nDerives relative permittivity and density from the lidar snow depths and median twt\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-2-match-the-gpr-data-to-the-lidar-grid-and-derive-relative-permittivity-and-density","position":43},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"We need to know the resolutions of the lidar and GPR datasets","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#we-need-to-know-the-resolutions-of-the-lidar-and-gpr-datasets","position":44},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"We need to know the resolutions of the lidar and GPR datasets","lvl2":"Commented until we fix reading of raster data"},"content":"The GPR dataset consists of points that are spaced ~0.10 m apart.\n\nWhat about the lidar? Run the code block below to answer this question.\n\nHow many GPR points would you expect to have per lidar pixel? Assume linear transects through each pixel.\n\n# #2.1 Let's learn a bit about the resolution of the lidar rasters\n\n# height, width = flcf_ds.read(1).shape #Find the height and width of the array\n\n# #Use meshgrid to create two arrays matching the height/width of the input raster\n# #The GPR dataset consists of vectors --> we will eventually need to vectorize these lidar arrays\n# cols, rows = np.meshgrid(np.arange(width), np.arange(height)) \n\n\n# #Extract the easting/northing from the raster \n# x_lidar, y_lidar = rio.transform.xy(flcf_ds.transform, rows, cols) \n\n# #What's the resolution of the lidar dataset?\n# print(\"The x resolution of the snow depth raster is:\",x_lidar[0][1]-x_lidar[0][0])\n# print(\"The y resolution of the snow depth raster is:\",y_lidar[0][0]-y_lidar[1][0])\n\n\n# # 2.2 Matching GPR to the lidar grid\n\n# #Two conceptual paths forward: rasterize the GPR data, or convert lidar data to points\n\n# #Let's vectorize the raster data\n# x_lidar_vec = np.array(x_lidar).flatten()\n# y_lidar_vec = np.array(y_lidar).flatten()\n# flcf_ds_vec = flcf_ds.read().flatten()\n\n# #Pull vectors from geo dataframe\n# gpr_arr = np.stack([flcf_gpr_df.geometry.x, flcf_gpr_df.geometry.y,flcf_gpr_df['value']], axis=1)\n# gpr_x=gpr_arr[:,0]\n# gpr_y=gpr_arr[:,1]\n# gpr_twt=gpr_arr[:,2].reshape(len(gpr_arr[:,2]),1)\n\n\n# #2.3 Create sets of coordinates for the nearest neighbors search\n# coordinates_set1 = np.column_stack((x_lidar_vec,y_lidar_vec))\n# coordinates_set2 = np.column_stack((gpr_x,gpr_y))\n\n# # Build KDTree from the second set of coordinates\n# tree = cKDTree(coordinates_set2)\n\n# # Define the radius (in meters)\n# radius = 0.25\n\n# # Function to find the median of travel times within a radius --> Credit where credit is due, this function was generated in part by chatgpt\n# def find_median_travel_time_within_radius(point, tree, coordinates_set1, gpr_twt, radius):\n#     indices = tree.query_ball_point(point, radius)\n#     if indices:\n#         # Retrieve travel times for the nearest neighbors\n#         neighbor_twt = gpr_twt[indices]\n#         median_twt = np.median(neighbor_twt)\n#         return median_twt\n#     else:\n#         return np.nan  # Return NaN if no neighbors are within the radius\n# # Find medians for each lidar point\n# medians = np.array([find_median_travel_time_within_radius(point, tree, coordinates_set2, gpr_twt, radius) for point in coordinates_set1])\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#we-need-to-know-the-resolutions-of-the-lidar-and-gpr-datasets","position":45},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"The GPR data is not as spatially continuous as the lidar data, so most of the median twt dataset consists of nan’s","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#the-gpr-data-is-not-as-spatially-continuous-as-the-lidar-data-so-most-of-the-median-twt-dataset-consists-of-nans","position":46},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"The GPR data is not as spatially continuous as the lidar data, so most of the median twt dataset consists of nan’s","lvl2":"Commented until we fix reading of raster data"},"content":"Let’s remove the nan’s to free up memory and reduce processing time.\n\n# #At this point, all lidar points should have an associated gpr twt --> most are likely nan's though. But let's check!\n# print(\"The gpr array has size:\",medians.shape)\n# print(\"The lidar array has size:\",flcf_ds_vec.shape)\n\n\n# #2.4 Before we get to the math part, let's clear out the nan's from all important vectors:\n# #Create mask for gpr medians that are nan's\n# mask = np.isnan(medians)\n\n# #Remove entries from the lidar snow depth, x, and y vectors that align with the nan twt values\n# flcf_ds_vec_clean = flcf_ds_vec[~mask]\n# coordinates_set1_clean=coordinates_set1[~mask]\n\n# #Lastly, remove entries from the twt medians\n# medians_clean = medians[~mask]\n\n# #Let's check the new size of the twt array\n# print(medians_clean.shape)\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#the-gpr-data-is-not-as-spatially-continuous-as-the-lidar-data-so-most-of-the-median-twt-dataset-consists-of-nans","position":47},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions-1","position":48},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"Commented until we fix reading of raster data"},"content":"Roughly, how many points were removed?\n\nWhen we are done, we will have derived 3788 snow density estimates. In the same area, about four snow pits were dug, resulting in four bulk density measurements. How useful do you think our data will be?\n\nIs more always better?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions-1","position":49},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s now transition to the relative permittivity and density calculations","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#lets-now-transition-to-the-relative-permittivity-and-density-calculations","position":50},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s now transition to the relative permittivity and density calculations","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# #2.5 We finally get to the math part!!\n# #Let's calculate relative permittivity first...\n# c=0.2998#The speed of light in a vacuum\n# e_s = ((c * medians_clean) / (2 * flcf_ds_vec_clean)) ** 2\n\n# #And then calculate density\n# rho_s = ((np.sqrt(e_s) - 1) / 0.845) * 1000\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#lets-now-transition-to-the-relative-permittivity-and-density-calculations","position":51},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 3: Examining the derived densities","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-3-examining-the-derived-densities","position":52},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 3: Examining the derived densities","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# # 3.1 Finally, let's take a peek at what the derived densities look like...\n# plt.figure()\n# plt.scatter(coordinates_set1_clean[:,0], coordinates_set1_clean[:,1], s=10, c=rho_s, cmap='viridis', clim=(0, 500), edgecolor=None)\n\n# # Add colorbar to show the scale of color values\n# plt.colorbar()\n# plt.title('Snow Density (kg m-3)')\n\n# # Show the plot\n# plt.show()\n\n# # 3.2 What does the histogram distribution look like??\n# # Define bin edges\n# bin_edges = np.arange(np.min(rho_s), np.max(rho_s), 25)  # Create bin edges from min(x) to max(x) with step size 25\n\n# # Create the histogram\n# plt.figure()  # Create a new figure\n# plt.hist(rho_s, bins=bin_edges, edgecolor=None)  # Plot histogram with specified bin edges\n\n# plt.title('Snow Density Histogram')\n\n# # Show the plot\n# plt.show()\n\n# #Let's zoom in a little...\n# # Define bin edges\n# bin_edges = np.arange(0, 500, 25)  # Create bin edges from min(x) to max(x) with step size 25\n\n# # Create the histogram\n# plt.figure()  # Create a new figure\n# plt.hist(rho_s, bins=bin_edges, edgecolor='black')  # Plot histogram with specified bin edges\n\n# plt.title('Snow Density Histogram')\n\n# # Show the plot\n# plt.show()\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-3-examining-the-derived-densities","position":53},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-5-discussion-improving-density-estimation","position":54},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"5. Discussion: Improving Density Estimation"},"content":"What do you think? Do the derived densities look usable at this stage?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-5-discussion-improving-density-estimation","position":55},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What contributes to the random error?","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#what-contributes-to-the-random-error","position":56},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What contributes to the random error?","lvl2":"5. Discussion: Improving Density Estimation"},"content":"There are three groups of factors that control the random error:\n\nMeasurement accuracy for lidar snow depths and GPR twt. Reduced accuracy for either or both of the techniques will lead to large errors. The boreal forest had a lot of complex vegetation that may have impeded the accuracy of these instruments.\n\nDepth of the snowpack. The accuracy of the lidar is not a function of snow depth. Thus, the random errors reduce as the snow depth increases. The boreal forest snow depths were shallow!\n\nGeolocation alignment. GPR coordinates were post-processed, but accuracy is still likely on the order of ±3 m.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#what-contributes-to-the-random-error","position":57},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Improving the derived densities","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#improving-the-derived-densities","position":58},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Improving the derived densities","lvl2":"5. Discussion: Improving Density Estimation"},"content":"Let’s say we want to learn something about snow density in the boreal forest. The derived densities offer a HUGE increase in the number of available density measurements compared to in situ. But, in situ are much more accurate. How can we improve this dataset?\n\nIncrease the footprint of the derived densities by upsampling the lidar (e.g., to 3 m).\n\nThis will reduce the impact of GPR geolocation accuracy and the lidar/GPR observation uncertainty.\n\nNeed to be careful! The GPR footprint is large, but it may not scale well past 3 m.\n\nRemove erroneous values.\n\nHow does the lidar survey time compare with the GPR survey time? Was the snow disturbed or did more snow accumulate between surveys?\n\nRelative permittivity of snow cannot be less than air (\\epsilon_a = 1.0) or greater than liquid water (\\epsilon_w = 88).\n\nFor dry snow, relative permittivity is usually between 1.0 and 2.0. The removal of values outside a certain number of standard deviations and/or the interquartile range may be warranted.\n\nRun a spatial averaging filter.\n\nOur surveys were primarily spirals --> should pair nicely with such a filter!\n\nExperiment with the window size of the filter. How would a 5 m x 5 m filter compare to a 25 m x 25 m filter?\n\nShould the data be parsed into different forest cover classes before such a filter is run?\n\nBe careful of linear transects! Large windows tend to remove any density variability along such transects.\n\nOnce you reach this point, it is likely that the densities will be analysis ready. You could run a predictive model to fill in the void spaces, use the densities to evaluate models, calculate experimental variograms, etc.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#improving-the-derived-densities","position":59},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"6. SnowEx GPR Analysis-Ready Datasets"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-6-snowex-gpr-analysis-ready-datasets","position":60},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"6. SnowEx GPR Analysis-Ready Datasets"},"content":"Grand Mesa, Colorado (SnowEx 2017, 2020)\n\nWebb et al. (2019). \n\nWebb et al. (2019)\n\nBonnell et al. (2021). \n\nBonnell et al. (2021)\n\nMeehan (2021). \n\nMeehan (2021)\n\nWebb (2021). \n\nWebb (2021)\n\nMeehan & Hojatimalekshah (2024). \n\nMeehan & Hojatimalekshah (2024)\n\nCameron Pass, Colorado (SnowEx 2020, 2021)\n\nMcGrath et al. (2021). \n\nMcGrath et al. (2021)\n\nBonnell et al. (2022). \n\nBonnell et al. (2022)\n\nBonnell et al. (2024). \n\nBonnell et al. (2024)\n\nJemez Mountains, New Mexico (SnowEx 2020)\n\nWebb (2021). \n\nWebb (2021)\n\nArctic Coastal Plains, Alaska (SnowEx 2023)\n\nWebb (2024). \n\nWebb (2024)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-6-snowex-gpr-analysis-ready-datasets","position":61},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"7. References"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-7-references","position":62},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"7. References"},"content":"Lidar Datasets\n\nLarsen (2024). \n\nLarsen (2024)\n\nRelevant GPR LWC Studies\n\nWebb et al. (2018). \n\nWebb et al. (2018)\n\nWebb et al. (2020). \n\nWebb et al. (2020)\n\nBonnell et al. (2021). \n\nBonnell et al. (2021)\n\nWebb et al. (2022). \n\nWebb et al. (2022)\n\nRelevant GPR Density Studies\n\nYildiz et al. (2021). \n\nYildiz et al. (2021)\n\nMcGrath et al. (2022). \n\nMcGrath et al. (2022)\n\nBonnell et al. (2023). \n\nBonnell et al. (2023)\n\nMeehan et al. (2024). \n\nMeehan et al. (2024)","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-7-references","position":63},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"type":"lvl1","url":"/notebooks/snowex-data-overview","position":0},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"content":"\n\n","type":"content","url":"/notebooks/snowex-data-overview","position":1},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"type":"lvl1","url":"/notebooks/snowex-data-overview#field-campaigns-overview","position":2},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"content":"(5 minutes)\n\nBy: Megan Mason (NASA Goddard / SSAI) \n\nmegan​.a​.mason@nasa​.gov\n\nSupport by:  Carrie Vuyovich (NASA Goddard), Hans-Peter Marshall (Boise State), Svetlana Stuefer (University of Alaska Fairbanks)\n\nLearning Objectives\n\nVisual overview of the NASA SnowEx field campaigns\n\nGet a sense for the extent of data coverage\n\n\n\n","type":"content","url":"/notebooks/snowex-data-overview#field-campaigns-overview","position":3},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl2":"Data Coverage"},"type":"lvl2","url":"/notebooks/snowex-data-overview#data-coverage","position":4},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl2":"Data Coverage"},"content":"Each year we build upon our efforts to further investigate snow remote sensing science gaps identified in the NASA SnowEx Science Plan \n\n(Durand et al., 2016). The summary table lists the focus for each campaign by year and type. There are two different campaign types (IOP vs. TS); both result in the same types of measurements and data products. Depending on the  research application it may not matter at all which you choose to work with, or even combine! The important thing to grasp is the difference in spatial and temporal extent of the campaign periods. If the sampling protocols or data products change over time, it is for the sake of improvement. When possible, we aim to keep things consistent to continue to build a legacy data set.\n\nYear\n\nCampaign Type\n\nMeasurement Focus\n\n2017\n\nIOP\n\nColorado, focused on multiple instruments in a forest gradient.\n\n2020\n\nIOP, TS\n\nWestern U.S focused on Time Series of L-band InSAR, active/passive microwave for SWE and thermal IR for snow surface temp.\n\n2021\n\nTS\n\nWestern U.S, continued Time Series of L-band InSAR, also addressed prairie & snow albedo questions.\n\n2023\n\nIOP\n\nAlaska Tundra & Boreal forest, focused on addressing SWE/snow depth and albedo objectives.\n\n*IOP=Intense Observation Period (~2-3 week, daily observations) *; TS=Time Series (~3-5 month winter, weekly observations)\n\n","type":"content","url":"/notebooks/snowex-data-overview#data-coverage","position":5},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Where has SnowEx Been?","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#where-has-snowex-been","position":6},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Where has SnowEx Been?","lvl2":"Data Coverage"},"content":"Campaign efforts are focused on various snow climates in the western United States. SnowEx partnerships and expertise are spread across the U.S and international.\n\n\nFigure 1. Map showing the locations of SnowEx field campaign areas (red dot). Base map shows snow classes defined in \n\nSturm and Liston, 2021. The snow pit images show a representative pit in each of the class types visited by SnowEx.\n\nTable 1. Number of manual depths and snow pits associated with NASA SnowEx measurement periods.\n\nSnowEx\n\nField Campaign Location\n\nTemporal Coverage\n\nManual Depths\n\nSnow Pits\n\nS17\n\nGrand Mesa & Senator Beck Basin, Colorado\n\nFebruary 6-25, 2017\n\n23,432\n\n265\n\nS20\n\nGrand Mesa, ColoradoWestern U.S Time Series (13 sites)\n\nNovember 4-7, 2019January 27-February 12, 2020October 24-May 20, 2020*\n\n16,21237,921TBD\n\n21154454\n\nS21\n\nWestern U.S Time Series (7 sites)\n\nNovember 16-May 27, 2021\n\n12,536\n\n247\n\nS23\n\nTundra & Boreal Forest, Alaska (pre-campaign site visit)Tundra & Boreal Forest, AlaskaTundra & Boreal Forest, AlaskaBoreal Forest, AlaskaTundra & Boreal Forest, Alaska\n\nMarch 7-17, 2022October 22-27, 2022March 7-16, 2023April 5-May 6, 2023October 17-28, 2023\n\n10,7289,04926,750TBD6,350\n\n1818617013127\n\n*The majority of sites in 2020 have a temporal coverage of January-March due to the Covid-19 pandemic.\n\n","type":"content","url":"/notebooks/snowex-data-overview#where-has-snowex-been","position":7},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Snow Classification Coverage","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#snow-classification-coverage","position":8},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Snow Classification Coverage","lvl2":"Data Coverage"},"content":" Thanks to Sturm and Liston 2021 (and 1995), we have a global seasonal snow classification system. This is a vital mission planning tool for remote sensing snow studies. Revised from inception, the snow classification system offers improved utility of the climatological snow classes due to improved (much higher) resolution (300 m over North America). This data set can be found at NSIDC and downloaded at multiple resolutions.\n\n[NSIDC Global Seasonal-Snow Classification, Version 1](https://nsidc.org/data/NSIDC-0768/versions/1) \n\nCheck out [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml) to find out more \n    \n![](./content/01_snow-classes-sturm.png)\n**Figure 3.** Snow Classes across North America at 300 m (Sturm and Liston, 2021) \n\nAs part of the mission statement, SnowEx aims to quantify snow estimation uncertainty across a range of snow classes, terrain and vegetation types. This is important to determine what areas and time periods have high SWE uncertainty across the ensemble of instrument techniques.\n\n\nFigure 2. Map of the in situ field visits for the duration of SnowEx field campaigns (2017-2023). At this scale, points are overlapping, especially in the eastern Rocky Mountain region around Colorado. The total number of unique visits with recorded SWE are listed in the legend. Upper Right Bar chart of snow classes over the four SnowEx field campaign years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occurred in open areas such as meadows and clearings. The snow classification colors match those used in \n\nSturm and Liston, 2021. ![](./content/01_snow-classes-barchart.png)\n**Figure 2.** Bar chart of snow classes over the four SnowEx field campagin years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occured in open areas such as meadows and clearings. The snow classification colors match those used in [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml).   ![](./content/01_map-n-barchart.png)\n**Figure 2.** Bar chart of snow classes over the four SnowEx field campagin years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occured in open areas such as meadows and clearings. The snow classification colors match those used in [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml). \n\n","type":"content","url":"/notebooks/snowex-data-overview#snow-classification-coverage","position":9},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Recap","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#recap","position":10},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Recap","lvl2":"Data Coverage"},"content":"SnowEx campaigns are structured based on the objectives set out in the SnowEx Science Plan. Some of those objectives are meet by conducting an all hands-on, short and intense observation period (IOP), while others are addressed by studying the evolution of the snowpack over a much longer time series (TS) style campaign.\n\nThe coincident field and airborne campaigns are designed to directly respond to the current knowledge gaps in remote sensing of seasonal snow, thus the participant-driven SnowEx effort targets a range of snow classes, terrain and vegetation types.\n\n","type":"content","url":"/notebooks/snowex-data-overview#recap","position":11},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"References","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#references","position":12},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"References","lvl2":"Data Coverage"},"content":"SnowEx Experimental Plans: 2017, \n\n2020, \n\n2021, \n\n2023\n\nSnowEx Science Plan\n\nSturm and Liston, 2021","type":"content","url":"/notebooks/snowex-data-overview#references","position":13},{"hierarchy":{"lvl1":"SnowExSQL Database"},"type":"lvl1","url":"/notebooks/snowexsql-database","position":0},{"hierarchy":{"lvl1":"SnowExSQL Database"},"content":"Tutorial Author Micah’: \n\nMicah Sandusky\n\nTutorial Author Micah_o: \n\nMicah Johnson\n\nSnowEx has introduced a unique opportunity to study SWE in a way that’s unprecedented, but with more data comes new challenges. \n<img src=\"https://snowexsql.readthedocs.io/en/latest/_images/gallery_overview_example_12_0.png\" alt=\"Grand Mesa Overview\" width=\"1000px\"> \n\nThe SnowEx database is a resource that shortcuts the time it takes to ask cross dataset questions\n\nStandardizing diverse data\n\nCross referencing data\n\nProvenance!\n\nAdded GIS functionality\n\nConnect w/ ArcGIS or QGIS!\n\nCITABLE\n\n2022- Estimating snow accumulation and ablation with L-band interferometric synthetic aperture radar (InSAR)\n\n2024 - Thermal infrared shadow-hiding in GOES-R ABI imagery: snow and forest temperature observations from the SnowEx 2020 Grand Mesa field campaign","type":"content","url":"/notebooks/snowexsql-database","position":1},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"What’s in it?"},"type":"lvl3","url":"/notebooks/snowexsql-database#whats-in-it","position":2},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"What’s in it?"},"content":"Snow pits - Density, hardness profiles, grain types + sizes\n\nManual snow depths - TONS of depths (Can you say spirals?)\n\nSnow Micropenetrometer (SMP) profiles - (Subsampled to every 100th)\n\nSnow depth + SWE rasters from ASO Inc.\n\nGPR\n\nPit site notes\n\nCamera Derived snow depths\n\nSnow off DEM from USGS 3DEP\n\nAnd almost all the associated metadata","type":"content","url":"/notebooks/snowexsql-database#whats-in-it","position":3},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Technically, what is it?"},"type":"lvl3","url":"/notebooks/snowexsql-database#technically-what-is-it","position":4},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Technically, what is it?"},"content":"PostgreSQL database\n\nPostGIS extension\n\nSupports vector and raster data\n\nAnd a host of GIS operations\n\nAND NOW WITH API!","type":"content","url":"/notebooks/snowexsql-database#technically-what-is-it","position":5},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"So what’s the catch?","lvl3":"Technically, what is it?"},"type":"lvl4","url":"/notebooks/snowexsql-database#so-whats-the-catch","position":6},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"So what’s the catch?","lvl3":"Technically, what is it?"},"content":"New tech can create barriers...\n\n","type":"content","url":"/notebooks/snowexsql-database#so-whats-the-catch","position":7},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"TL;DR Do less wrangling, do more crunching.","lvl3":"Technically, what is it?"},"type":"lvl4","url":"/notebooks/snowexsql-database#tl-dr-do-less-wrangling-do-more-crunching","position":8},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"TL;DR Do less wrangling, do more crunching.","lvl3":"Technically, what is it?"},"content":"\n\n","type":"content","url":"/notebooks/snowexsql-database#tl-dr-do-less-wrangling-do-more-crunching","position":9},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I get at this magical box of data ?"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-do-i-get-at-this-magical-box-of-data","position":10},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I get at this magical box of data ?"},"content":"SQL\n\nsnowexsql \n\n← 😎","type":"content","url":"/notebooks/snowexsql-database#how-do-i-get-at-this-magical-box-of-data","position":11},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Welcome to API Land","lvl3":"How do I get at this magical box of data ?"},"type":"lvl4","url":"/notebooks/snowexsql-database#welcome-to-api-land","position":12},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Welcome to API Land","lvl3":"How do I get at this magical box of data ?"},"content":"\n\nfrom snowexsql.api import PointMeasurements\n\ndf = PointMeasurements.from_filter(type=\"depth\", instrument='pit ruler', limit=100)\ndf.plot(column='value', cmap='jet', vmin=10, vmax=150)\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#welcome-to-api-land","position":13},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Old Ways / Advanced Users","lvl3":"How do I get at this magical box of data ?"},"type":"lvl4","url":"/notebooks/snowexsql-database#old-ways-advanced-users","position":14},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Old Ways / Advanced Users","lvl3":"How do I get at this magical box of data ?"},"content":"Advanced queries can be made using SQL or SQAlchemy under the hood.\n\nSee previous presentations\n\nEngine objects, session objects, and a crash course in ORM, oh my!\n\nHackweek 2021\n\nHackweek 2022\n\n","type":"content","url":"/notebooks/snowexsql-database#old-ways-advanced-users","position":15},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"How is the Database Structured?"},"type":"lvl2","url":"/notebooks/snowexsql-database#how-is-the-database-structured","position":16},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"How is the Database Structured?"},"content":"The goal of the database is to hold as much of the SnowEx data in one place and make it easier to\ndo research with. With that in mind follow the steps below to see how the the data base is structured.\n\n","type":"content","url":"/notebooks/snowexsql-database#how-is-the-database-structured","position":17},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Where do datasets live (i.e. tables)?","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#where-do-datasets-live-i-e-tables","position":18},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Where do datasets live (i.e. tables)?","lvl2":"How is the Database Structured?"},"content":"Data in the database lives in 1 of 4 places.\n\n\n\nLayout of the database tables\n\nThe 4th table is a table detailing the site information. Lots and lots of metadata for which the API has not been written yet.\n\nSo how does this look in python?\n\nfrom snowexsql.api import PointMeasurements, LayerMeasurements, RasterMeasurements\n\n","type":"content","url":"/notebooks/snowexsql-database#where-do-datasets-live-i-e-tables","position":19},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How are tables structured?","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-are-tables-structured","position":20},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How are tables structured?","lvl2":"How is the Database Structured?"},"content":"Each table consists of rows and columns. Below are the available columns!\n\n# Import the class reflecting the points table in the db\nfrom snowexsql.api import PointMeasurements as measurements\n\n# Grab one measurement to see what attributes are available\ndf = measurements.from_filter(type=\"depth\", limit=1)\n\n# Print out the results nicely\nprint(\"These are the available columns in the table:\\n \\n* {}\\n\".format('\\n* '.join(df.columns)))\n\nTry this: Using what we just did, but swap out PointMeasurements for LayerMeasurements.\n\nQuestion: Did you collect any data? What is it? What table do you think it would go in?\n\nFor more detail, checkout the readthedocs page on \n\ndatabase structure to see how data gets categorized.\n\n","type":"content","url":"/notebooks/snowexsql-database#how-are-tables-structured","position":21},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#bonus-step-learning-to-help-yourself","position":22},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowexsql has a host of resources for you to  help your self. First when you are looking for something be sure to check the snowexsql’s docs.\nThere you will find notes on the database structure. datasets, and of course our new API!","type":"content","url":"/notebooks/snowexsql-database#bonus-step-learning-to-help-yourself","position":23},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Usage/Examples","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl4","url":"/notebooks/snowexsql-database#database-usage-examples","position":24},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Usage/Examples","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowexsql Code\n\nsnowexsql Documentation","type":"content","url":"/notebooks/snowexsql-database#database-usage-examples","position":25},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Building/Notes","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl4","url":"/notebooks/snowexsql-database#database-building-notes","position":26},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Building/Notes","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowex_db Code\n\nsnowex_db Documentation\n\n","type":"content","url":"/notebooks/snowexsql-database#database-building-notes","position":27},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap","position":28},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"How is the Database Structured?"},"content":"You just explored the database structure and discussed how they differ.\n\nYou should know:\n\nWhich table a dataset might live in\n\nWhat columns you can work with (or how to get the available columns)\n\nSome resources to begin helping yourself.\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!\n\n","type":"content","url":"/notebooks/snowexsql-database#recap","position":29},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Forming Queries through the API!"},"type":"lvl2","url":"/notebooks/snowexsql-database#forming-queries-through-the-api","position":30},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Forming Queries through the API!"},"content":"Get familiar with the tools available for querying the database. The simplest way is to use the api classes\n\nsnowexsql.api.PointMeasurements\n\nsnowexsql.api.LayerMeasurements\n\nEach class has to very useful functions\n\nfrom_filter\n\nfrom_area","type":"content","url":"/notebooks/snowexsql-database#forming-queries-through-the-api","position":31},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_filter","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#useful-function-from-filter","position":32},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_filter","lvl2":"Forming Queries through the API!"},"content":"Use the from filter function to find density profiles\n\n# Import in our two classes to access the db\nfrom snowexsql.api import LayerMeasurements\nfrom datetime import datetime \n\n# Find some density pit measurements at the Boise site in december 2019.\ndf = LayerMeasurements.from_filter(\n    type=\"density\",\n    site_name=\"Boise River Basin\",\n    date_less_equal=datetime(2020, 1, 1),\n    date_greater_equal=datetime(2019, 12, 1),\n)\n\n# Plot Example!\ndf.plot()\n\n# Show off the dataframe\ndf\n\n# Analysis Example - Find the bulk density \ndf['value'] = df['value'].astype(float)\nprint(df[['site_id', 'value']].groupby(by='site_id').mean())\n\n","type":"content","url":"/notebooks/snowexsql-database#useful-function-from-filter","position":33},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_area","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#useful-function-from-area","position":34},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_area","lvl2":"Forming Queries through the API!"},"content":"Find specific surface area within a certain distance of a pit.\n\n# Import our api class\nfrom snowexsql.api import LayerMeasurements\nfrom datetime import datetime\nimport geopandas as gpd \n\n# import some gis functionality \nfrom shapely.geometry import Point \n\n# Find some SSA measurements within a distance of a known point\npnt = Point(740820.624625,4.327326e+06)\ndf = LayerMeasurements.from_area(pt=pnt, crs=26912, buffer=500,\n    type='specific_surface_area')\n\n# plot up the results\nax = df.plot()\n\n# plot the site so we can see how close everything is.\nsite = gpd.GeoDataFrame(geometry=[pnt], crs=26912)\nsite.plot(ax=ax, marker='^', color='magenta')\n\n# show off the dataframe\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#useful-function-from-area","position":35},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-do-i-know-what-to-filter-on","position":36},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"content":"We got tools for that! Each class has a host of functions that start with all_* these function return the unique value in that column.\n\nall_types - all the data types e.g. depth, swe, density...\n\nall_instruments - all instruments available in the table\n\nall_dates - all dates listed in the table\n\nall_site_names - all the site names available in the table. e.g. Grand Mesa\n\nfrom snowexsql.api import PointMeasurements\n\n# Instantiate the class to use the properties!\nmeasurements = PointMeasurements()\n\n# Get the unique data names/types in the table\nresults = measurements.all_types\nprint('Available types = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique instrument in the table\nresults = measurements.all_instruments\nprint('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique dates in the table\nresults = measurements.all_dates\nprint('\\nAvailable Dates = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique site names in the table\nresults = measurements.all_site_names\nprint('\\nAvailable sites = {}'.format(', '.join([str(r) for r in results])))\n\n","type":"content","url":"/notebooks/snowexsql-database#how-do-i-know-what-to-filter-on","position":37},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"More specific filtering options","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#more-specific-filtering-options","position":38},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"More specific filtering options","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"content":"Sometimes we need a bit more filtering to know more about what I can filter on. Questions like “What dates was the SMP used?” are a bit more complicated than “Give me all the dates for snowex”\n\nThe good news is, we have tool for that! from_unique_entries is your friend!\n\n# import layer measurements\nfrom snowexsql.api import LayerMeasurements\n\n# Query dates where SMP was used\nLayerMeasurements.from_unique_entries(['date'], instrument='snowmicropen')\n\n","type":"content","url":"/notebooks/snowexsql-database#more-specific-filtering-options","position":39},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#query-nuances","position":40},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"","type":"content","url":"/notebooks/snowexsql-database#query-nuances","position":41},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Limit size","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#limit-size","position":42},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Limit size","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"To avoid accidental large queries, we have added some bumper rails. By default if you ask for more than 1000 records then an error will pop up unless you explicitly say you want more.\n\nTry This: Do a large query. Run the code block below without the limit keyword argument (“kwarg”):\n\n# Import PointMeasurements\nfrom snowexsql.api import PointMeasurements\n\n# Query db using a vague filter or on a huge dataset like GPR but remove the limit kwarg\ndf = PointMeasurements.from_filter(type='two_way_travel', limit=100)\n\n# Show the dataframe\ndf\n\n\n\nWe have added this on the db to allow you to explore without accidentally pulling the entire SnowEx universe down. If you know you want a large query (defined as > 1000) then use the limit = #### option in the from_filter or from_area function.\n\nWarning - It is better to filter using other things besides the limit because the limit is not intelligent. It will simply limit the query by the order of entries that were submitted AND fits your filter. So if you encounter this then consider how to tighten up the filter.","type":"content","url":"/notebooks/snowexsql-database#limit-size","position":43},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"List of Criteria","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#list-of-criteria","position":44},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"List of Criteria","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"You can use lists in your requests too!\n\n# Import layer measurements\nfrom snowexsql.api import LayerMeasurements\n\n# Grab all the data that used the one of these instruments (hint hint SSA)\nssa_instruments = [\"IS3-SP-15-01US\", \"IRIS\",  \"IS3-SP-11-01F\"]\n\n# Query the DB (throw a limit for safety)\nLayerMeasurements.from_filter(instrument=ssa_instruments, limit=100)\n\n","type":"content","url":"/notebooks/snowexsql-database#list-of-criteria","position":45},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Greater than or Less than","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#greater-than-or-less-than","position":46},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Greater than or Less than","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"Sometimes we want to isolate certain ranges of value or even dates. The greater_equal and less_equal terms can be added on to value or dates.\n\ndate_greater_equal\n\ndate_less_equal\n\nvalue_greater_equal\n\nvalue_less_equal\n\n# Import the point measurements class\nfrom snowexsql.api import PointMeasurements\n\n# Filter values > 100 cm from the pulse ecko GPR\ndf = PointMeasurements.from_filter(value_greater_equal=100, type='depth', instrument='pulse EKKO Pro multi-polarization 1 GHz GPR', limit=100)\n\n# Show off the dataframe\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#greater-than-or-less-than","position":47},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap-1","position":48},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Forming Queries through the API!"},"content":"You just came in contact with the new API tools. We can use each API class to pull from specific tables and filter the data.\nYou should know:\n\nHow to build queries using from_filter, from_area, from_unique_entries\n\nDetermine what values to filter on\n\nManage the limit error\n\nFiltering on greater and less than\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!\n\n","type":"content","url":"/notebooks/snowexsql-database#recap-1","position":49},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl2","url":"/notebooks/snowexsql-database#exercise-visualize-a-manual-depth-spiral","position":50},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"During the SnowEx campaigns a TON of manual snow depths were collected, past surveys for hackweek showed an overhelming interest in the manual\nsnow depths dataset. This tutorial shows how easy it is to get at that data in the database while learning how to build queries\n\nGoal: Visualize a small subset of snow depth, ideally a full spiral (mostly cause they are cool!)\n\nApproach:\n\nDetermine the necessary details for isolating manual depths\n\nFind a pit where many spirals were done.\n\nBuffer on the pit location and grab all manual snow depths\n\n","type":"content","url":"/notebooks/snowexsql-database#exercise-visualize-a-manual-depth-spiral","position":51},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl3","url":"/notebooks/snowexsql-database#process","position":52},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\nfrom snowexsql.api import LayerMeasurements\ndata_type = 'depth'\n\n","type":"content","url":"/notebooks/snowexsql-database#process","position":53},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 1: Find a pit of interest","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-1-find-a-pit-of-interest","position":54},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 1: Find a pit of interest","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# Pick the first one we find\nsite_id = LayerMeasurements().all_site_ids[0]\n\n# Query the database, we only need one point to get a site id and its geometry\nsite_df = LayerMeasurements.from_filter(site_id=site_id, limit=1)\n\n# Print it out \nsite_df\n\n","type":"content","url":"/notebooks/snowexsql-database#step-1-find-a-pit-of-interest","position":55},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 2: Collect Snow Depths","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-2-collect-snow-depths","position":56},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 2: Collect Snow Depths","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# We import the points measurements because snow depths is a single value at single location and date\nfrom snowexsql.api import PointMeasurements \n\n# Filter the results to within 100m within the point from our pit\ndf = PointMeasurements.from_area(pt=site_df.geometry[0], type=data_type, buffer=200)\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#step-2-collect-snow-depths","position":57},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 3: Plot it!","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-3-plot-it","position":58},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 3: Plot it!","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# Get the Matplotlib Axes object from the dataframe object, color the points by snow depth value\nax = df.plot(column='value', legend=True, cmap='PuBu')\nsite_df.plot(ax=ax, marker='^', color='m')\n\n# Use non-scientific notation for x and y ticks\nax.ticklabel_format(style='plain', useOffset=False)\n\n# Set the various plots x/y labels and title.\nax.set_title(f'{len(df.index)} Manual Snow depths collected at {site_id}')\nax.set_xlabel('Easting [m]')\nax.set_ylabel('Northing [m]')\n\n\nTry This:\n\nA. Go back and add a filter to reduce to just one spiral. What would you change to reduce this?\n\nB. Try to filtering to add more spirals. What happens?","type":"content","url":"/notebooks/snowexsql-database#step-3-plot-it","position":59},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap-2","position":60},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"You just plotted snow depths and reduce the scope of the data by using from_area on it\n\nYou should know:\n\nManual depths are neat.\n\nfilter using from area is pretty slick.\n\nWe can use LayerMeasurements to get site details easily.\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!","type":"content","url":"/notebooks/snowexsql-database#recap-2","position":61},{"hierarchy":{"lvl1":"Thermal Infrared"},"type":"lvl1","url":"/notebooks/thermal-ir-tutorial","position":0},{"hierarchy":{"lvl1":"Thermal Infrared"},"content":"Learning Objectives\n\nAt the conclusion of this tutorial, you will be able to:\n\nunderstand the differences between sources of thermal IR observations, the advantages and disadvantages of each, and types of research questions we can address with those observations\n\nvisualize point and raster thermal infrared datasets together, then compute error statistics between point and raster datasets\n\naccess and visualize airborne and satellite thermal infrared imagery, then scale imagery of different spatial resolutions for comparison\n\nDownload the sample datasets for this tutorial\n\nFor ease of access during the hackweek, sample files are available for download for running the command in the cell below. (See the bonus notebook “\n\nthermal​-ir​-data​-download​.ipynb” for more details about data access methods)\n\n# S3 base URL for tutorial data\nS3_BASE_URL = \"https://snowex-tutorials.s3.us-west-2.amazonaws.com/thermal-ir/\"\n\nImport the packages we’ll need for this tutorial\n\n# Import some general-purpose packages for handling different data structures\nimport numpy as np # for working with n-D arrays\nimport pandas as pd # for reading our csv data file and working with tabular data\n\n# Import matplotlib which we'll use for plotting images and graphs\nimport matplotlib.pyplot as plt\n\n# Import these packages for working with raster data\nimport xarray as xr # xarray lets us work with n-D arrays and labeled data, such as NetCDF files\nimport rioxarray # rioxarray provides capabilities of the rasterio package to xarray, letting us easily work with files such as GeoTIFFs\nimport fsspec\n\n# Import some packages for working with the SnowEx SQL database\nfrom snowexsql.db import get_db # Import the connection function from the snowexsql library\nfrom  snowexsql.data import SiteData # Import the table classes from our data module which is where our ORM classes are defined \nfrom datetime import date # Import some tools to build dates \nfrom snowexsql.conversions import query_to_geopandas # Import a useful function for plotting and saving queries! See https://snowexsql.readthedocs.io/en/latest/snowexsql.html#module-snowexsql.conversions\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial","position":1},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl2","url":"/notebooks/thermal-ir-tutorial#part-1-comparing-airborne-ir-imagery-with-ground-truth-observations","position":2},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"","type":"content","url":"/notebooks/thermal-ir-tutorial#part-1-comparing-airborne-ir-imagery-with-ground-truth-observations","position":3},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Airborne IR imagery","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#airborne-ir-imagery","position":4},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Airborne IR imagery","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"\n\nThe Naval Postgraduate School Twin Otter aircraft carried the UW APL thermal infrared imager and SWESARR instrument over Grand Mesa for SnowEx 2020. (Photo by Chris Chickadel)\n\nLoad IR image mosaic geotiff file\n\nairborne_ir = rioxarray.open_rasterio(S3_BASE_URL + 'SNOWEX2020_IR_PLANE_2020Feb08_mosaicked_2020-02-08T181915.tif')\n\nInspect the contents of the file we just opened\n\nairborne_ir\n\nairborne_ir.rio.crs # original CRS\n\nUnder the dataarray’s attributes we can see that we have a coordinate reference system already defined (crs) as \n\nEPSG:32612. We can also find this through da.rio.crs.\n\nHowever, we would like to reproject this into the common projection used by datasets on the SnowEx SQL database: \n\nEPSG:26912. We can do that using rioxarray’s \n\nreproject method (see an example \n\nhere).\n\nNOTE: Reprojections typically require a lot of processing time, so expect this cell to run for up to 1 minute.\n\nairborne_ir = airborne_ir.rio.reproject('EPSG:26912') # overwrite itself with new reprojected data array\n\nairborne_ir.rio.crs # new CRS\n\nNext, the filename shows us when this imagery was taken in UTC time, “2020-02-08T181915”\n\nWe can create a pandas timestamp variable in local time for comparison with other datasets:\n\n# Create a pandas timestamp, subtract 7 hours from UTC time to get local time (MST, UTC-7)\nairborne_ir_timestamp = pd.Timestamp(2020,2,8,18,19,15) - pd.Timedelta(hours=7)\n\nWhat color scale should we use for temperature?\n\nCommon advice you may have heard is to \n\navoid using rainbow color scales. Luckily \n\nmatplotlib gives us lots of options to choose from.\n\nWhen representing images of temperature, sometimes we want to pick colors that intuitively suggest temperature, such as the “magma” colorbar below. Other times we might be interested in both magnitude and sign, such as temperatures above or below melting point, in which case we could use something like “RdBu_r” below. I often pick simple greyscale, though less visually interesting, it is sometimes easier to pick out details in a continuous color scale like they “Greys” scale below. Make sure to include a labeled colorbar so your plot can be correctly interpreted!\n\nSome matplotlib color scale options (top to bottom): “magma”, “RdBu_r”, “Greys”\n\nPlot the airborne TIR image.\n\nWhat does our chosen colorscale tell us about temperatures here?\n\nWhat can we see?\n\nfig, ax = plt.subplots(figsize=(20,10)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10,ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\nax.set_title('Airborne TIR imagery of Grand Mesa, CO (Feb. 8, 2020)');\n\nImage interpretation\n\nWhat does our chosen colorscale tell us about temperatures here?\n\nThe colorbar on the right shows us that colder temperatures are represented with dark purple to black colors.\n\nWarmer temperatures are represented with lighter orange/yellow.\n\nWhat can we see?\n\nWe see a narrow stripe of imagery, this is a mosaic of individual camera images taken from the aircraft along a single flight line over Grand Mesa.\n\nOn the left (west) side of the image we see warmer but varied temperatures (yellow, orange, and purple), then an abrupt transition to uniformly cold temperatures (purple). This is the westernmost edge of the mesa where the snow on top is much colder than the lower elevation slopes of the mountain.\n\nContinuing to move from left (west) to right (east) we see patches of lighter colors, corresponding with warmer temperatures. These are patches of forest on the central and eastern portions of the mesa.\n\nFinally near the easternmost side of the image we see a very dark region that means it is much colder than the rest of the scene. What might this cold area or object be?\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#airborne-ir-imagery","position":5},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Bonus activity:","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#bonus-activity","position":6},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Bonus activity:","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"To help with our image interpretation, we can load visible imagery taken concurrently from the UW-APL airborne instrument. (Note: this example image is a single band black and white image, though we also have full RGB images available through NSIDC)\n\nairborne_vis = rioxarray.open_rasterio(S3_BASE_URL + 'SNOWEX2020_EO_PLANE_2020Feb08_mosaicked_2020-02-08T181915.tif')\n\n# note that the filename is identical with the same timestamp, but is labeled \"EO\" (electro-optical) rather than \"IR\" (infrared)\n\n# Also reproject the airborne visible imagery into EPSG:26912\nairborne_vis = airborne_vis.rio.reproject('EPSG:26912') # overwrite itself with new reprojected data array\n\nairborne_vis\n\nPlot the visible and infrared images side by side. This time, we will change the x and y axes limits (\n\nset_xlim, and \n\nset_ylim) to zoom in closer.\n\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(20,10), tight_layout=True)\n\n# Plot the IR imagery\nairborne_ir.plot(ax=axs[0], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('Airborne IR')\n\n# Plot the visible imagery\nairborne_vis.plot(ax=axs[1], \n                  cmap='Greys_r',\n                  cbar_kwargs={'label': 'DN'})\naxs[1].set_title('Airborne Vis')\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # give each axis a label\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_ylabel('Northings UTM 12N (m)')\n    \n    # set the axes limits, units in meters UTM Zone 12N (I chose these values by just looking at the plot above)\n    ax.set_xlim((735000, 760000)) # x axis limits\n    ax.set_ylim((4320000, 4325000)) # y axis limits\n\nImage interpretation\n\nThe visible imagery camera covers a slightly narrower width along the flight path than the IR cameras.\n\nNow what do you think the cold object on the eastern side of the image is?\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#bonus-activity","position":7},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Ground-based temperature observations","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#ground-based-temperature-observations","position":8},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Ground-based temperature observations","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"To provide a source of “ground truth” for the airborne and satellite thermal infrared images during the SnowEx 2020 Grand Mesa campaign, we can use ground-based snow surface temperature measurements. On February 5, 2020, we installed a thermal infrared radiometer pointing at the snow surface at snow pit #2S10 (left), and buried temperature sensors beneath the snow surface (right). These logged observations at 5-minute intervals until we removed the instrumentation a week later on February 12.\n\nSnow temperature sensor setup at snow pit 2S10: (left) tripod-mounted thermal ifrared radiometer to measure snow surface, (right) temperature probes to be buried beneath the snow surface.(Photos by Steven Pestana)\n\nWhat are some of the differences we might expect to see between the ground-based surface temperature data and the thermal IR images?\n\nEmissivity differences?\n\nOur ground-based radiometer was looking at 45 deg off nadir, versus nadir ASTER versus variable view angle airborne (snow emissivity changes off-nadir)\n\nDifferent TIR bandwidths (broad versus narrow)?\n\nGround-based radiometer: 8-14 μm, Airborne IR cameras: 8-14 μm, ASTER band 14: 10.95-11.65 µm\n\nDifferent atmospheric path lengths?\n\nFrom <1 meter, to 1 km, to entire atmospheric column (~100 km)\n\n“Point” versus area, and geolocation accuracy\n\nThe ground-based radiometer is measuring temperature for a spot (not really a single point) maybe ~1m in diameter. The airborne and ASTER imagers have spatial resolutions of 5m and 90m respectively. How confident are we in the geolocation of individual pixels in the imagery?\n\nWhere is snow pit 2S10?\n\nWe can find this information through a query to the SnowEx SQL database. First, set up the connection:\n\n# This is what you will use for all of hackweek to access the db\ndb_name = 'snow:hackweek@db.snowexdata.org/snowex'\n# Using the function get_db, we receive 2 ways to interact with the database\nengine, session = get_db(db_name)\n\nThen, query \n\nSiteData using \n\nfilter_by to find the entry with the site ID that we want (2S10). Preview the resulting geodataframe.\n\n# Form the query to receive site_id='2S10' from the sites table\nqry = session.query(SiteData).filter_by(site_id='2S10')\n\n# Convert the record received into a geopandas dataframe\nsiteData_df = query_to_geopandas(qry, engine)\n\n# Preview the resulting geopandas dataframe\nsiteData_df\n\nInspect of the geodatframe’s metadata\n\n# What is the coordinate reference system used here?\nsiteData_df.crs\n\n# Preview the geometry of this geodataframe, we should see that it is a POINT\nsiteData_df.geometry\n\nWe can now plot our snow pit site from this \n\ngeodataframe on top of the airborne IR image. (See more tips about plotting geodataframes \n\nhere)\n\nfig, ax = plt.subplots(figsize=(20,5)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10, ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\n# set the axes limits, units in meters UTM Zone 12N (I chose these values by just looking at the plot above)\nax.set_xlim((735000, 760000)) # x axis limits\nax.set_ylim((4320000, 4325000)) # y axis limits\n\n# set plot title\nax.set_title('Location of Snow Pit 2S10\\nwith Airborne TIR imagery of Grand Mesa, CO (Feb. 8, 2020)');\n\nChange the x and y axes limits (\n\nset_xlim, and \n\nset_ylim) to zoom in to our point of interest. In this case we can use \n\ndf​.geometry​.total​_bounds to get the x and y values that define the area our geometry takes up. (In this case we have a point so it will return just the point’s location, but this would work if we had a polygon as well)\n\nfig, ax = plt.subplots(figsize=(10,10)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10, ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n\n# set axes limits\nxmin, ymin, xmax, ymax = siteData_df.geometry.total_bounds # get the \"total bounds\" for our geometry\nax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\nax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\n# set plot title\nax.set_title('Location of Snow Pit 2S10\\nAirborne TIR imagery of Grand Mesa, CO (Feb. 8, 2020)');\n\nImport the snow temperature timeseries dataset\n\nThis data is \n\navailable through NSIDC, but we have already downloaded a local copy for this tutorial. (See the bonus notebook \n\nthermal​-ir​-data​-download​.ipynb for more details about data access methods)\n\nThe raw data file doesn’t include the column names, so we need to set the column headers following the dataset’s README file.\n\n!cat data/snow-temperature-README.txt\n\nCreate a list of column headers according to the readme above (for “GM1” which we can read was the datalogger at snowpit 2S10)\n\ncolumn_headers = ['table', 'year', 'doy', 'time', # year, day of year, time of day (local time, UTC-7)\n                  'rad_avg', 'rad_max', 'rad_min', 'rad_std', # radiometer surface temperature\n                  'sb_avg', 'sb_max', 'sb_min', 'sb_std', # radiometer sensor body temperature (for calibration)\n                  'temp1_avg', 'temp1_max', 'temp1_min', 'temp1_std', # temperature at 5 cm below snow surface\n                  'temp2_avg', 'temp2_max', 'temp2_min', 'temp2_std', #               10 cm\n                  'temp3_avg', 'temp3_max', 'temp3_min', 'temp3_std', #               15 cm\n                  'temp4_avg', 'temp4_max', 'temp4_min', 'temp4_std', #               20 cm\n                  'temp5_avg', 'temp5_max', 'temp5_min', 'temp5_std', #               30 cm\n                  'batt_a','batt_b', # battery voltage data\n                 ]\n\nOpen the file as a pandas data frame with \n\nread_csv\n\ndf = pd.read_csv(f'data/CR10X_GM1_final_storage_1.dat',\n                 header = None, names = column_headers) \n\n# After the filepath we specify header=None because the file doesn't contain column headers, \n# then we specify names=column_headers to give our own names for each column.\n\nWe need to do some formatting of the data fields, but we can preview what we just loaded fist\n\ndf.head() # show the first 5 rows of the dataframe\n\nData cleanup and formatting\n\n# Create a zero-padded time string (e.g. for 9:30 AM we are changing '930' into '0930')\ndf['time_str'] = [('0' * (4 - len(str(df.time[i])))) + str(df.time[i]) for i in range(df.shape[0])]\n\n# locate where rows have time_str == 2400 (midnight), and the whole column 'doy'\n# where we are at midnight, we need to shift one day forward\ndf.loc[df['time_str'] == '2400','doy'] += 1\n\n# and then change midnight from '2400' to '0000'\ndf.time_str.replace('2400', '0000', inplace=True)\n\nThis function lets us convert year and day of year (the format that the datalogger uses) to a pandas \n\ndatetime index:\n\ndef compose_date(years, months=1, days=1, weeks=None, hours=None, minutes=None,\n                 seconds=None, milliseconds=None, microseconds=None, nanoseconds=None):\n    '''Compose a datetime object from various datetime components. This clever solution is from:\n        https://stackoverflow.com/questions/34258892/converting-year-and-day-of-year-into-datetime-index-in-pandas'''\n    years = np.asarray(years) - 1970\n    months = np.asarray(months) - 1\n    days = np.asarray(days) - 1\n    types = ('<M8[Y]', '<m8[M]', '<m8[D]', '<m8[W]', '<m8[h]',\n             '<m8[m]', '<m8[s]', '<m8[ms]', '<m8[us]', '<m8[ns]')\n    vals = (years, months, days, weeks, hours, minutes, seconds,\n            milliseconds, microseconds, nanoseconds)\n    return sum(np.asarray(v, dtype=t) for t, v in zip(types, vals)\n               if v is not None)\n\n# Create a datetime value from the date field and zero-padded time_str field, set this as our dataframe's index\ndf.index = compose_date(df['year'], \n                        days=df['doy'], \n                        hours=df['time_str'].str[:2],\n                        minutes=df['time_str'].str[2:])\n\n# Remove entries that are from table \"102\" (this contains datalogger battery information we're not interested in at the moment)\ndf = df[df.table != 102]\n\n# drop the columns we no longer need\ndf.drop(columns=['table','year','doy','time','time_str','batt_a','batt_b'], inplace=True)\n\nInspect the contents\n\ndf.head()\n\nMake a simple plot of the data. We are interested in the variable rad_avg which is the average temperature measured by the radiometer over each 5 minute period.\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n\n# set axes limits\nplt.ylim((-35,5))\nplt.xlim((pd.Timestamp(2020,2,5,11,0),pd.Timestamp(2020,2,12,16,0)))\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel(r'Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\nBonus plot: look at snow temperatures below the snow surface\n\nAdd the following to the above plot to add lines for temperature recorded at each depth interval below the snow surface:# plot the snow temperature at each depth it was measured\ndf.temp1_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.8,0.8,1], label='Ts @ -5 cm')\ndf.temp2_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.6,0.6,1], label='Ts @ -10 cm')\ndf.temp3_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.4,0.4,1], label='Ts @ -15 cm')\ndf.temp4_avg.plot(linestyle='-', marker='.', markersize=1, c=[0.2,0.2,1], label='Ts @ -20 cm')\ndf.temp5_avg.plot(linestyle='-', marker='.', markersize=1, c=[0,0,1], label='Ts @ -30 cm')\n\nBut then we want to focus on the date/time when our IR image was from, so zoom in on Feb 8th by changing our plot’s \n\nxlim (using pandas \n\nTimestamps for the x axis values).\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n# set axes limits\nplt.ylim((-15,0)) # set some temperature y-axis limits for our plot\nplt.xlim((pd.Timestamp(2020,2,8,6,0),pd.Timestamp(2020,2,8,20,0))) # zoom in to daytime hours on Feb. 8, 2020\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel(r'Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#ground-based-temperature-observations","position":9},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Compare Airborne IR against the “ground truth” snow surface temperature","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#compare-airborne-ir-against-the-ground-truth-snow-surface-temperature","position":10},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Compare Airborne IR against the “ground truth” snow surface temperature","lvl2":"Part 1: Comparing airborne IR imagery with ground-truth observations"},"content":"What is the temperature at this point in the airborne IR image?\n\nUse rioxarray’s \n\nclip function to extract the raster values that intersect with the point’s geometry. Because we have a point, this will return a single value for the pixel that overlaps this point.\n\n# clip using our point's geometry\nairborne_ir_point_temperature = airborne_ir.rio.clip(siteData_df.geometry)\n\n# preview the result\nairborne_ir_point_temperature\n\nOur result is a DataArray with a single data value at one set of x and y coordinates.\n\nPixel = Point ?\n\nShould we expect that the temperature measured for an image pixel would be the same for an individual point on the ground? The airborne imagery is at 5 meter spatial resolution, whereas our ground-based radiometer measured a spot maybe only ~1 m in diameter. Additionally, the geolocation of the airborne imagery is less accurate than 5 meters (closer to 10-15 meters) meaning that if we picked a single pixel to overlap our ground point, it may be the wrong pixel. Let’s instead look at the average and distribution of temperatures from the airborne imagery in an area around this point.\n\nAdd a 100 m radius \n\nbuffer around this point and get the temperature from the airborne imagery for a larger area around the snow pit.\n\nr = 100 # radius of the buffer in meters (this is in meters because we are working in a UTM coordinate reference system)\n\n# create the buffered geometry\nsiteData_df_buffer = siteData_df.buffer(r)\n\n# preview the resulting geometry, we should see this is a POLYGON now\nsiteData_df_buffer\n\nWhat does this polygon look like when we plot it on top of the airborne IR image now?\n\nfig, ax = plt.subplots(figsize=(10,10)) # create a new matplotlib figure, set the figure size\nax.set_aspect('equal') # set the aspect ratio to \"equal\"\n\n# plot the airborne infrared image\nairborne_ir.plot(cmap='magma', vmin=-10, vmax=10, ax=ax, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n\n# set the same axes limits as above\nax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\nax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n\n# set plot title\nax.set_title('Location of Snow Pit 2S10, and 100 m radius buffer\\nwith ASTER Band 14 TIR imagery');\n\nClip the airborne IR raster again, now with our 200 m diameter polygon around the snow pit site.\n\n# clip using our new geometry\nairborne_ir_area_temperature = airborne_ir.rio.clip(siteData_df_buffer.geometry)\n\n# preview the result\nairborne_ir_area_temperature\n\nThe result of clipping is again a DataArray, this time though it is 40x40. We can plot this to see what it looks like, and to see the distribution of temperatures in the area.\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5), tight_layout=True)\n\n# plot the portion of the airborne TIR image we selected within the buffer area geometry\nairborne_ir_area_temperature.plot(cmap='magma', vmin=-7, vmax=-4, ax=ax[0], \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\nax[0].set_title('Airborne TIR image within\\n100 m radius buffer (2S10)\\n')\nax[0].set_aspect('equal')\nax[0].set_xlabel('Eastings UTM 12N (m)')\nax[0].set_ylabel('Northings UTM 12N (m)')\nax[0].set_xlim((xmin-150, xmax+150)) # x axis limits to +/- 150 m from our point's \"total bounds\"\nax[0].set_ylim((ymin-150, ymax+150)) # y axis limits to +/- 150 m from our point's \"total bounds\"\n\n# plot the location of the snow pit of interest to the plot\nsiteData_df.plot(ax=ax[0], color='c', marker='x')\n\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax[0], edgecolor='c', facecolor='none')\n\n# plot a histogram of image temperature data within the buffer area geometry\nairborne_ir_area_temperature.plot.hist(ax=ax[1],\n                                       color='k', \n                                       zorder=1, # use zorder to make sure this plots below the point\n                                       label='zonal $T_S$ histogram') \n\n# plot a vertical line for the single-pixel temperature we think is right at the snow pit\nax[1].axvline(airborne_ir_point_temperature, \n              color='c',linestyle='--',  # set color and style\n              zorder=2, # use zorder to make sure this plots on top of the histogram\n              label='$T_S$ single pixel') \n\n# plot a vertical line for the mean temperature within the buffer area geometry\nax[1].axvline(airborne_ir_area_temperature.mean(), \n              color='m',linestyle='--',  # set color and style\n              zorder=2, # use zorder to make sure this plots on top of the histogram\n              label='zonal mean $T_S$') \n\nax[1].legend(loc='upper left') # add a legend\nax[1].set_xlim((-7,-4)) # set xlim to same values as colorbar in image plot\nax[1].set_ylim((0,400)) # set ylim\nax[1].set_title('Snow surface temperatures\\nfrom Airborne TIR image (snow pit 2S10)')\nax[1].set_ylabel('Number of pixels');\n\nWhat do these plots tell us about the surface temperature around the snow pit as measured by the airborne IR cameras?\n\nIs the snow surface temperature more variable or uniform in this area?\n\nNote that we changed the minimum and maximum values of our colorbar!\n\nTry computing the standard deviation of temperatures in this area\n\nHow does our single pixel at the center compare with the rest of this area?\n\nTry taking the mean or median of all temperatures in the area and compare against the single point. What is the difference?\n\nSee \n\nLundquist et al., 2018 for an application of these methods with airborne and MODIS thermal infrared imagery\n\nPlot the airborne IR temperature data on top of the ground-based timeseries\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n# plot the mean airborne IR temperature from the area around the snow pit:\nplt.plot(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n         marker='o', c='r', linestyle='none',\n         label='Airborne IR mean $T_s$ for 100 m radius area')\n\n# plot an error bar showing the maximum and minimum airborne IR temperature around the snow pit\nplt.errorbar(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n             yerr=[[airborne_ir_area_temperature.mean()-airborne_ir_area_temperature.min()], \n                   [airborne_ir_area_temperature.max()-airborne_ir_area_temperature.mean()]],\n            capsize=3, fmt='none', ecolor='r',\n            label='Airborne IR $T_s$ range for 100 m radius area')\n\n\n# set axes limits\nplt.ylim((-15,0))\nplt.xlim((pd.Timestamp(2020,2,8,6,0),pd.Timestamp(2020,2,8,20,0))) # zoom in to daytime hours on Feb. 8, 2020\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel(r'Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\nContinuing with this analysis:\n\nIn the above plot we’ve added “error bars” to represent the full range of temperatures within the 100 m radius area around the snow pit.\n\nIs this a fair comparison?\n\nShould we make the area smaller based on our confidence in the image’s geolocation accuracy (10-15 m)?\n\nWhat is the difference between the “ground truth” data and the airborne IR data at this point in time?\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#compare-airborne-ir-against-the-ground-truth-snow-surface-temperature","position":11},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"type":"lvl2","url":"/notebooks/thermal-ir-tutorial#part-2-satellite-ir-remote-sensing-obsevations","position":12},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"content":"","type":"content","url":"/notebooks/thermal-ir-tutorial#part-2-satellite-ir-remote-sensing-obsevations","position":13},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#satellite-ir-imagery-with-aster","position":14},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"content":"Advantages of satellite IR images: We don’t always have airplanes with IR cameras flying around. Satellites can provide images at more regular intervals for long-term studies, and can see areas that are difficult to access on the ground or by air.\n\nWhat might be some diadvantages of satellite IR imagery compared to airborne IR imagery?\n\nLower spatial resolution because they’re further away from the Earth’s surface\n\nMixed pixel problem: with lower image resolutions, each pixel contains a more heterogeneous mixtures of surfaces and temperatures, meaning that temperature information is more blurred together\n\nWhat other disadvantages can you think of?\n\nHow might these differences (advantages or disadvantages) change the type of research questions you can investigate?\n\nFor this tutorial, we will look at an image from NASA’s \n\nAdvanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) imager, which is onboard the Terra satellite along with a MODIS imager. We can compare an ASTER IR image of Grand Mesa that was taken at roughly the same time as the airborne IR image. The ASTER image we will be working with is from ASTER’s \n\nband 14 which is sensitive to radiance in the 10.95-11.65 µm wavelength range.\n\nLoad an ASTER geotiff that we’ve downloaded for this tutorial, and inspect its contents.\n\naster_ir = rioxarray.open_rasterio(S3_BASE_URL + 'AST_L1T_00302082020180748_20200209065849_17218_ImageData14.tif')\n\nInspect the ASTER file we just opened\n\naster_ir\n\nWhat is its CRS?\n\naster_ir.rio.crs\n\n# Reproject this ASTER image into our common coordinate system\naster_ir = aster_ir.rio.reproject('EPSG:26912') # overwrite itself with new reprojected data array\n\nWhen was this image taken?\n\naster_ir_timestamp = pd.Timestamp(2020,2,8,18,7,48) - pd.Timedelta(hours=7)\n\nPlot the image. What are the units of the values on the colorbar?\n\naster_ir.plot()\n\nIt’s necessary to read the product documentation to understand what we are looking at here.\n\nWe are using the ASTER Level 1 Precision Terrain Corrected Registered At-Sensor Radiance (AST_L1T) product. \n\nProduct documentation is available here. Also helpful is the ** (AST_L1B) \n\nproduct documentation here from which AST_L1T is derived.\n\nThe values here are stored as scaled “digital number” (DN) values rather than the actual radiance values. The product documentation also provides information about how to unscale these values back into radiance units, and from radiance to brightness temperature, using laboratory calibrated constants.\n\nI’ve written two functions here to do this unit conversion for the five ASTER TIR bands in two steps (DN to radiance, radiance to brightness temperature). The function takes as its arguments the DN or radiance values respectively, and the band number (in our case band number 14, not the band wavelengths).\n\ndef tir_dn2rad(DN, band):\n    '''Convert AST_L1T Digital Number values to At-Sensor Radiance for the TIR bands (bands 10-14).'''\n    ucc = [6.822e-3, 6.780e-3, 6.590e-3, 5.693e-3, 5.225e-3]\n    rad = (DN-1.) * ucc[band-10]\n    return rad\n\ndef tir_rad2tb(rad, band):\n    '''Convert AST_L1T At-Sensor Radiance to Brightness Temperature [K] for the TIR bands (bands 10-14).'''\n    k1 = [3047.47, 2480.93, 1930.80, 865.65, 649.60]\n    k2 = [1736.18, 1666.21, 1584.72,1349.82, 1274.49]\n    tb = k2[band-10] /  np.log((k1[band-10]/rad) + 1)\n    return tb\n\nUse the above functions to convert from DN to radiance, radiance to brightness temperature (assume and emissivity of 1 for all surfaces, note that the airborne imagery also assumed emissivity of 1).\n\nThen convert from degeees K to degrees C by subtracting 273.15.\n\naster_band14_rad = tir_dn2rad( aster_ir, band=14 ) # convert from DN to radiance\naster_band14_tb_k = tir_rad2tb( aster_band14_rad, band=14 ) # convert from radiance to brightness temperature (K)\naster_band14_tb_c = aster_band14_tb_k - 273.15 # convert from K to C\n\n# Note that an \"invalid value encountered...\" warning may pop up here. This is because the above function tries to take the log of \"nan\" values that are outside the imaged area\n# we can ignore this warning and proceed\n\nDuring this unit conversion, xarray dropped the coordinate reference system attributes, so here we add the original crs to the new ASTER degrees celsius dataarray.\n\naster_band14_tb_c.rio.set_crs(aster_ir.rio.crs, inplace=True);\n\nPlot our image again, this time setting our colorscale and colorbar values. We should see “realistic” surface temperature values in degrees C now.\n\nfig, ax = plt.subplots(figsize=(15,10))\nax.set_aspect('equal')\naster_band14_tb_c.plot(ax=ax,\n                       cmap='magma', \n                       vmin=-20, vmax=20, # note that we have a wider temperature range on our colorbar for this image, -20 to +20 C instead of -10 to +10 C\n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\n\nImage interpretation\n\nWhat does our chosen colorscale tell us about temperatures here?\n\nWhat can we see?\n\nWhat do you think that cold linear feature across the image is? (Hint: think about the cold object we saw in the airborne IR image)\n\n\n\nPlot ASTER next to Airborne IR to see spatial resolution differences\n\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12,6), tight_layout=True)\n\naster_band14_tb_c.plot(ax=axs[0], \n                       cmap='magma', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('ASTER IR')\naxs[0].set_aspect('equal')\n\n\nairborne_ir.plot(ax=axs[1], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[1].set_title('Airborne IR')\naxs[1].set_aspect('equal')\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # plot the location of the snow pit of interest\n    siteData_df.plot(ax=ax, color='r', marker='x')\n    # plot the area of the buffer we made around the snow pit\n    siteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n    \n    # set axes labels and limits\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_xlim((735000, 760000))\n    ax.set_ylabel('Northings UTM 12N (m)')\n    ax.set_ylim((4320000, 4325000))\n\nMake another plot to zoom in on snow pit 2S10:\n\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,4), tight_layout=True)\n\naster_band14_tb_c.plot(ax=axs[0], \n                       cmap='magma', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('ASTER IR')\naxs[0].set_aspect('equal')\n\n\nairborne_ir.plot(ax=axs[1], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[1].set_title('Airborne IR')\naxs[1].set_aspect('equal')\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # plot the location of the snow pit of interest\n    siteData_df.plot(ax=ax, color='r', marker='x')\n    # plot the area of the buffer we made around the snow pit\n    siteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n    \n    # set axes labels\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_ylabel('Northings UTM 12N (m)')\n    # set the same axes limits as above\n    ax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\n    ax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\nGet the temperature of the ASTER pixel at the snow pit point using rioxarray \n\nclip.\n\n# First clip to the single point\naster_band14_tb_c_point_temperature = aster_band14_tb_c.rio.clip(siteData_df.geometry)\n\n# Second clip to the 100 m radius buffered area\naster_band14_tb_c_area_temperature = aster_band14_tb_c.rio.clip(siteData_df_buffer.geometry)\n\n# preview the result\naster_band14_tb_c_area_temperature\n\nHow many ASTER pixels in the area did we select?\n\nPlot the clipped area:\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,5), tight_layout=True)\n\n# plot the portion of the airborne TIR image we selected within the buffer area geometry\naster_band14_tb_c_area_temperature.plot(cmap='magma', vmin=-7, vmax=-4, ax=ax[0], \n                 cbar_kwargs={'label': 'Temperature $\\degree C$'})\nax[0].set_title('ASTER TIR image within\\n100 m radius buffer (2S10)\\n')\nax[0].set_aspect('equal')\nax[0].set_xlabel('Eastings UTM 12N (m)')\nax[0].set_ylabel('Northings UTM 12N (m)')\nax[0].set_xlim((xmin-150, xmax+150)) # x axis limits to +/- 150 m from our point's \"total bounds\"\nax[0].set_ylim((ymin-150, ymax+150)) # y axis limits to +/- 150 m from our point's \"total bounds\"\n\n# plot the location of the snow pit of interest to the plot\nsiteData_df.plot(ax=ax[0], color='r', marker='x')\n\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax[0], edgecolor='r', facecolor='none')\n\n# plot a histogram of image temperature data within the buffer area geometry\naster_band14_tb_c_area_temperature.plot.hist(ax=ax[1], color='k');\nax[1].set_xlim((-7,-4)) # set xlim to same values as colorbar in image plot\nax[1].set_title('Histogram of temperatures from ASTER TIR image\\n100 m radius buffer (2S10)')\nax[1].set_ylabel('Number of pixels');\n\nPlot the ASTER IR temperature data on top of the ground-based timeseries and airborne IR temperature\n\nplt.figure(figsize=(10,4))\n\n# plot radiometer average temperature\ndf.rad_avg.plot(linestyle='-', marker='', markersize=1, c='k', label='Ground-based $T_s$')\n\n# plot the mean airborne IR temperature from the area around the snow pit:\nplt.plot(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n         marker='o', c='r', linestyle='none',\n         label='Airborne IR mean $T_s$ for 100 m radius area')\n# plot an error bar showing the maximum and minimum airborne IR temperature around the snow pit\nplt.errorbar(airborne_ir_timestamp, airborne_ir_area_temperature.mean(),\n             yerr=[[airborne_ir_area_temperature.mean()-airborne_ir_area_temperature.min()], \n                   [airborne_ir_area_temperature.max()-airborne_ir_area_temperature.mean()]],\n            capsize=3, fmt='none', ecolor='r',\n            )#label='Airborne IR $T_s$ range for 100 m radius area')\n\n# plot the mean ASTER IR temperature from the area around the snow pit:\nplt.plot(aster_ir_timestamp, aster_band14_tb_c_area_temperature.mean(),\n         marker='o', c='b', linestyle='none',\n        label='ASTER IR mean $T_s$ for 100 m radius area')\n# plot an error bar showing the maximum and minimum ASTER IR temperature around the snow pit\nplt.errorbar(aster_ir_timestamp, aster_band14_tb_c_area_temperature.mean(),\n             yerr=[[aster_band14_tb_c_area_temperature.mean()-aster_band14_tb_c_area_temperature.min()], \n                   [aster_band14_tb_c_area_temperature.max()-aster_band14_tb_c_area_temperature.mean()]],\n            capsize=3, fmt='none', ecolor='b',\n            )#label='ASTER IR $T_s$ range for 100 m radius area')\n\n\n# set axes limits\nplt.ylim((-15,0))\nplt.xlim((pd.Timestamp(2020,2,8,6,0),pd.Timestamp(2020,2,8,20,0))) # zoom in to daytime hours on Feb. 8, 2020\n\n# add a legend to the plot\nplt.legend()\n\n# set axes labels\nplt.ylabel('Temperature [$C\\degree$]')\nplt.xlabel('Time')\n\n# add grid lines to the plot\nplt.grid('on')\n\n# set the plot title\nplt.title('Snow Surface Temperature at Snow Pit 2S10');\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#satellite-ir-imagery-with-aster","position":15},{"hierarchy":{"lvl1":"Thermal Infrared","lvl4":"Bonus activity: comparing two thermal IR rasters","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"type":"lvl4","url":"/notebooks/thermal-ir-tutorial#bonus-activity-comparing-two-thermal-ir-rasters","position":16},{"hierarchy":{"lvl1":"Thermal Infrared","lvl4":"Bonus activity: comparing two thermal IR rasters","lvl3":"Satellite IR imagery with ASTER","lvl2":"Part 2: Satellite IR remote sensing obsevations"},"content":"How does the finer spatial resolution airborne IR image compare with the coarser resolution ASTER IR image?\n\nOne way to compare these two images is to “upscale” the finer resolution airborne IR image to the same spatial resolution as ASTER.\n\nWe can use the rioxarray \n\nreproject_match function to do this. (\n\nalso see this example)\n\nNote that this function has \n\nmultiple options for how we want to resample the image data to the new spatial resolution. We will use resampling=5 which corresponds to taking the mean value.\n\nairborne_ir_repr = airborne_ir.rio.reproject_match(aster_ir, resampling=5)\n\nPreview the result.\n\nWhat are the image dimensions of the reprojected airborne IR image compared with the original?\n\nairborne_ir_repr\n\nPlot the ASTER image, original airborne IR image, and resampled airborne IR image next to each other to visualize these spatial resolution differences.\n\nfig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,4), tight_layout=True)\n\n# ASTER IR image\naster_band14_tb_c.plot(ax=axs[0], \n                       cmap='magma', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[0].set_title('ASTER IR')\naxs[0].set_aspect('equal')\n\n# Original airborne IR image\nairborne_ir.plot(ax=axs[1], \n                 cmap='magma', \n                 vmin=-10, vmax=10, \n                 cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[1].set_title('Airborne IR')\naxs[1].set_aspect('equal')\n\n# Resampled airborne IR image\nairborne_ir_repr.plot(ax=axs[2], \n                      cmap='magma', \n                      vmin=-10, vmax=10, \n                      cbar_kwargs={'label': r'Temperature $\\degree C$'})\naxs[2].set_title('Airborne IR resampled (mean)\\nto ASTER resolution (90m)')\naxs[2].set_aspect('equal')\n\n\n# for each subplot, do the following:\nfor ax in axs: \n    ax.set_aspect('equal') # set the aspect ratio to \"equal\"\n    \n    # plot the location of the snow pit of interest\n    siteData_df.plot(ax=ax, color='r', marker='x')\n    # plot the area of the buffer we made around the snow pit\n    siteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n    \n    # set axes labels\n    ax.set_xlabel('Eastings UTM 12N (m)')\n    ax.set_ylabel('Northings UTM 12N (m)')\n    # set the same axes limits as above\n    ax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\n    ax.set_ylim((ymin-1000, ymax+1000)) # y axis limits to +/- 1 km from our point's \"total bounds\"\n\nFinally, compute the difference between the ASTER IR image and resampled airborne IR image, then plot the result:\n\n# Subtract reprojected airborne IR image from ASTER IR image\ndifference_image = aster_band14_tb_c - airborne_ir_repr\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6,5), tight_layout=True)\n\n# Difference image\ndifference_image.plot(ax=ax, \n                       cmap='RdBu_r', \n                       vmin=-10, vmax=10, \n                       cbar_kwargs={'label': 'Temperature $\\degree C$'})\nax.set_title('Temperature Difference\\n(ASTER IR - Reprojected Airborne IR)\\n')\nax.set_aspect('equal')\n\n# plot the location of the snow pit of interest\nsiteData_df.plot(ax=ax, color='r', marker='x')\n# plot the area of the buffer we made around the snow pit\nsiteData_df_buffer.plot(ax=ax, edgecolor='r', facecolor='none')\n\n# set axes labels\nax.set_xlabel('Eastings UTM 12N (m)')\nax.set_ylabel('Northings UTM 12N (m)')\n# set the same axes limits as above\nax.set_xlim((xmin-1000, xmax+1000)) # x axis limits to +/- 1 km from our point's \"total bounds\"\nax.set_ylim((ymin-1000, ymax+1000)); # y axis limits to +/- 1 km from our point's \"total bounds\"\n\n","type":"content","url":"/notebooks/thermal-ir-tutorial#bonus-activity-comparing-two-thermal-ir-rasters","position":17},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Next steps:"},"type":"lvl2","url":"/notebooks/thermal-ir-tutorial#next-steps","position":18},{"hierarchy":{"lvl1":"Thermal Infrared","lvl2":"Next steps:"},"content":"","type":"content","url":"/notebooks/thermal-ir-tutorial#next-steps","position":19},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Project ideas with these data:","lvl2":"Next steps:"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#project-ideas-with-these-data","position":20},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Project ideas with these data:","lvl2":"Next steps:"},"content":"Compare more snow pit temperature data (using snowexsql queries) against airborne and satellite IR imagery\n\nInvestigate spatial patterns of snow temperature from open areas to forested areas on the mesa, differences between ASTER and airborne IR imagery\n\nImproved data visualization using \n\nhvplot or something similar to create interactive plots of IR and/or visible imagery\n\nCompare thermal infrared and SAR imagery, or snow temperature observations and snow model outputs\n\nNote\n\nContact Steven Pestana during the hackweek for help accessing more airborne IR or visible imagery and related datasets","type":"content","url":"/notebooks/thermal-ir-tutorial#project-ideas-with-these-data","position":21},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Data access/download and pre-processing","lvl2":"Next steps:"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#data-access-download-and-pre-processing","position":22},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Data access/download and pre-processing","lvl2":"Next steps:"},"content":"See the jupyter notebook \n\nthermal​-ir​-data​-download​.ipynb for more details about data access methods through the NASA EarthData API, and pre-processing ASTER data into geotiff images.","type":"content","url":"/notebooks/thermal-ir-tutorial#data-access-download-and-pre-processing","position":23},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Additional learning resources:","lvl2":"Next steps:"},"type":"lvl3","url":"/notebooks/thermal-ir-tutorial#additional-learning-resources","position":24},{"hierarchy":{"lvl1":"Thermal Infrared","lvl3":"Additional learning resources:","lvl2":"Next steps:"},"content":"NumPy learning resources:\n\nNumPy and the ndarray\n\nNumPy: the absolute basics for beginners\n\nNumPy: creating and manipulating numerical data\n\nAdvanced NumPy\n\nNumPy for MATLAB users\n\nXarray and \n\nrioxarray learning resources:\n\nIntroduction to xarray\n\nGeoHackWeek 2019 raster tools\n\nrasterio\n\ncartopy\n\nASTER resources:\n\nASTER L1T Scripts and Tutorials\n\nValidating ASTER Thermal Infrared Imaging for use in Snow Models\n\nOpen an airborne TIR mosaic NetCDF file\n\n# Open airborne TIR mosaic NetCDF file\nwith fsspec.open(S3_BASE_URL + 'SNOWEX2020_IR_PLANE_2020Feb08_mosaicked_APLUW.nc') as f:\n    ds = xr.open_dataset(f, decode_times=False)\n    ds = ds.load()\n\nInspect the dataset and its dimensions\n\n# Preview the dataset\nds\n\n# Take a look at the dimensions in the dataset\nds.dims\n\nThere is an extra dimension (“na”) that we will want to drop, we will want to rename some of the dims, assign coordinates to those dims, and add a coordinate reference system for plotting.\n\n# Drop the extra \"na\" dimension from E_UTM, N_UTM, and time\nds['E_UTM'] = ds['E_UTM'].isel(na=0, drop=True)\nds['N_UTM'] = ds['N_UTM'].isel(na=0, drop=True)\nds['time'] = ds['time'].isel(na=0, drop=True)\n\nRename the dimensions to some easier to use names\n\n# Rename dims\nds = ds.rename({\"pass\" : \"time\", \n                \"easting, x\" : \"easting\", \n                \"northing, y\" : \"northing\"})\n\nThis NetCDF file was generated in MATLAB, and the dates/times are in an epoch format. Use \n\nutcfromtimestamp() and \n\nisoformat() to convert and reformat into a more convenient format.\n\n# Decode matlab (epoch) format times\nutctime = [datetime.datetime.utcfromtimestamp(this_time).isoformat() for this_time in ds.time.values]\n\nAssign and then transpose coordinates in our dataset\n\n# Assign coordinates to the \"northing\",  \"easting\", and \"time\" dimensions\nds = ds.assign_coords({\"time\": utctime, \"northing\": ds.N_UTM, \"easting\": ds.E_UTM})\n\n# Transpose coords\nds = ds.transpose(\"time\", \"northing\", \"easting\")\n\nSet spatial dimensions then define which coordinate reference system the spatial dimensions are in\n\n# Write the coordinate reference system for the spatial dims with rioxarray\n# https://github.com/corteva/rioxarray/issues/379\nds.rio.write_crs('epsg:32612', inplace=True,\n                ).rio.set_spatial_dims('easting', 'northing', inplace=True,\n                                      ).rio.write_coordinate_system(inplace=True)","type":"content","url":"/notebooks/thermal-ir-tutorial#additional-learning-resources","position":25},{"hierarchy":{"lvl1":"Time-lapse Cameras"},"type":"lvl1","url":"/notebooks/timelapse-camera-tutorial","position":0},{"hierarchy":{"lvl1":"Time-lapse Cameras"},"content":"Learning Objectives\n\nAt the conclusion of this tutorial, you will...:\n\nKnow about all the time-lapse images available from the SnowEx 2017 and 2020 field campaigns\n\nView example time-lapse images from SnowEx 2020 and visualize their locations\n\nAccess snow depth measurements extracted from the SnowEx 2020 time-lapse images\n\nCompare snow depths from different SnowEx 2020 time-lapse cameras\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial","position":1},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#time-lapse-cameras-on-grand-mesa-during-snowex-field-campaigns","position":2},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"Time-lapse cameras were installed in both the SnowEx 2017 and 2020 field campaigns on Grand Mesa in similar locations.\n\nSnowEx 2017 Time-lapse Cameras\n\n28 Total Time-lapse Cameras\n\nCapturing the entire winter season (September 2016-June 2017)\n\nTaking 4 photos/day at 8AM, 10AM, 12PM, 2PM, 4PM\n\nAn orange pole was installed in front of 15 cameras for snow depth measurements\n\nTime-lapse images have been submitted to the NSIDC by Mark Raleigh with all the required metadata (e.g., locations, naming convention, etc.) for use.\n\nSnowEx 2020 Time-lapse Cameras\n\n29 Total Time-lapse Cameras\n\nCapturing the entire winter season (September 2019-June 2020)\n\nTaking 3 photos/day at 11AM, 12PM, 1PM or 2 photos/day at 11AM and 12PM\n\nA red pole was installed in front of each camera for snow depth measurements.\n\nCameras were installed on the east and west side of the Grand Mesa, across a vegetation scale of 1-9, using the convention XMR:\n\nX = East (E) or West (W) areas of the Mesa\n\nM = number 1-9, representing 1 (least vegetation) to 9 (most vegetation). Within each vegetation class, there were three sub-classes of snow depths derived from 2017 SnowEx lidar measurements.\n\nR = Replicate of vegetation assignment, either A, B, C, D, or E.\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#time-lapse-cameras-on-grand-mesa-during-snowex-field-campaigns","position":3},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl3","url":"/notebooks/timelapse-camera-tutorial#an-automated-way-of-viewing-and-mapping-time-lapse-photos","position":4},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"\n\nFirst, we will procedurally import the necessary packages to access the data. To access the snow depths at each camera station, we will use the SnowEx database (snowexsql) to access the depths as PointMeasurements.\n\nfrom snowexsql.api import PointMeasurements\n\n# Import information for all point measurement types\nmeasurements = PointMeasurements()\n\n# List unique instruments\nresults = measurements.all_instruments\nprint('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n\n# Packages for data analysis \nimport geopandas as gpd # geopandas library for data analysis and visualization\nimport pandas as pd # pandas as to read csv data and visualize tabular data\nimport numpy as np # numpy for data analysis \n\n# Packages for data visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt # matplotlib.pyplot for plotting images and graphs\n\nplt.rcParams['figure.figsize']  = (10, 4) # figure size\nplt.rcParams['axes.titlesize']  = 14 # title size \nplt.rcParams['axes.labelsize']  = 12 # axes label size \nplt.rcParams['xtick.labelsize'] = 11 # x tick label size \nplt.rcParams['ytick.labelsize'] = 11 # y tick label size \nplt.rcParams['legend.fontsize'] = 11 # legend size \nmpl.rcParams['figure.dpi'] = 100\n\n# Query the database for camera-based snow depths\ncamera_depths = measurements.from_filter(\n    type=\"depth\",\n    site_name=\"Grand Mesa\",\n    instrument=\"camera\",\n    limit = 13371\n)\n\ncamera_depths.head()\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#an-automated-way-of-viewing-and-mapping-time-lapse-photos","position":5},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl4":"Plot the camera locations, using snow pit locations for reference.","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl4","url":"/notebooks/timelapse-camera-tutorial#plot-the-camera-locations-using-snow-pit-locations-for-reference","position":6},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl4":"Plot the camera locations, using snow pit locations for reference.","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"\n\ncamera_depths.explore(tooltip=['equipment','date','latitude','longitude','value','type','units'])\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#plot-the-camera-locations-using-snow-pit-locations-for-reference","position":7},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Viewing the time-lapse photos"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#viewing-the-time-lapse-photos","position":8},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Viewing the time-lapse photos"},"content":"Thanks to the SnowEx database, we were able to easily access snow depths at each site. However, if we wish to examine the camera imagery, we will need to be a bit more creative.\n\nThe images are available through NSIDC, so we will use earthaccess to grab one of the image archives.\n\nEarthdata Login Authentication\n\nThis tutorial requires NASA Earthdata Login credentials to access NSIDC data.\n\nRegister for free if you don’t have an account\n\nOnce you have a username and password, you can either enter these in manually\nin the strategy=\"interactive\" mode (as coded below), or you can configure your\nlocal envrionment as follows:\n\nHere’s how to configure your local system for this to work:\n\nFirst time: Run earthaccess.login() without the strategy parameter to authenticate interactively\n\nThis creates a .netrc file for future sessions\n\nAfter making those changes, you should switch to strategy=\"environment\" below!\n\nimport earthaccess\n\n# Authenticate with Earthdata Login servers\ntry:\n    auth = earthaccess.login(strategy=\"environment\")\n    print(\"✓ Successfully authenticated with Earthdata Login\")\n# Search for camera imagery (only if authenticated)\n    granules = earthaccess.search_data(\n        doi = \"10.5067/WYRNU50R9L5R\"\n    )\n    print(granules[0].data_links())\nexcept Exception as e:\n    print(f\"⚠ Authentication failed: {e}\")\n    print(\"This is expected in automated builds. \\\n           Interactive users should run earthaccess.login() to authenticate.\")\n    granules = None\n\n# Load the files into memory (only if authenticated)\nif granules:\n    files = earthaccess.open(granules)\nelse:\n    print(\"⚠ Skipping remote data access - using local sample data instead\")\n    files = None\n\nLarge Downloads Ahead!\n\nLooking at the above data links, one will notice that the images are saved in .tar.gz format. We can read files through earthaccess in this format, but it will require some more work than simply downloading the data.\n\nUsers may download the files if they wish, but they are on the larger side (900+ Mb). If you wish to avoid large data downloads, then the below code will help with the process. However, be aware that the code can be rather memory intensive. If running this code on CryoCloud, then consider using larger memory allocations (4+ Gb).\n\nHere is how you would read in every file in the large tar.gz from earthaccess into memory:\n\nfile_content = files[0].read()\n\nSimplifying the download for learning purposes\n\nFor the sake of this tutorial we will create a synthetic tar.gz file with just three images we want to show here.\n\nfile_content = 'data/sample-data.tar.gz'\n\n\nimport tarfile\nfrom io import BytesIO\nfrom datetime import datetime\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\njpg_files = []\n# Open the tarfile remotely\nwith tarfile.open(file_content, mode=\"r:gz\") as tar:\n    # Identify contents of tarfile\n    members = tar.getmembers()\n\n    # Loop through tarfile contents for images of interest\n    fig, ax = plt.subplots(1,3, figsize=(12,12))\n    ax.flatten()\n    for member in members:\n        if member.name.lower().endswith('.jpg'):\n            jpg_file = tar.extractfile(member).read()\n            \n            # Estimate datetime from image\n            creationTime = member.mtime\n            dt_c = datetime.fromtimestamp(creationTime)\n            formatted_datetime = dt_c.strftime(\"%m/%d/%Y %H:%M\")\n\n            desired_datetimes = ['09/27/2016 15:13',\n                                 '11/08/2016 14:00',\n                                 '12/10/2016 14:00']\n            \n            # Append files with desired datetime\n            for idx,dt in enumerate(desired_datetimes):\n                if formatted_datetime == dt:\n                    image = Image.open(BytesIO(jpg_file))\n                    ax[idx].imshow(image)\n                    ax[idx].set_title(desired_datetimes[idx])\n                    ax[idx].axis('off')\n\n    plt.tight_layout()\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#viewing-the-time-lapse-photos","position":9},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Camera Applications"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#time-lapse-camera-applications","position":10},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Camera Applications"},"content":"Installing snow poles in front of time-lapse camera provides low-cost, long-term snow depth timeseries. Snow depths from the 2020 SnowEx time-lapse imagery have been manually processed with estimation of submission to the NSIDC database in summer 2021.\n\nThe snow depth is the difference between the number of pixels in a snow-free image and an image with snow, with a conversion from pixels to centimeters (Figure 1).\n\n\n\nFigure 1: Equation to extract snow depth from camera images. For each image, take the difference in pixels between the length of a snow-free stake and the length of the stake and multiply by length(cm)/pixel. The ratio can be found by dividing the full length of the stake (304.8 cm) by the length of a snow-free stake in pixels.\n\nSnow depth can be obtained in this manner manually, but it is now easier to determine the pixel size of the stakes through machine learning. For the sake of completeness, we will provide a brief example using the camera imagery above. Otherwise, users interested in using the camera imagery with machine learning are encouraged to check out the following resources by Katherine Breen and others:\n\nPublication on methodBreen C. M., W. R. Currier, C. Vuyovich, et al. 2024. “Snow Depth Extraction From Time‐Lapse Imagery Using a Keypoint Deep Learning Model.” Water Resources Research 60 (7): [10.1029/2023wr036682]\n\nGithub page for algorithm\n\nhttps://​github​.com​/catherine​-m​-breen​/snowpoles\n\nIn the example images above, we use the red pole in the fully snow-off and snow-on images for estimation.\n\nFor the snow-off image, the length of the red pole is 136 pixels. If we assume that the pole is 304.8 cm in length, then each pixel is approximately 2.24 cm in length.\n\nFor the snow-on image, the length of the red pole is 72 pixels, much shorter than the snow-off length. So, there is a ~64 pixel difference between the snow-on and snow-off lengths. Using the equation in Figure 1, we can calculate snow depth:\n\nDepth = 2.24 * (136-72) = 143.36 cm\n\nAcknowledgements: Anthony Arendt, Scott Henderson, Micah Johnson, Carrie Vuyovich, Ryan Currier, Megan Mason, Mark Raleigh\n\nAdditional ReferencesDickerson-Lange et al., 2017. Snow disappearance timing is dominated by forest effects on snow accumulation in warm winter climates of the Pacific Northwest, United States. Hydrological Processes. Vol 31, Issue 10. 13 February 2017. \n\nDickerson‐Lange et al. (2017)\n\nRaleigh et al., 2013. Approximating snow surface temperature from standard temperature and humidity data: New possibilities for snow model and remote sensing evaluation. Water Resources Research. Vol 49, Issue 12. 07 November 2013.  \n\nRaleigh et al. (2013)","type":"content","url":"/notebooks/timelapse-camera-tutorial#time-lapse-camera-applications","position":11},{"hierarchy":{"lvl1":"UAVSAR"},"type":"lvl1","url":"/notebooks/uavsar-tutorial","position":0},{"hierarchy":{"lvl1":"UAVSAR"},"content":"\n\nDevelopers: Jack Tarricone, University of Nevada, Reno Zach Keskinen, Boise State University\n\nOther contributors: Ross Palomaki, Montana State UniversityNaheem Adebisi, Boise State University\n\n","type":"content","url":"/notebooks/uavsar-tutorial","position":1},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What is UAVSAR?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-is-uavsar","position":2},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What is UAVSAR?"},"content":"UAVSAR is a low frequency plane-based synthetic aperture radar. UAVSAR stands for “Uninhabited Aerial Vehicle Synthetic Aperture Radar”. It captures imagery using a L-band radar. This low frequency means it can penetrate into and through clouds, vegetation, and snow.\n\nfrequency (cm)\n\nresolution (rng x azi m)\n\nSwath Width (km)\n\nPolarizations\n\nLaunch date\n\nL-band 23\n\n1.8 x 5.5\n\n16\n\nVV, VH, HV, HH\n\n2007","type":"content","url":"/notebooks/uavsar-tutorial#what-is-uavsar","position":3},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"NASA SnowEx 2020 and 2021 UAVSAR Campaigns","lvl3":"What is UAVSAR?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#nasa-snowex-2020-and-2021-uavsar-campaigns","position":4},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"NASA SnowEx 2020 and 2021 UAVSAR Campaigns","lvl3":"What is UAVSAR?"},"content":"During the winter of 2020 and 2021, NASA conducted an L-band InSAR timeseries across the Western US with the goal of tracking changes in SWE. Field teams in 13 different locations in 2020, and in 6 locations in 2021, deployed on the date of the flight to perform calibration and validation observations.\n\nThe site locations from the above map along with the \n\nUAVSAR defined campaign name and currently processed pairs of InSAR images for each site. Note that the image pair count may contain multiple versions of the same image and may increase as more pairs of images are processed by JPL. Also note that the Lowman campaign name is the wrong state when searching.\n\nSite Location\n\nCampaign Name\n\nImage Pairs\n\nGrand Mesa\n\nGrand Mesa, CO\n\n13\n\nBoise River Basin\n\nLowman, CO\n\n17\n\nFrazier Experimental Forest\n\nFraser, CO\n\n16\n\nSenator Beck Basin\n\nIronton, CO\n\n9\n\nEast River\n\nPeeler Peak, CO\n\n4\n\nCameron Pass\n\nRocky Mountains NP, CO\n\n15\n\nReynold Creek\n\nSilver City, ID\n\n1\n\nCentral Agricultral Research Center\n\nUtica, MT\n\n2\n\nLittle Cottonwoody Canyon\n\nSalt Lake City, UT\n\n21\n\nJemez River\n\nLos Alamos, NM\n\n3\n\nAmerican River Basin\n\nEldorado National Forest, CA\n\n4\n\nSagehen Creek\n\nDonner Memorial State Park, CA\n\n4\n\nLakes Basin\n\nSierra National Forest, CA\n\n3\n\n","type":"content","url":"/notebooks/uavsar-tutorial#nasa-snowex-2020-and-2021-uavsar-campaigns","position":5},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Why would I use UAVSAR?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar","position":6},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Why would I use UAVSAR?"},"content":"UAVSAR works with low frequency radar waves. These low frequencies (< 3 GHz) can penetrate clouds and maintain coherence (a measure of radar image quality) over long periods. For these reasons, time series was captured over 13 sites as part of the winter of 2019-2020 and 2020-2021 for snow applications. Additionally the UAVSAR is awesome!\n\n","type":"content","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar","position":7},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Accessing UAVSAR Images"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#accessing-uavsar-images","position":8},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Accessing UAVSAR Images"},"content":"UAVSAR imagery can be downloaded from both the \n\nJPL and \n\nAlaska Satellite Facility. However both provide the imagery in a binary format that is not readily usable or readable by GIS software or python libraries.","type":"content","url":"/notebooks/uavsar-tutorial#accessing-uavsar-images","position":9},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#data-download-and-conversion-with-uavsar-pytools","position":10},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"uavsar_pytools (\n\nGithub) is a Python package developed out of work started at SnowEx Hackweek 2021. It nativiely downloads, formats, and converts this data in analysis ready rasters projected in WSG-84 Lat/Lon (\n\nEPSG:4326. The data traditionally comes in a binary format, which is not injestible by traditional geospatial analysis software (Python, R, QGIS, ArcGIS). It can download and convert either individual images - UavsarScene or entire collections of images - UavsarCollection.","type":"content","url":"/notebooks/uavsar-tutorial#data-download-and-conversion-with-uavsar-pytools","position":11},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Netrc Authorization","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#netrc-authorization","position":12},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Netrc Authorization","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"In order to download uavsar images you will need a \n\nnetrc file that contains your earthdata username and password. If you need to register for a NASA earthdata account use this \n\nlink. A netrc file is a hidden file, it won’t appear in the your file explorer, that is in your home directory and that programs can access to get the appropriate usernames and passwords. While you’ll have already done this for the Hackweek virtual machines, uavsar_pytools has a tool to create this netrc file on a local computer. You only need to create this file once and then it should be permanently stored on your computer.\n\n# ## Creating .netrc file with Earthdata login information\n# from uavsar_pytools.uavsar_tools import create_netrc\n\n# # This will prompt you for your username and password and save this\n# # information into a .netrc file in your home directory. You only need to run\n# # this command once per computer. Then it will be saved.\n# create_netrc()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#netrc-authorization","position":13},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a single UAVSAR interferogram scene","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-single-uavsar-interferogram-scene","position":14},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a single UAVSAR interferogram scene","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"You can find urls for UAVSAR images at the \n\nASF vertex website. Make sure to change the platform to UAVSAR and you may also want to filter to ground projected interferograms.\n\ntry:\n    from uavsar_pytools import UavsarScene\nexcept ModuleNotFoundError:\n    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n\n## This is the directory you want to download and convert the images in.\nwork_dir = '/tmp/uavsar_data'\n\n## This is a url you want to download. Can be obtained from vertex\nurl = 'https://datapool.asf.alaska.edu/INTERFEROMETRY_GRD/UA/\\\nlowman_23205_21009-004_21012-000_0007d_s01_L090_01_int_grd.zip'\n\n## clean = True will delete the binary and zip files leaving only the tiffs\nscene = UavsarScene(url = url, work_dir=work_dir, clean= True)\n\n## After running url_to_tiffs() you will download the zip file, unzip the binary \n## files, and convert them to geotiffs in the directory with the scene name in\n## the work directory. It also generate a .csv pandas dictionary of metadata.\n# scene.url_to_tiffs()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-single-uavsar-interferogram-scene","position":15},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a full UAVSAR collection","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-full-uavsar-collection","position":16},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a full UAVSAR collection","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"If you want to download and convert an entire Uavsar collection for a larger analysis you can use UavsarCollection. The collection names for the SnowEx campaign are listed in the table in the introduction. The UavsarCollection can download either InSAR pairs and PolSAR images.\n\nfrom uavsar_pytools import UavsarCollection\n## Collection name, the SnowEx Collection names are listed above. These are case \n## and space sensitive.\ncollection_name = 'Grand Mesa, CO'\n\n## Directory to save collection into. This will be filled with directory with \n## scene names and tiffs inside of them.\nout_dir = '/tmp/collection_ex/'\n\n## This is optional, but you will generally want to at least limit the date\n## range between 2019 and today.\ndate_range = ('2019-11-01', 'today')\n\n# Keywords: to download incidence angles with each image use `inc = True`\n# For only certain pols use `pols = ['VV','HV']`\n\ncollection = UavsarCollection(collection = collection_name, work_dir = out_dir, dates = date_range)\n\n## You can use this to check how many image pairs have at least one image in\n## the date range.\n\n#collection.find_urls()\n\n## When you are ready to download all the images run:\n\n# collection.collection_to_tiffs()\n\n## This will take a long time and a lot of space, ~1-5 gB and 10 minutes per \n## image pair depending on which scene, so run it if you have the space and time.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-full-uavsar-collection","position":17},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"UAVSAR Data Products"},"type":"lvl2","url":"/notebooks/uavsar-tutorial#uavsar-data-products","position":18},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"UAVSAR Data Products"},"content":"UAVSAR has a variety of different type of images:\n\nRepeat Pass Interferometric images contain:\n\nInSAR Data Types\n\nANN file (.ann): a text annotation file with metadata\n\nAMP files (.amp1 and .amp2): amplitude products for flight 1 and flight 2\n\nCOR files (.cor): coherence a measure of the noise level of the phase\n\nINT files (.int): wrapped phase difference between the two images\n\nUNW files (.unw): unwrapped phase difference between the two images\n\nINC files (.inc): incidence angle in radians\n\nHGT file  (.hgt): the DEM that was used in the InSAR processing\n\nUAVSAR repeat pass interferometry uses two images of the same place but separated in time. Phase changes between the two aquistions are calculated,  creating a wrapped interferogram. These phase changes are due to either the wave traveling a longer distance (ground movement or refraction) or change wave speeds (atmospheric water vapor and snow).\n\nGRD files (.grd): products projected to the ground in geographic coordinates (latitude, longitude)\nFinally all images can be in radar slant range or projected into WGS84. Images that have already been projected to ground range will have the extension .grd appended to their file type extension.\n\nFor instance a image of unwrapped phase that has not been georefenced would end with .unw, while one that was georeferenced would end with .unw.grd. You will generally want to use .grd files for most analysis.\n\nPolarimetric PolSAR images contain:\n\nANN file (.ann): a text annotation file with metadata\n\nPolsar file (HHVV.grd): all the rest of the files will be a pair of polarizations pushed together\n\nPolsar files have a pair of polarizations (VV, VH, HV, HH) combined in their file name. These files are the phase difference between polarization XX and polarization YY. For instance HHHV is the phase difference between HH and HV polarizations. HVVV is the phase difference between HV and VV and so one. There are 6 of these pairs since order is irrelevant. These 6 images are combined to calculate various metrics that tell you about the types of scattering occurring.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#uavsar-data-products","position":19},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Import Libraries","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#import-libraries","position":20},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Import Libraries","lvl2":"UAVSAR Data Products"},"content":"\n\ntry:\n    from uavsar_pytools import UavsarScene\n    from uavsar_pytools.snow_depth_inversion import depth_from_phase, phase_from_depth\nexcept ModuleNotFoundError:\n    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n\nimport os\nfrom os.path import join, basename\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport holoviews as hv\nimport rioxarray as rxa\nimport rasterio as rio\nfrom bokeh.plotting import show\nimport datashader as ds\nfrom datashader.mpl_ext import dsshow\nhv.extension('bokeh', logo=False)\nimport earthpy.plot as ep\nimport earthpy.spatial as es\nimport contextily as cx\nfrom datetime import date\nfrom shapely.geometry import box\nimport requests\n%config InlineBackend.figure_format='retina'\n\n# Database imports\nfrom snowexsql.db import get_db\nfrom snowexsql.data import PointData, ImageData, LayerData, SiteData\nfrom snowexsql.conversions import query_to_geopandas\n\nimport warnings\nwarnings.filterwarnings('ignore', category=UserWarning, module='rasterio')\nimport logging\nlogging.getLogger('rasterio._env').setLevel(logging.ERROR)\nlogging.getLogger('rasterio._filepath').setLevel(logging.ERROR)\nos.environ['CPL_CURL_VERBOSE'] = 'NO'\n\n","type":"content","url":"/notebooks/uavsar-tutorial#import-libraries","position":21},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#interferometric-imagery","position":22},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"\n\n","type":"content","url":"/notebooks/uavsar-tutorial#interferometric-imagery","position":23},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Banner Summit","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#banner-summit","position":24},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Banner Summit","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"\n\nIn this section we’ll be plotting and comparing dirrerent types of SAR and InSAR data with optical imagery and a digital elevation model. For this example we’ll be taking a subet of the Lowman flight (Boise, ID) line encompassing Banner Summit.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#banner-summit","position":25},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Access Tutorial Data from S3","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#access-tutorial-data-from-s3","position":26},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Access Tutorial Data from S3","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"The tutorial data is hosted on AWS S3 and can be accessed directly without downloading. The data will be streamed as needed using rioxarray.\n\n# S3 base URL for tutorial data\nS3_BASE_URL = \"https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/\"\n\n","type":"content","url":"/notebooks/uavsar-tutorial#access-tutorial-data-from-s3","position":27},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Load in Rasters","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#load-in-rasters","position":28},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Load in Rasters","lvl2":"UAVSAR Data Products"},"content":"Here we’ll load our rasters into the environemtns using rioxarray or rxa, we will then convert to a np.array to be able to use matplotlib.pyplot or plt for plotting\n\n","type":"content","url":"/notebooks/uavsar-tutorial#load-in-rasters","position":29},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Optical Data","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#optical-data","position":30},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Optical Data","lvl2":"UAVSAR Data Products"},"content":"We will be using \n\nHaromized Landsat Sentinel (HLS) dataset from January 13th, 2021. This date was selected because it is mostly cloud free, which is uncommon in mountain environments during the winter.\n\n# Define S3 URLs for the three RGB bands and stack them in memory\nred_path = S3_BASE_URL + 'lowman_red.tif'\ngreen_path = S3_BASE_URL + 'lowman_green.tif'\nblue_path = S3_BASE_URL + 'lowman_blue.tif'\n\n# Load and stack RGB bands directly from S3 (no local files needed)\nimport xarray as xr\nred = rxa.open_rasterio(red_path)\ngreen = rxa.open_rasterio(green_path)\nblue = rxa.open_rasterio(blue_path)\n\n# Stack the bands into a single array\nrgb = xr.concat([red, green, blue], dim='band')\nrgb['band'] = [1, 2, 3]  # Label bands as 1, 2, 3\n\n","type":"content","url":"/notebooks/uavsar-tutorial#optical-data","position":31},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What do we see in this image? Any notable features?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-do-we-see-in-this-image-any-notable-features","position":32},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What do we see in this image? Any notable features?","lvl2":"UAVSAR Data Products"},"content":"\n\n# plot rgb image\nep.plot_rgb(rgb.values,\n            figsize=(15, 15),\n            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n            title = \"HLS Optical 2/18/2021\", \n            stretch=True)\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-do-we-see-in-this-image-any-notable-features","position":33},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"InSAR and SAR Data","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#insar-and-sar-data","position":34},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"InSAR and SAR Data","lvl2":"UAVSAR Data Products"},"content":"Here we’ll be using five different data products related to InSAR and SAR: unwrapped phase (unw), coherence (cor), amplitude (amp), elevation (dem), and incidence angle (inc).\n\n# Open rasters directly from S3 and inspect metadata using xarray\nunw_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_unw.tif')\nunw = unw_rast[0].values # np.array for plotting\n    \n# coherence\ncor_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_cor.tif')\ncor = cor_rast[0].values\n\n# amplitude\namp_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_amb_db.tif')\namp = amp_rast[0].values # np.array for plotting\n\n# dem\ndem_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_dem.tif')\ndem = dem_rast[0].values\n\n# incidence angle\ninc_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_inc_deg.tif')\ninc = inc_rast[0].values # np.array for plotting\n\n# plot unwrapped phase\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"UNW (radians)\", fontsize= 20) #title and font size\nimg = ax.imshow(unw, interpolation = 'nearest', cmap = 'viridis', vmin = -3, vmax = 2)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot coherence\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Coherence\", fontsize= 20) #title and font size\nimg = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot amplitude\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Amplitude (dB)\", fontsize= 20) #title and font size\nimg = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot dem\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Elevation (m)\", fontsize= 20) #title and font size\nimg = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot incidence angle\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Incidence Angle (deg)\", fontsize= 20) #title and font size\nimg = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#insar-and-sar-data","position":35},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison Plot","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#comparison-plot","position":36},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison Plot","lvl2":"UAVSAR Data Products"},"content":"\n\n# plot all InSAR products\nfig = plt.figure(figsize=(30,19))\n\nax = fig.add_subplot(1,3,1)\ncax=ax.imshow(unw, cmap='viridis', interpolation = 'nearest', vmin = -3, vmax = 2)\nax.set_title(\"UNW (radians)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[-3,0,2],orientation='horizontal', fraction=0.03, pad=0.04)\ncbar.ax.set_xticklabels([-3,0,2])\n\nax = fig.add_subplot(1,3,2)\ncax = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\nax.set_title(\"Coherence\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[0,.5,1], orientation='horizontal',fraction=0.03, pad=0.04)\n\n\nax = fig.add_subplot(1,3,3)\ncax = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\nax.set_title(\"Amplitude (dB)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[-20,-10,0], orientation='horizontal',fraction=0.03, pad=0.04)\ncbar.ax.set_xticklabels([-20,-10,0])\n\nax = fig.add_subplot(2,3,1)\ncax = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\nax.set_title(\"Incidence Angle (deg)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[20,90], orientation='horizontal', pad=0.07)\ncbar.ax.set_xticklabels([20,90])\n\nax = fig.add_subplot(2,3,2)\ncax = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\nax.set_title(\"Elevation (m)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[1800,2800], orientation='horizontal', pad=0.07)\ncbar.ax.set_xticklabels([1800,2800])\n\ndone = None\n\nep.plot_rgb(rgb.values,\n            figsize=(7, 7),\n            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n            title = \"HLS Optical 2/18/2021\", \n            stretch=True)\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#comparison-plot","position":37},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What are some notable similarities between images? Differences?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-are-some-notable-similarities-between-images-differences","position":38},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What are some notable similarities between images? Differences?","lvl2":"UAVSAR Data Products"},"content":"In the next section we’ll go into more detail about the features that impact coherence, phase, and how they’re related\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-are-some-notable-similarities-between-images-differences","position":39},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Sagehen Creek Example","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#sagehen-creek-example","position":40},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Sagehen Creek Example","lvl2":"UAVSAR Data Products"},"content":"\n\n# Load Sagehen Creek data directly from S3\nsage_files = ['cor.tif', 'hgt.tif', 'unw.tif']\nimgs = {}\nfor filename in sage_files:\n    name = filename.split('.')[0]\n    s3_path = S3_BASE_URL + 'sage/' + filename\n    imgs[name] = rxa.open_rasterio(s3_path, parse_coordinates=True, default_name=name)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#sagehen-creek-example","position":41},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What topographic features seem to impact coherence?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-topographic-features-seem-to-impact-coherence","position":42},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What topographic features seem to impact coherence?","lvl2":"UAVSAR Data Products"},"content":"Take a moment to chat with the people around you about this. Some features to get you thinking:\n\nlakes\n\naspect (south vs north, east vs west)\n\nelevation\n\ntrees\n\nroads\n\nothers?\n\ntiles = hv.element.tiles.EsriUSATopo().opts()\ncor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\nhgt = hv.Image(hv.Dataset(imgs['hgt'], kdims=['x','y'])).opts(cmap = 'terrain', colorbar=True, xaxis = None, yaxis = None, title= 'DEM', alpha = 0.4)\nhgt_trans = hv.Image(hv.Dataset(imgs['hgt'][0,::100,::100], kdims=['x','y'])).opts(alpha = 0, xaxis = None, yaxis = None, title = 'Topo')\ncor_tile = tiles  * cor\nhgt_tile = tiles  * hgt\nimagery = hv.element.tiles.EsriImagery()  * hgt_trans\n\nhv.Layout([cor_tile, hgt_tile, imagery]).opts(width = 400, height = 900)\n\nimport seaborn as sns\nxna = imgs['hgt'].data.ravel()\nyna = imgs['cor'].data.ravel()\nx = xna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\ny = yna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\n\ndf = pd.DataFrame(dict(x=x, y=y))\ndf['x_cat'] = pd.qcut(df.x, q= 6, precision = 0)\nf, ax = plt.subplots(figsize = (12,8))\nsns.violinplot(y = df.y[::100], x = df.x_cat[::100], scale = 'count')\nplt.xlabel('Elevation Bands (m)')\nplt.ylabel('Coherence')\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-topographic-features-seem-to-impact-coherence","position":43},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"UNW vs. Coherence","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#unw-vs-coherence","position":44},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"UNW vs. Coherence","lvl2":"UAVSAR Data Products"},"content":"\n\ntiles = hv.element.tiles.EsriUSATopo().opts()\ncor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\nunw = hv.Image(hv.Dataset(imgs['unw'], kdims=['x','y'])).opts(cmap = 'magma', colorbar=True, xaxis = None, yaxis = None, title= 'Unwrapped Phase', clim = (0, 2*np.pi))\ncor_tile = tiles  * cor\nunw_tile = tiles  * unw\n\nhv.Layout([cor_tile, unw_tile]).opts(width = 400, height = 900)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#unw-vs-coherence","position":45},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl2","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar-for-snow","position":46},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"Why would I use UAVSAR for snow?"},"content":"L-band SAR penetrates through the snowpack. However when it crosses into the snowpack from the air it refracts at an angle, similar to light entering water. This refraction leads to a phase shift relative to an image with no or less snow. Using this difference in phase between two images we can calculate the change in snow height between flights using:\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWhere \\Delta d is the change in snow height, \\Delta \\phi is the phase shift between two SAR images, \\lambda is the radar wavelength, \\alpha is the incidence angle, and \\epsilon_{s} is the dielectric constant of snow which is dependent on the density and liquid water content.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar-for-snow","position":47},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Set variables","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#set-variables","position":48},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Set variables","lvl2":"Why would I use UAVSAR for snow?"},"content":"\n\n# Mesa Lake Snotel Coordinates\nsnotel_coords = (-108.05, 39.05)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#set-variables","position":49},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Phase Change between February 1st and 13th UAVSAR Image Pairs","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#phase-change-between-february-1st-and-13th-uavsar-image-pairs","position":50},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Phase Change between February 1st and 13th UAVSAR Image Pairs","lvl2":"Why would I use UAVSAR for snow?"},"content":"You learned in the first section how to access and download UAVSAR imagery. For this section the data has already been downloaded, converted to GeoTiffs and cropped down to an area of interest that overlaps the main field sites of Grand Mesa. Lets take a look at the coherence and unwrapped phase between these two flights. If you don’t remember what these two represent check out the previous section of this tutorial.\n\n# Create figures and subplots\nfig, axes = plt.subplots(2, 1, figsize = (12,8))\n\n# Select colormap for each image type\nvis_dic = {'cor': 'Blues', 'unw':'magma'}\n\n# Loop through coherence and unwrapped phase images\nfor i, type in enumerate(vis_dic.keys()):\n    # select correct axis\n    ax = axes[i]\n    # open image directly from S3 with rioxarray\n    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n    # calculate visualization parameters\n    vmin, vmax = img.quantile([0.1,0.9])\n    # plot images\n    img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n    # zoom out a bit\n    ax.set_xlim(-108.28,-108)\n    ax.set_ylim(38.98, 39.08)\n    # add topo basemap\n    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n    # turn off labels\n    ax.xaxis.label.set_visible(False)\n    ax.yaxis.label.set_visible(False)\n# set titles\naxes[0].set_title('Coherence')\naxes[1].set_title('Unwrapped Phase Change')\n\nplt.show()\n\nfig, ax = plt.subplots(figsize = (12,8))\n\n# Plot the snotel location\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n\n# Plot bounding box of uavsar - stream from S3\nuavsar_bounds = rxa.open_rasterio(S3_BASE_URL + 'cor.tif').rio.bounds()\nx,y = box(*uavsar_bounds).exterior.xy\nax.plot(x,y, color = 'blue')\n\n# Set overview bounds\nax.set_xlim(-108.4,-107.75)\nax.set_ylim(38.75, 39.3)\n\n# Add background map\ncx.add_basemap(ax, crs='EPSG:4326', alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\nplt.title('Overview Map')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#phase-change-between-february-1st-and-13th-uavsar-image-pairs","position":51},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Using the SnowEx SQL Database to collect snow depth and lidar datasets","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#using-the-snowex-sql-database-to-collect-snow-depth-and-lidar-datasets","position":52},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Using the SnowEx SQL Database to collect snow depth and lidar datasets","lvl2":"Why would I use UAVSAR for snow?"},"content":"Lets explore how many overlapping depth observations we have between these two days.\n\n# This is what you will use for all of hackweek to access the db\ndb_name = 'snow:hackweek@db.snowexdata.org/snowex'\n\n# Using the function get_db, we receive 2 ways to interact with the database\nengine, session = get_db(db_name)\n\n# Its convenient to store a query like the following \nqry = session.query(PointData)\n\n# Filter to snow depths\nqry = qry.filter(PointData.type == 'depth')\nqry = qry.filter(PointData.site_name == 'Grand Mesa')\nqry = qry.filter(PointData.instrument != 'Mala 800 MHz GPR')\n\n# Then filter on it first date. We are gonna get one day either side of our flight date\nqry_feb1 = qry.filter(PointData.date >= date(2020, 1, 31))\nqry_feb1 = qry_feb1.filter(PointData.date <= date(2020, 2, 2))\ndf_feb_1 = query_to_geopandas(qry_feb1, engine)\n\n# Get depths from second flight date\nqry_feb12 = qry.filter(PointData.date >= date(2020, 2, 11))\nqry_feb12 = qry_feb12.filter(PointData.date <= date(2020, 2, 13))\ndf_feb_12 = query_to_geopandas(qry_feb12, engine)\n\n# Get depths that were captured on both days\ndf_both = df_feb_1.overlay(df_feb_12, how = 'intersection')\n\n# Convert crs to match our uavsar images\ndf_both = df_both.to_crs(epsg = 4326)\n\n# Calculate the snow depth change for each point\ndf_both['sd_diff'] = df_both.value_2 - df_both.value_1\n\nfig, ax = plt.subplots(figsize = (12,4))\n\n# Plot depth measurements\ndf_both.plot(ax = ax, column = 'sd_diff', legend = True, legend_kwds = {'label': 'Snow Depth Change [cm]'}, cmap = 'magma')\n\n# Plot the snotel location\nsnotel_coords = (-108.05, 39.05)\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n\n# Plot bounding box of uavsar - stream from S3\nimg = rxa.open_rasterio(S3_BASE_URL + 'cor.tif')\nuavsar_bounds = img.rio.bounds()\nx,y = box(*uavsar_bounds).exterior.xy\nax.plot(x,y, color = 'blue')\n\n# Set same bounds as uavsar image plot\nax.set_xlim(-108.28,-108)\nax.set_ylim(38.98, 39.08)\n\n# Add background map\ncx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\nplt.title('Database Snow Depth Measurements')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#using-the-snowex-sql-database-to-collect-snow-depth-and-lidar-datasets","position":53},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#getting-the-remaining-parameters","position":54},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"","type":"content","url":"/notebooks/uavsar-tutorial#getting-the-remaining-parameters","position":55},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Incidence Angle","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#incidence-angle","position":56},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Incidence Angle","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"We can recall the formula to calculate snow depth change from incidence angle, phase change, and the snow permittivity.\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWe have two of these variables already: incidence angle and phase change.\n\n# Create figures and subplots\nfig, axes = plt.subplots(2, 1, figsize = (12,8))\n\n# Select colormap for each image type\nvis_dic = {'inc': 'Greys', 'unw':'magma'}\n\n# Loop through each image type\nfor i, type in enumerate(vis_dic.keys()):\n    ax = axes[i]\n    # Open image directly from S3 with rioxarray\n    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n    # convert incidence angle from radians to degrees\n    if type == 'inc':\n        img = np.rad2deg(img)\n    # this is a great convenience feature to calculate good visualization levels\n    vmin, vmax = img.quantile([0.1,0.9])\n    # plot the image\n    im = img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n    # Zoom out a big\n    ax.set_xlim(-108.28,-108)\n    ax.set_ylim(38.98, 39.08)\n    # Add a topo basemap\n    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n    # Remove unnecessary 'x' 'y' labels\n    ax.xaxis.label.set_visible(False)\n    ax.yaxis.label.set_visible(False)\n\n# Add titles\naxes[0].set_title('Incidence Angle')\naxes[1].set_title('Unwrapped Phase Change')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#incidence-angle","position":57},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Getting Permittivity","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#getting-permittivity","position":58},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Getting Permittivity","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"We have two ways of getting the e_{s}, or the real part of the snow’s dielectric permittivity. One is by estimating from the snow density. For dry snow we can estimate the permittivity using the density. There are a number of equations for calculating this value, but we will use the equation from \n\nGuneriussen et al. 2001:e_{s} = 1 + 0.0016 \\rho + 1.8 1\\mathrm{e}{-9} \\rho^{3}\n\nwhere e_{s} is the real part of the snow’s dielectric permittivity and \\rho is the density of the new snow accumulated between the two images in \\frac{kg}{m^{3}}.\n\nThe other method is to use the directly measured values for permittivity from the field and averaging the top layer.\n\n# Its convenient to store a query like the following \nqry = session.query(LayerData)\n\n# Then filter on it first date. We are gonna get one day either side of second flight date\nqry = qry.filter(LayerData.date >= date(2020, 1, 31))\nqry = qry.filter(LayerData.date <= date(2020, 2, 2))\nqry = qry.filter(LayerData.site_name == 'Grand Mesa')\n# Filter to snow density\nqry_p = qry.filter(LayerData.type == 'density')\n# Change the qry to a geopandas dataframe\ndf = query_to_geopandas(qry_p, engine)\n# create a list to hold the density values\np_values = []\n# Loop through each snowpit (each unique site-id is a snowpit) \nfor id in np.unique(df.site_id):\n    sub = df[df.site_id == id]\n    # get the density for the top layer identified in each snowpit\n    p = float(sub.sort_values(by = 'depth', ascending = False).iloc[0]['value'])\n    # add it our list\n    p_values.append(p)\n# calculate the mean density of the top layer for each snowpit\nmean_new_density = np.nanmean(p_values)\n# Use our equation above to estimate our new snow permittivity\nes_estimate = 1 + 0.0016*mean_new_density + 1.8e-09*mean_new_density**3\n\n## We can also use snowpits where permittivity was directly observed to compare to\n# our density estimates\nqry = qry.filter(LayerData.type == 'permittivity')\ndf = query_to_geopandas(qry, engine)\nes_values = []\nfor id in np.unique(df.site_id):\n    sub = df[df.site_id == id]\n    es_str = sub.sort_values(by = 'depth', ascending = False).iloc[0]['value']\n    if es_str != None:\n        es = float(es_str)\n        if es != None:\n            es_values.append(es)\nes_measured = np.nanmean(es_values)\n\nprint(f'New snow measured permittivity: {es_measured}. Permittivity from density: {es_estimate}')\n\n","type":"content","url":"/notebooks/uavsar-tutorial#getting-permittivity","position":59},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Now we have a new snow permittivity (either from density or directly measured) and we can use that along with our unwrapped phase to calculate the Uavsar snow depth change.","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#now-we-have-a-new-snow-permittivity-either-from-density-or-directly-measured-and-we-can-use-that-along-with-our-unwrapped-phase-to-calculate-the-uavsar-snow-depth-change","position":60},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Now we have a new snow permittivity (either from density or directly measured) and we can use that along with our unwrapped phase to calculate the Uavsar snow depth change.","lvl2":"Why would I use UAVSAR for snow?"},"content":"Take a moment to code up the formula for snow depth change from phase and incidence angle:\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWhere \\Delta d is the change in snow height, \\Delta \\phi is the phase shift between two SAR images, \\lambda is the radar wavelength, \\alpha is the incidence angle, and \\epsilon_{s} is the dielectric constant of snow which is dependent on the density and liquid water content.\n\n# Open rasters directly from S3 (unwrapped phase and incidence angle)\nunw = rxa.open_rasterio(S3_BASE_URL + 'unw.tif')\ninc = rxa.open_rasterio(S3_BASE_URL + 'inc.tif')\n\n# This uses the pytool's function to directly give you snow depth change\n# feel free to rerun with this to check your results\n# https://github.com/SnowEx/uavsar_pytools/blob/main/uavsar_pytools/snow_depth_inversion.py\nsd_change = depth_from_phase(unw, inc, density = mean_new_density)\n\n# convert to centimeters from meters\nsd_change = sd_change*100\n\n# Now we can plot the results!\nf, ax = plt.subplots(figsize = (12,8))\n\n# Plot our uavsar snow depth change\nsd_change.plot(ax = ax, cmap = 'Blues', vmin = -10, vmax = 10)\n# plot black shadow for field observations\ndf_both.plot(ax = ax, color = 'black', markersize = 90)\n# plot field observed snow depth difference\ndf_both.plot(ax = ax, column = 'sd_diff', legend = True, cmap = 'Blues', vmin = -10, vmax = 10)\n# add snotel coordinates\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n# turn off labels\nax.xaxis.label.set_visible(False)\nax.yaxis.label.set_visible(False)\n# set title\nax.set_title('Uavsar Snow Depth Inversion vs Field Observations')\n\n## Uncomment this to zoom in on the measured results\n# ax.set_xlim(-108.14, -108.23)\n# ax.set_ylim(39, 39.05)\n\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#now-we-have-a-new-snow-permittivity-either-from-density-or-directly-measured-and-we-can-use-that-along-with-our-unwrapped-phase-to-calculate-the-uavsar-snow-depth-change","position":61},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Numerical Comparison","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#numerical-comparison","position":62},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Numerical Comparison","lvl2":"Why would I use UAVSAR for snow?"},"content":"We can now extract the snow depth change at each measured point and compare them\nto the pit values of snow depth change.\n\n# Sample UAVSAR snow depth change at field measurement points (in memory, no file I/O)\ncoord_list = [(x, y) for x, y in zip(df_both['geometry'].x, df_both['geometry'].y)]\n\n# Use rioxarray to sample values directly from the in-memory array\nfrom rasterio.transform import rowcol\ndf_both['uavsar_sd'] = [\n    float(sd_change.sel(x=x, y=y, method='nearest').values) \n    for x, y in coord_list\n]\n\nf, ax = plt.subplots(figsize = (12,8))\ndf_both['geometry-str'] = df_both['geometry'].astype(str)\ndf_dis = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'mean', 'uavsar_sd': 'mean'})\nfield_sd_std = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'std'})['sd_diff'].values\nax.errorbar(x = df_dis.uavsar_sd, y = df_dis.sd_diff, yerr = field_sd_std, fmt=\"o\")\n\nlims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n]\ndef rmse(predictions, targets):\n    return np.sqrt(((predictions - targets) ** 2).mean())\nrmse_sd = rmse(df_both['sd_diff'], df_both['uavsar_sd'])\nprint(f'RMSE between uavsar and field observations is {rmse_sd} cm')\n\n# now plot both limits against each other\nax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\nax.set_xlabel('Uavsar Snow Depth Change')\nax.set_ylabel('Field Measured Snow Depth Change')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#numerical-comparison","position":63},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison to Lidar","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#comparison-to-lidar","position":64},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison to Lidar","lvl2":"Why would I use UAVSAR for snow?"},"content":"\n\n# Create figures and subplots\nfig, axes = plt.subplots(3, 1, figsize = (12,8))\n\n# Load lidar data from S3\nlidar = rxa.open_rasterio(S3_BASE_URL + 'sd_lidar.tif')\n\ndiff = lidar.copy()\ndiff = diff - sd_change\n\nvmin, vmax = sd_change.quantile([0.1,0.9])\nsd_change_masked = sd_change.copy()\nsd_change_masked.data[np.isnan(lidar).data] = np.nan\nsd_change_masked.plot(ax = axes[0], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\nlidar.plot(ax = axes[1], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\ndiff.plot(ax = axes[2], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\n\nfor ax in axes:\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n\naxes[0].set_title('Uavsar Snow Depth Change')\naxes[1].set_title('Lidar Snow Depth Change')\naxes[2].set_title('Snow Depth Difference')\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize = (12,8))\ndiffs = diff.values.ravel()\ndiffs = diffs[diffs < 100]\ndiffs = diffs[diffs > -100]\nplt.hist(diffs, bins = 100, density = True, label = 'Uavsar sd change')\n# plt.axvline(sd_change_masked.mean().values, label = 'Uavsar Mean Snow Depth Change', color = 'green')\nlidar_vals = lidar.astype(np.float64).values[~lidar.isnull().values]\nlidar_vals = lidar_vals[lidar_vals < 100]\nlidar_vals = lidar_vals[lidar_vals > -100]\nmean_lidar = np.nanmean(lidar_vals)\nplt.axvline(mean_lidar, color = 'red', linewidth = 5, label = 'mean lidar sd change')\n# plt.axvline(mean_lidar, label = 'Lidar Mean Snow Depth Change', color = 'red')\nrmse = np.sqrt(((diffs) ** 2).mean())\nprint(f'Lidar mean depth change: {sd_change_masked.mean().values} cm, uavsar mean depth change: {mean_lidar} cm')\nprint(f'Mean difference: {np.nanmean(diffs)} cm, rmse = {rmse} cm')\nplt.legend(loc = 'lower left')\nplt.xlabel('Snow Depth Change (cm)')\nplt.show()","type":"content","url":"/notebooks/uavsar-tutorial#comparison-to-lidar","position":65}]}