{"version":"1","records":[{"hierarchy":{"lvl1":"Snow Observations Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Snow Observations Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook is a compilation of tutorials and training\nmaterials in support of the NASA snow reserach community. Some tutorials\ncome from the 2020 to 2024 SnowEx Hackweek program hosted at the UW eScience\nInstitute. Other materials are drawn from the NASA Goddard “SnowPit” Science\nTask Group or STG. The purpose of the tutorials is to help people with data\naccess and to demonstrate a variety of disciplinary use cases.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Motivation"},"content":"There are numerous data products and methods for accessing and analyzing\nsnow observations. These include field, airborne, and satellite missions.\nThe goal of these tutorials is to streamline data access, reduce duplication\nof effort and build an open science community around snow research\ndatasets, algorithms and software.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Authors"},"content":"Zach Fair\n\n\nAnthony Arendt,\n\n\nMark Welden-Smith\n\nmore to be added","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into three main sections: “Data Access”, “Observations”, and “Analysis and Machine Learning”. The current listing of subtopics is currently a work in progress.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 1: Data Access","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-data-access","position":10},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 1: Data Access","lvl2":"Structure"},"content":"Field Campaigns Overview\n\nSnowExSQL Database","type":"content","url":"/#section-1-data-access","position":11},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 2: Observations","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-observations","position":12},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 2: Observations","lvl2":"Structure"},"content":"GPR and Lidar\n\nTime-lapse Cameras\n\nUAVSAR\n\nMicrostructure\n\nAVIRIS-NG\n\nTerrestrial Laser Scanning","type":"content","url":"/#section-2-observations","position":13},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 3: Analysis and Machine Learning","lvl2":"Structure"},"type":"lvl3","url":"/#section-3-analysis-and-machine-learning","position":14},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Section 3: Analysis and Machine Learning","lvl2":"Structure"},"content":"Neural Networks with PyTorch\n\nSnow Modeling\n\nUCLA Reanalysis\n\nMERRA-2\n\nERA5","type":"content","url":"/#section-3-analysis-and-machine-learning","position":15},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":16},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using\n\n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":17},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":18},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of\nhow this works are not important for now. All you need to know is how to launch\na Pythia Cookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":19},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":20},{"hierarchy":{"lvl1":"Snow Observations Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer,\nyou will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/snow-cookbook repository: git clone https://github.com/ProjectPythia/snow-cookbook.git\n\nMove into the snow-cookbook directorycd snow-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate snow-cookbook\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":21},{"hierarchy":{"lvl1":"GPR and Lidar"},"type":"lvl1","url":"/notebooks/gpr-lidar-hackweektutorial","position":0},{"hierarchy":{"lvl1":"GPR and Lidar"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial","position":1},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Author: Randall Bonnell"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#author-randall-bonnell","position":2},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Author: Randall Bonnell"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#author-randall-bonnell","position":3},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Outline:"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#outline","position":4},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Outline:"},"content":"GPR Methods for the Retrieval of Snow Depth and SWE\n\nLidar Methods for Snow Depth Retrieval and SWE Estimation\n\nLeveraging Coincident GPR and Lidar Data Sets to Derive Snow Density\n\nSnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska\n\nDiscussion: Improving Density Estimation\n\nGPR SnowEx Analysis-Ready Datasets\n\nReferences\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#outline","position":5},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-1-gpr-methods-for-the-retrieval-of-snow-depth-and-swe","position":6},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-1-gpr-methods-for-the-retrieval-of-snow-depth-and-swe","position":7},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous GPR tutorial developed by Tate Meehan (CRREL) that may be of interest: https://​snowex​-2021​.hackweek​.io​/tutorials​/gpr​/gpr​.html","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#previous-gpr-tutorial-developed-by-tate-meehan-crrel-that-may-be-of-interest-https-snowex-2021-hackweek-io-tutorials-gpr-gpr-html","position":8},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous GPR tutorial developed by Tate Meehan (CRREL) that may be of interest: https://​snowex​-2021​.hackweek​.io​/tutorials​/gpr​/gpr​.html","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#previous-gpr-tutorial-developed-by-tate-meehan-crrel-that-may-be-of-interest-https-snowex-2021-hackweek-io-tutorials-gpr-gpr-html","position":9},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"SnowEx Review","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#snowex-review","position":10},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"SnowEx Review","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Ground-based, airborne, and satellite radars were operated as part of the NASA SnowEx campaigns.\n\nGround-based radars included ground-penetrating radar (GPR), frequency-modulated continuous-wave radar (FMCW), and tower mounted radars.\n\nWhat airborne and satellite radars were tasked?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#snowex-review","position":11},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Brief Blurb on Radar Physics","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-brief-blurb-on-radar-physics","position":12},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Brief Blurb on Radar Physics","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Radar is fully transmissible in dry snow, but there is frequency-dependent interaction between the radar signal and the snowpack.\n\nAt L-band frequencies (1–2 GHz, ~25 cm wavelength) there limited to no interaction with the snowpack.","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-brief-blurb-on-radar-physics","position":13},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What is GPR?","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#what-is-gpr","position":14},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What is GPR?","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"We use L-band GPR, which was operated during all SnowEx campaigns!\n\nGPR transmits a radar signal into the snowpack, which then reflects off objects/interfaces with contrasting dielectric permittivity. The GPR records the amplitude and two-way travel time (twt) of the reflections.\n\nDielectric permittivity refers to the dielectric properties of the snowpack that define how EM energy transmits through the medium.\n\nUsually, we are interested in the snow-ground interface and we measure the snowpack thickness in twt (nanoseconds).\n\nHowever, in complex vegetation, radargrams are difficult to interpret! Causes increased uncertainty.\n\nSee radargram examples below for the boreal forest GPR surveys (credit Kajsa Holland-Goon).\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#what-is-gpr","position":15},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Snow Depth, SWE, and Density Calculations","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#snow-depth-swe-and-density-calculations","position":16},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Snow Depth, SWE, and Density Calculations","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"To calculate snow depth (d_s) from twt, we need to estimate the relative permittivity (\\epsilon_s) and radar velocity (v_s) of the snowpack:\n\nv_s = \\frac{c}{\\sqrt{\\epsilon_s}}; --> Where c is the velocity of EM energy in a vacuum.\n\n\\epsilon_s = (1+\\frac{0.845\\rho_s}{1000})^2; --> Kovacs et al. (1995), but more than 19 equations exist for dry snow conditions.\n\nd_s = \\frac{twt}{2}*v_s;\n\nSWE = d_s\\rho_s;--> Where SWE is snow water equivalent.\n\nBut...If we know the snow depth, we can constrain the radar velocity and estimate relative permittivity and density!\n\n\\epsilon_s=(\\frac{c*twt}{2d_s})^2\n\n\\rho_s=(\\sqrt{\\epsilon_s}-1)\\frac{1000}{0.845}\n\nHow can we find the snow depth?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#snow-depth-swe-and-density-calculations","position":17},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Shameless Plug...","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-shameless-plug","position":18},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A Shameless Plug...","lvl2":"1. GPR Methods for the Retrieval of Snow Depth and SWE"},"content":"Most analysis-ready GPR products have twt, snow depth, and snow water equivalent. Some have been updated with derived snow densities. See 6. SnowEx GPR Analysis-Ready Datasets below.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-shameless-plug","position":19},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-2-lidar-methods-for-snow-depth-retrieval-and-swe-estimation","position":20},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-2-lidar-methods-for-snow-depth-retrieval-and-swe-estimation","position":21},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous lidar tutorial developed by Naheem Adebisi (ESRI) that may be of interest: https://​snowex​-2022​.hackweek​.io​/tutorials​/lidar​/index​.html","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#previous-lidar-tutorial-developed-by-naheem-adebisi-esri-that-may-be-of-interest-https-snowex-2022-hackweek-io-tutorials-lidar-index-html","position":22},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Previous lidar tutorial developed by Naheem Adebisi (ESRI) that may be of interest: https://​snowex​-2022​.hackweek​.io​/tutorials​/lidar​/index​.html","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#previous-lidar-tutorial-developed-by-naheem-adebisi-esri-that-may-be-of-interest-https-snowex-2022-hackweek-io-tutorials-lidar-index-html","position":23},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A (Very) General Review of Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#a-very-general-review-of-lidar","position":24},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"A (Very) General Review of Lidar","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"Lidar emits photons and measures the twt of the returned photons\n\nThese twt are converted to elevation surfaces (e.g., DEM, DTM, DSM).\n\nLidar can be collected from a variety of platforms:\n\nTerrestrial\n\nUAV\n\nAirborne\n\nSatellite\n\nTwo acquisitions are required for snow, a snow-on acquisition and a snow-off acquisition. Snow depth can be calculated in two general ways:\n\nRaster-based approaches (see figure below, credit Airborne Snow Observatories Inc.)\n\nPoint cloud approaches","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#a-very-general-review-of-lidar","position":25},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"How is SWE calculated from lidar snow depths?","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#how-is-swe-calculated-from-lidar-snow-depths","position":26},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"How is SWE calculated from lidar snow depths?","lvl2":"2. Lidar Methods for Snow Depth Retrieval and SWE Estimation"},"content":"At larger scales, SWE is calculated via modeled densities (e.g., M3 Works and ASO).\n\nAt smaller field sites, it may be appropriate to use representative in situ measurements.\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#how-is-swe-calculated-from-lidar-snow-depths","position":27},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"3. Leveraging Coincident GPR and Lidar Data Sets to Derive Snow Density"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-3-leveraging-coincident-gpr-and-lidar-data-sets-to-derive-snow-density","position":28},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"3. Leveraging Coincident GPR and Lidar Data Sets to Derive Snow Density"},"content":"Density, liquid water content, and relative permittivity are understudied relative to snow depth and/or SWE.\n\nCombined coincident snow depths and twt can yield spatially distributed measurements of relative permittivity.\n\nIn wet snow, relative permittivity can be converted to liquid water content (e.g., Webb et al., 2018, 2020, 2022; Bonnell et al., 2021).\n\nIn dry snow, density can be estimated from the relative permittivity (Yildiz et al., 2021; McGrath et al., 2022; Bonnell et al., 2023; Meehan et al., 2024).\n\nThis technique has provided an unprecedented glimpse into the spatial properties of these parameters!\n\nCritically, studies have noted a large random error in derived products that should be considered (see figure below, credit: Meehan et al., 2024).\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-3-leveraging-coincident-gpr-and-lidar-data-sets-to-derive-snow-density","position":29},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-4-snowex23-gpr-lidar-derived-permittivities-densities-in-the-boreal-forest-alaska","position":30},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-4-snowex23-gpr-lidar-derived-permittivities-densities-in-the-boreal-forest-alaska","position":31},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Here, we will use this approach to derive densities at Farmer’s Loop Creamer’s Field during the SnowEx23 Alaska Campaign","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#here-we-will-use-this-approach-to-derive-densities-at-farmers-loop-creamers-field-during-the-snowex23-alaska-campaign","position":32},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Here, we will use this approach to derive densities at Farmer’s Loop Creamer’s Field during the SnowEx23 Alaska Campaign","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"Lidar data was collected on 11 March 2023\n\nGPR data was collected on 7, 11, 13, and 16 March 2023\n\n#1.1 Load relevant packages\nimport os\nimport numpy as np \nfrom datetime import date\nfrom scipy.spatial import cKDTree\n\n#packages for figures\nimport matplotlib.pyplot as plt\nfrom rasterio.plot import show\n\n#geospatial packages\nimport geopandas as gpd #for vector data\nimport xarray as xr\nimport pandas as pd\nfrom shapely.geometry import box, Point\nimport rasterio as rio\n\n#Import SnowEx database\nfrom snowexsql.api import PointMeasurements, LayerMeasurements, RasterMeasurements\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#here-we-will-use-this-approach-to-derive-densities-at-farmers-loop-creamers-field-during-the-snowex23-alaska-campaign","position":33},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 1: Load the GPR data from the SnowEx data base","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-1-load-the-gpr-data-from-the-snowex-data-base","position":34},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 1: Load the GPR data from the SnowEx data base","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"-Huge thank you to Micah Johnson and Micah Sandusky for their support!\n\nNote that if we used the full GPR/Lidar dataset, we would need to allocate way more memory. This example focuses on a single date of collection in very dense forest.\n\nExamine the headers from the GPR csv --> what are the variables that we are interested in?\n\n# 1.2 Load GPR data\n\n#Note, memory space is fairly limited, will need to pull only one date\n\n#Set a number of dates to pull GPR for\n#dt1 = date(2023, 3, 7)\ndt2 = date(2023, 3, 11)\n#dt3 = date(2023, 3, 13)\n#dt4 = date(2023, 3, 16)\n\n#site1 = LayerMeasurements.from_filter(date=dt1, site_name='Fairbanks', site_id='FLCF', limit=1)\nsite2 = LayerMeasurements.from_filter(date=dt2, site_name='Fairbanks', site_id='FLCF', limit=1)\n#site3 = LayerMeasurements.from_filter(date=dt3, site_name='Fairbanks', site_id='FLCF', limit=1)\n#site4 = LayerMeasurements.from_filter(date=dt4, site_name='Fairbanks', site_id='FLCF', limit=1)\n\n#Use pandas ot read in csv data\n#gpr_df_dt1 = PointMeasurements.from_area(pt=site1.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt1, site_name='farmers-creamers',\n#    limit=29432)#The number of expected measurements\ngpr_df_dt2 = PointMeasurements.from_area(pt=site2.geometry[0], crs=26906, buffer=10000,\n    type='two_way_travel',\n    observers='Randall Bonnell',\n    date=dt2, site_name='farmers-creamers',\n    limit=20213)#The number of expected measurements\n#gpr_df_dt3 = PointMeasurements.from_area(pt=site3.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt3, site_name='farmers-creamers',\n#    limit=19024)\n#gpr_df_dt4 = PointMeasurements.from_area(pt=site4.geometry[0], crs=26906, buffer=10000,\n#    type='two_way_travel',\n#    observers='Randall Bonnell',\n#    date=dt4, site_name='farmers-creamers',\n#    limit=15785)\n\n\n#Compile into one dataframe\n#flcf_gpr_df = pd.concat([gpr_df_dt1,gpr_df_dt2,gpr_df_dt3,gpr_df_dt4],axis=0, join='outer', ignore_index=True, keys=None, levels=None,names=None,verify_integrity=False,sort=False,copy=None)\nflcf_gpr_df = gpr_df_dt2\n#Print out the csv headers and initial entries --> What's important here and what do we need?\nprint(flcf_gpr_df.head())\n\n# Let's look at the distribution of gpr two-way travel times and estimated snow depths\n#Estimate snow depths from twt by assuming a velocity of 0.25 m/ns --> Is this an appropriate velocity estimate?\nflcf_gpr_df['Depth_estimated'] = (flcf_gpr_df['value']/2)*0.25\n\nax1 = flcf_gpr_df.plot.hist(column=[\"value\"], edgecolor='black', title='two-way travel time (ns)')\nax2 = flcf_gpr_df.plot.hist(column=[\"Depth_estimated\"], edgecolor='black', title='Snow depth (m)')\n\n#Extract x/y limits from GPR data --> these will be used when loading the lidar snow depths\nbounds = flcf_gpr_df.total_bounds\n\n# Create a bounding box\ngpr_limits = box(*bounds)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-1-load-the-gpr-data-from-the-snowex-data-base","position":35},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s load in the lidar canopy heights and snow depths.","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#lets-load-in-the-lidar-canopy-heights-and-snow-depths","position":36},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s load in the lidar canopy heights and snow depths.","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"We’ll look at the canopy heights to get an idea of what kind of forest the data were collected in.\n\nThen, we’ll look at the lidar snow depths to visualize the snow distribution.","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#lets-load-in-the-lidar-canopy-heights-and-snow-depths","position":37},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions","position":38},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"4. SnowEx23 GPR/Lidar Derived Permittivities/Densities in the Boreal Forest, Alaska"},"content":"What type of survey design was implemented for the GPR?\n\nDo the lidar snow depth patterns seem to exhibit any kind of dependence upon the forest cover?\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions","position":39},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Commented until we fix reading of raster data"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#commented-until-we-fix-reading-of-raster-data","position":40},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# # 1.3 Load Lidar vegetation/canopy heights --> This may take a few minutes\n# #Read in the canopy heights raster from Farmer's Loop/Creamer's Field Alaska\n# flcf_ch = RasterMeasurements.from_area(shp = gpr_limits, crs=26906,\n#     buffer=None, type='canopy_height',\n#     site_name='farmers-creamers',\n#     observers='chris larsen')\n# print(flcf_ch)\n\n# #Plot the datasets\n# fig, ax = plt.subplots()\n# show(flcf_ch, ax=ax, cmap='Greens', clim=(0,5), title = 'Canopy Height (m)')\n# #Plot the GPR points on top\n# flcf_gpr_df.plot(ax=ax, color='blue', markersize = 10)\n\n# # 1.4 Load Lidar Snow depths --> This will take a few minutes\n\n# #Read in the canopy heights raster from Farmer's Loop/Creamer's Field Alaska\n# flcf_ds = RasterMeasurements.from_area(shp = gpr_limits, crs=26906,\n#     buffer=None, type='depth',\n#     site_name='farmers-creamers',\n#     observers='chris larsen')\n\n# #Plot the datasets\n# fig, ax = plt.subplots()\n# show(flcf_ds, ax=ax, cmap='Blues', clim=(0,1.5), title='Snow Depth (m)')\n# #Plot the GPR points on top\n# flcf_gpr_df.plot(ax=ax, color='red', markersize = 10)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#commented-until-we-fix-reading-of-raster-data","position":41},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 2: Match the GPR data to the lidar grid and derive relative permittivity and density","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-2-match-the-gpr-data-to-the-lidar-grid-and-derive-relative-permittivity-and-density","position":42},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 2: Match the GPR data to the lidar grid and derive relative permittivity and density","lvl2":"Commented until we fix reading of raster data"},"content":"There are two conceptual paths forward:\n\nRasterize the GPR data or\n\nVectorize the lidar data\n\nFor simplicity, the following code:\n\nvectorizes the lidar data\n\nperforms a nearest neighbor search between the lidar and GPR coordinate vectors\n\nCalculates the median GPR twt from the nearest neighbors\n\nDerives relative permittivity and density from the lidar snow depths and median twt\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-2-match-the-gpr-data-to-the-lidar-grid-and-derive-relative-permittivity-and-density","position":43},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"We need to know the resolutions of the lidar and GPR datasets","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#we-need-to-know-the-resolutions-of-the-lidar-and-gpr-datasets","position":44},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"We need to know the resolutions of the lidar and GPR datasets","lvl2":"Commented until we fix reading of raster data"},"content":"The GPR dataset consists of points that are spaced ~0.10 m apart.\n\nWhat about the lidar? Run the code block below to answer this question.\n\nHow many GPR points would you expect to have per lidar pixel? Assume linear transects through each pixel.\n\n# #2.1 Let's learn a bit about the resolution of the lidar rasters\n\n# height, width = flcf_ds.read(1).shape #Find the height and width of the array\n\n# #Use meshgrid to create two arrays matching the height/width of the input raster\n# #The GPR dataset consists of vectors --> we will eventually need to vectorize these lidar arrays\n# cols, rows = np.meshgrid(np.arange(width), np.arange(height)) \n\n\n# #Extract the easting/northing from the raster \n# x_lidar, y_lidar = rio.transform.xy(flcf_ds.transform, rows, cols) \n\n# #What's the resolution of the lidar dataset?\n# print(\"The x resolution of the snow depth raster is:\",x_lidar[0][1]-x_lidar[0][0])\n# print(\"The y resolution of the snow depth raster is:\",y_lidar[0][0]-y_lidar[1][0])\n\n\n# # 2.2 Matching GPR to the lidar grid\n\n# #Two conceptual paths forward: rasterize the GPR data, or convert lidar data to points\n\n# #Let's vectorize the raster data\n# x_lidar_vec = np.array(x_lidar).flatten()\n# y_lidar_vec = np.array(y_lidar).flatten()\n# flcf_ds_vec = flcf_ds.read().flatten()\n\n# #Pull vectors from geo dataframe\n# gpr_arr = np.stack([flcf_gpr_df.geometry.x, flcf_gpr_df.geometry.y,flcf_gpr_df['value']], axis=1)\n# gpr_x=gpr_arr[:,0]\n# gpr_y=gpr_arr[:,1]\n# gpr_twt=gpr_arr[:,2].reshape(len(gpr_arr[:,2]),1)\n\n\n# #2.3 Create sets of coordinates for the nearest neighbors search\n# coordinates_set1 = np.column_stack((x_lidar_vec,y_lidar_vec))\n# coordinates_set2 = np.column_stack((gpr_x,gpr_y))\n\n# # Build KDTree from the second set of coordinates\n# tree = cKDTree(coordinates_set2)\n\n# # Define the radius (in meters)\n# radius = 0.25\n\n# # Function to find the median of travel times within a radius --> Credit where credit is due, this function was generated in part by chatgpt\n# def find_median_travel_time_within_radius(point, tree, coordinates_set1, gpr_twt, radius):\n#     indices = tree.query_ball_point(point, radius)\n#     if indices:\n#         # Retrieve travel times for the nearest neighbors\n#         neighbor_twt = gpr_twt[indices]\n#         median_twt = np.median(neighbor_twt)\n#         return median_twt\n#     else:\n#         return np.nan  # Return NaN if no neighbors are within the radius\n# # Find medians for each lidar point\n# medians = np.array([find_median_travel_time_within_radius(point, tree, coordinates_set2, gpr_twt, radius) for point in coordinates_set1])\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#we-need-to-know-the-resolutions-of-the-lidar-and-gpr-datasets","position":45},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"The GPR data is not as spatially continuous as the lidar data, so most of the median twt dataset consists of nan’s","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#the-gpr-data-is-not-as-spatially-continuous-as-the-lidar-data-so-most-of-the-median-twt-dataset-consists-of-nans","position":46},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"The GPR data is not as spatially continuous as the lidar data, so most of the median twt dataset consists of nan’s","lvl2":"Commented until we fix reading of raster data"},"content":"Let’s remove the nan’s to free up memory and reduce processing time.\n\n# #At this point, all lidar points should have an associated gpr twt --> most are likely nan's though. But let's check!\n# print(\"The gpr array has size:\",medians.shape)\n# print(\"The lidar array has size:\",flcf_ds_vec.shape)\n\n\n# #2.4 Before we get to the math part, let's clear out the nan's from all important vectors:\n# #Create mask for gpr medians that are nan's\n# mask = np.isnan(medians)\n\n# #Remove entries from the lidar snow depth, x, and y vectors that align with the nan twt values\n# flcf_ds_vec_clean = flcf_ds_vec[~mask]\n# coordinates_set1_clean=coordinates_set1[~mask]\n\n# #Lastly, remove entries from the twt medians\n# medians_clean = medians[~mask]\n\n# #Let's check the new size of the twt array\n# print(medians_clean.shape)\n\n\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#the-gpr-data-is-not-as-spatially-continuous-as-the-lidar-data-so-most-of-the-median-twt-dataset-consists-of-nans","position":47},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions-1","position":48},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Discussion questions:","lvl2":"Commented until we fix reading of raster data"},"content":"Roughly, how many points were removed?\n\nWhen we are done, we will have derived 3788 snow density estimates. In the same area, about four snow pits were dug, resulting in four bulk density measurements. How useful do you think our data will be?\n\nIs more always better?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#discussion-questions-1","position":49},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s now transition to the relative permittivity and density calculations","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#lets-now-transition-to-the-relative-permittivity-and-density-calculations","position":50},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Let’s now transition to the relative permittivity and density calculations","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# #2.5 We finally get to the math part!!\n# #Let's calculate relative permittivity first...\n# c=0.2998#The speed of light in a vacuum\n# e_s = ((c * medians_clean) / (2 * flcf_ds_vec_clean)) ** 2\n\n# #And then calculate density\n# rho_s = ((np.sqrt(e_s) - 1) / 0.845) * 1000\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#lets-now-transition-to-the-relative-permittivity-and-density-calculations","position":51},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 3: Examining the derived densities","lvl2":"Commented until we fix reading of raster data"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#part-3-examining-the-derived-densities","position":52},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Part 3: Examining the derived densities","lvl2":"Commented until we fix reading of raster data"},"content":"\n\n# # 3.1 Finally, let's take a peek at what the derived densities look like...\n# plt.figure()\n# plt.scatter(coordinates_set1_clean[:,0], coordinates_set1_clean[:,1], s=10, c=rho_s, cmap='viridis', clim=(0, 500), edgecolor=None)\n\n# # Add colorbar to show the scale of color values\n# plt.colorbar()\n# plt.title('Snow Density (kg m-3)')\n\n# # Show the plot\n# plt.show()\n\n# # 3.2 What does the histogram distribution look like??\n# # Define bin edges\n# bin_edges = np.arange(np.min(rho_s), np.max(rho_s), 25)  # Create bin edges from min(x) to max(x) with step size 25\n\n# # Create the histogram\n# plt.figure()  # Create a new figure\n# plt.hist(rho_s, bins=bin_edges, edgecolor=None)  # Plot histogram with specified bin edges\n\n# plt.title('Snow Density Histogram')\n\n# # Show the plot\n# plt.show()\n\n# #Let's zoom in a little...\n# # Define bin edges\n# bin_edges = np.arange(0, 500, 25)  # Create bin edges from min(x) to max(x) with step size 25\n\n# # Create the histogram\n# plt.figure()  # Create a new figure\n# plt.hist(rho_s, bins=bin_edges, edgecolor='black')  # Plot histogram with specified bin edges\n\n# plt.title('Snow Density Histogram')\n\n# # Show the plot\n# plt.show()\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#part-3-examining-the-derived-densities","position":53},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-5-discussion-improving-density-estimation","position":54},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"5. Discussion: Improving Density Estimation"},"content":"What do you think? Do the derived densities look usable at this stage?","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-5-discussion-improving-density-estimation","position":55},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What contributes to the random error?","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#what-contributes-to-the-random-error","position":56},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"What contributes to the random error?","lvl2":"5. Discussion: Improving Density Estimation"},"content":"There are three groups of factors that control the random error:\n\nMeasurement accuracy for lidar snow depths and GPR twt. Reduced accuracy for either or both of the techniques will lead to large errors. The boreal forest had a lot of complex vegetation that may have impeded the accuracy of these instruments.\n\nDepth of the snowpack. The accuracy of the lidar is not a function of snow depth. Thus, the random errors reduce as the snow depth increases. The boreal forest snow depths were shallow!\n\nGeolocation alignment. GPR coordinates were post-processed, but accuracy is still likely on the order of ±3 m.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#what-contributes-to-the-random-error","position":57},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Improving the derived densities","lvl2":"5. Discussion: Improving Density Estimation"},"type":"lvl3","url":"/notebooks/gpr-lidar-hackweektutorial#improving-the-derived-densities","position":58},{"hierarchy":{"lvl1":"GPR and Lidar","lvl3":"Improving the derived densities","lvl2":"5. Discussion: Improving Density Estimation"},"content":"Let’s say we want to learn something about snow density in the boreal forest. The derived densities offer a HUGE increase in the number of available density measurements compared to in situ. But, in situ are much more accurate. How can we improve this dataset?\n\nIncrease the footprint of the derived densities by upsampling the lidar (e.g., to 3 m).\n\nThis will reduce the impact of GPR geolocation accuracy and the lidar/GPR observation uncertainty.\n\nNeed to be careful! The GPR footprint is large, but it may not scale well past 3 m.\n\nRemove erroneous values.\n\nHow does the lidar survey time compare with the GPR survey time? Was the snow disturbed or did more snow accumulate between surveys?\n\nRelative permittivity of snow cannot be less than air (\\epsilon_a = 1.0) or greater than liquid water (\\epsilon_w = 88).\n\nFor dry snow, relative permittivity is usually between 1.0 and 2.0. The removal of values outside a certain number of standard deviations and/or the interquartile range may be warranted.\n\nRun a spatial averaging filter.\n\nOur surveys were primarily spirals --> should pair nicely with such a filter!\n\nExperiment with the window size of the filter. How would a 5 m x 5 m filter compare to a 25 m x 25 m filter?\n\nShould the data be parsed into different forest cover classes before such a filter is run?\n\nBe careful of linear transects! Large windows tend to remove any density variability along such transects.\n\nOnce you reach this point, it is likely that the densities will be analysis ready. You could run a predictive model to fill in the void spaces, use the densities to evaluate models, calculate experimental variograms, etc.\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#improving-the-derived-densities","position":59},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"6. SnowEx GPR Analysis-Ready Datasets"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-6-snowex-gpr-analysis-ready-datasets","position":60},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"6. SnowEx GPR Analysis-Ready Datasets"},"content":"Grand Mesa, Colorado (SnowEx 2017, 2020)\n\nWebb et al. (2019). \n\nWebb et al. (2019)\n\nBonnell et al. (2021). \n\nBonnell et al. (2021)\n\nMeehan (2021). \n\nMeehan (2021)\n\nWebb (2021). \n\nWebb (2021)\n\nMeehan & Hojatimalekshah (2024). \n\nMeehan & Hojatimalekshah (2024)\n\nCameron Pass, Colorado (SnowEx 2020, 2021)\n\nMcGrath et al. (2021). \n\nMcGrath et al. (2021)\n\nBonnell et al. (2022). \n\nBonnell et al. (2022)\n\nBonnell et al. (2024). \n\nBonnell et al. (2024)\n\nJemez Mountains, New Mexico (SnowEx 2020)\n\nWebb (2021). \n\nWebb (2021)\n\nArctic Coastal Plains, Alaska (SnowEx 2023)\n\nWebb (2024). \n\nWebb (2024)\n\n","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-6-snowex-gpr-analysis-ready-datasets","position":61},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"7. References"},"type":"lvl2","url":"/notebooks/gpr-lidar-hackweektutorial#id-7-references","position":62},{"hierarchy":{"lvl1":"GPR and Lidar","lvl2":"7. References"},"content":"Lidar Datasets\n\nLarsen (2024). \n\nLarsen (2024)\n\nRelevant GPR LWC Studies\n\nWebb et al. (2018). \n\nWebb et al. (2018)\n\nWebb et al. (2020). \n\nWebb et al. (2020)\n\nBonnell et al. (2021). \n\nBonnell et al. (2021)\n\nWebb et al. (2022). \n\nWebb et al. (2022)\n\nRelevant GPR Density Studies\n\nYildiz et al. (2021). \n\nYildiz et al. (2021)\n\nMcGrath et al. (2022). \n\nMcGrath et al. (2022)\n\nBonnell et al. (2023). \n\nBonnell et al. (2023)\n\nMeehan et al. (2024). \n\nMeehan et al. (2024)","type":"content","url":"/notebooks/gpr-lidar-hackweektutorial#id-7-references","position":63},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"type":"lvl1","url":"/notebooks/snowex-data-overview","position":0},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"content":"\n\n","type":"content","url":"/notebooks/snowex-data-overview","position":1},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"type":"lvl1","url":"/notebooks/snowex-data-overview#field-campaigns-overview","position":2},{"hierarchy":{"lvl1":"Field Campaigns Overview"},"content":"(5 minutes)\n\nBy: Megan Mason (NASA Goddard / SSAI) \n\nmegan​.a​.mason@nasa​.gov\n\nSupport by:  Carrie Vuyovich (NASA Goddard), Hans-Peter Marshall (Boise State), Svetlana Stuefer (University of Alaska Fairbanks)\n\nLearning Objectives\n\nVisual overview of the NASA SnowEx field campaigns\n\nGet a sense for the extent of data coverage\n\n\n\n","type":"content","url":"/notebooks/snowex-data-overview#field-campaigns-overview","position":3},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl2":"Data Coverage"},"type":"lvl2","url":"/notebooks/snowex-data-overview#data-coverage","position":4},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl2":"Data Coverage"},"content":"Each year we build upon our efforts to further investigate snow remote sensing science gaps identified in the NASA SnowEx Science Plan \n\n(Durand et al., 2016). The summary table lists the focus for each campaign by year and type. There are two different campaign types (IOP vs. TS); both result in the same types of measurements and data products. Depending on the  research application it may not matter at all which you choose to work with, or even combine! The important thing to grasp is the difference in spatial and temporal extent of the campaign periods. If the sampling protocols or data products change over time, it is for the sake of improvement. When possible, we aim to keep things consistent to continue to build a legacy data set.\n\nYear\n\nCampaign Type\n\nMeasurement Focus\n\n2017\n\nIOP\n\nColorado, focused on multiple instruments in a forest gradient.\n\n2020\n\nIOP, TS\n\nWestern U.S focused on Time Series of L-band InSAR, active/passive microwave for SWE and thermal IR for snow surface temp.\n\n2021\n\nTS\n\nWestern U.S, continued Time Series of L-band InSAR, also addressed prairie & snow albedo questions.\n\n2023\n\nIOP\n\nAlaska Tundra & Boreal forest, focused on addressing SWE/snow depth and albedo objectives.\n\n*IOP=Intense Observation Period (~2-3 week, daily observations) *; TS=Time Series (~3-5 month winter, weekly observations)\n\n","type":"content","url":"/notebooks/snowex-data-overview#data-coverage","position":5},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Where has SnowEx Been?","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#where-has-snowex-been","position":6},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Where has SnowEx Been?","lvl2":"Data Coverage"},"content":"Campaign efforts are focused on various snow climates in the western United States. SnowEx partnerships and expertise are spread across the U.S and international.\n\n\nFigure 1. Map showing the locations of SnowEx field campaign areas (red dot). Base map shows snow classes defined in \n\nSturm and Liston, 2021. The snow pit images show a representative pit in each of the class types visited by SnowEx.\n\nTable 1. Number of manual depths and snow pits associated with NASA SnowEx measurement periods.\n\nSnowEx\n\nField Campaign Location\n\nTemporal Coverage\n\nManual Depths\n\nSnow Pits\n\nS17\n\nGrand Mesa & Senator Beck Basin, Colorado\n\nFebruary 6-25, 2017\n\n23,432\n\n265\n\nS20\n\nGrand Mesa, ColoradoWestern U.S Time Series (13 sites)\n\nNovember 4-7, 2019January 27-February 12, 2020October 24-May 20, 2020*\n\n16,21237,921TBD\n\n21154454\n\nS21\n\nWestern U.S Time Series (7 sites)\n\nNovember 16-May 27, 2021\n\n12,536\n\n247\n\nS23\n\nTundra & Boreal Forest, Alaska (pre-campaign site visit)Tundra & Boreal Forest, AlaskaTundra & Boreal Forest, AlaskaBoreal Forest, AlaskaTundra & Boreal Forest, Alaska\n\nMarch 7-17, 2022October 22-27, 2022March 7-16, 2023April 5-May 6, 2023October 17-28, 2023\n\n10,7289,04926,750TBD6,350\n\n1818617013127\n\n*The majority of sites in 2020 have a temporal coverage of January-March due to the Covid-19 pandemic.\n\n","type":"content","url":"/notebooks/snowex-data-overview#where-has-snowex-been","position":7},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Snow Classification Coverage","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#snow-classification-coverage","position":8},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Snow Classification Coverage","lvl2":"Data Coverage"},"content":" Thanks to Sturm and Liston 2021 (and 1995), we have a global seasonal snow classification system. This is a vital mission planning tool for remote sensing snow studies. Revised from inception, the snow classification system offers improved utility of the climatological snow classes due to improved (much higher) resolution (300 m over North America). This data set can be found at NSIDC and downloaded at multiple resolutions.\n\n[NSIDC Global Seasonal-Snow Classification, Version 1](https://nsidc.org/data/NSIDC-0768/versions/1) \n\nCheck out [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml) to find out more \n    \n![](./content/01_snow-classes-sturm.png)\n**Figure 3.** Snow Classes across North America at 300 m (Sturm and Liston, 2021) \n\nAs part of the mission statement, SnowEx aims to quantify snow estimation uncertainty across a range of snow classes, terrain and vegetation types. This is important to determine what areas and time periods have high SWE uncertainty across the ensemble of instrument techniques.\n\n\nFigure 2. Map of the in situ field visits for the duration of SnowEx field campaigns (2017-2023). At this scale, points are overlapping, especially in the eastern Rocky Mountain region around Colorado. The total number of unique visits with recorded SWE are listed in the legend. Upper Right Bar chart of snow classes over the four SnowEx field campaign years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occurred in open areas such as meadows and clearings. The snow classification colors match those used in \n\nSturm and Liston, 2021. ![](./content/01_snow-classes-barchart.png)\n**Figure 2.** Bar chart of snow classes over the four SnowEx field campagin years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occured in open areas such as meadows and clearings. The snow classification colors match those used in [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml).   ![](./content/01_map-n-barchart.png)\n**Figure 2.** Bar chart of snow classes over the four SnowEx field campagin years. Counts represent in situ field visits. A range of sites in Boreal and Montane Forests occured in open areas such as meadows and clearings. The snow classification colors match those used in [Sturm and Liston, 2021](https://journals.ametsoc.org/view/journals/hydr/22/11/JHM-D-21-0070.1.xml). \n\n","type":"content","url":"/notebooks/snowex-data-overview#snow-classification-coverage","position":9},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Recap","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#recap","position":10},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"Recap","lvl2":"Data Coverage"},"content":"SnowEx campaigns are structured based on the objectives set out in the SnowEx Science Plan. Some of those objectives are meet by conducting an all hands-on, short and intense observation period (IOP), while others are addressed by studying the evolution of the snowpack over a much longer time series (TS) style campaign.\n\nThe coincident field and airborne campaigns are designed to directly respond to the current knowledge gaps in remote sensing of seasonal snow, thus the participant-driven SnowEx effort targets a range of snow classes, terrain and vegetation types.\n\n","type":"content","url":"/notebooks/snowex-data-overview#recap","position":11},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"References","lvl2":"Data Coverage"},"type":"lvl3","url":"/notebooks/snowex-data-overview#references","position":12},{"hierarchy":{"lvl1":"Field Campaigns Overview","lvl3":"References","lvl2":"Data Coverage"},"content":"SnowEx Experimental Plans: 2017, \n\n2020, \n\n2021, \n\n2023\n\nSnowEx Science Plan\n\nSturm and Liston, 2021","type":"content","url":"/notebooks/snowex-data-overview#references","position":13},{"hierarchy":{"lvl1":"SnowExSQL Database"},"type":"lvl1","url":"/notebooks/snowexsql-database","position":0},{"hierarchy":{"lvl1":"SnowExSQL Database"},"content":"Tutorial Author Micah’: \n\nMicah Sandusky\n\nTutorial Author Micah_o: \n\nMicah Johnson\n\nSnowEx has introduced a unique opportunity to study SWE in a way that’s unprecedented, but with more data comes new challenges. \n<img src=\"https://snowexsql.readthedocs.io/en/latest/_images/gallery_overview_example_12_0.png\" alt=\"Grand Mesa Overview\" width=\"1000px\"> \n\nThe SnowEx database is a resource that shortcuts the time it takes to ask cross dataset questions\n\nStandardizing diverse data\n\nCross referencing data\n\nProvenance!\n\nAdded GIS functionality\n\nConnect w/ ArcGIS or QGIS!\n\nCITABLE\n\n2022- Estimating snow accumulation and ablation with L-band interferometric synthetic aperture radar (InSAR)\n\n2024 - Thermal infrared shadow-hiding in GOES-R ABI imagery: snow and forest temperature observations from the SnowEx 2020 Grand Mesa field campaign","type":"content","url":"/notebooks/snowexsql-database","position":1},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"What’s in it?"},"type":"lvl3","url":"/notebooks/snowexsql-database#whats-in-it","position":2},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"What’s in it?"},"content":"Snow pits - Density, hardness profiles, grain types + sizes\n\nManual snow depths - TONS of depths (Can you say spirals?)\n\nSnow Micropenetrometer (SMP) profiles - (Subsampled to every 100th)\n\nSnow depth + SWE rasters from ASO Inc.\n\nGPR\n\nPit site notes\n\nCamera Derived snow depths\n\nSnow off DEM from USGS 3DEP\n\nAnd almost all the associated metadata","type":"content","url":"/notebooks/snowexsql-database#whats-in-it","position":3},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Technically, what is it?"},"type":"lvl3","url":"/notebooks/snowexsql-database#technically-what-is-it","position":4},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Technically, what is it?"},"content":"PostgreSQL database\n\nPostGIS extension\n\nSupports vector and raster data\n\nAnd a host of GIS operations\n\nAND NOW WITH API!","type":"content","url":"/notebooks/snowexsql-database#technically-what-is-it","position":5},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"So what’s the catch?","lvl3":"Technically, what is it?"},"type":"lvl4","url":"/notebooks/snowexsql-database#so-whats-the-catch","position":6},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"So what’s the catch?","lvl3":"Technically, what is it?"},"content":"New tech can create barriers...\n\n","type":"content","url":"/notebooks/snowexsql-database#so-whats-the-catch","position":7},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"TL;DR Do less wrangling, do more crunching.","lvl3":"Technically, what is it?"},"type":"lvl4","url":"/notebooks/snowexsql-database#tl-dr-do-less-wrangling-do-more-crunching","position":8},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"TL;DR Do less wrangling, do more crunching.","lvl3":"Technically, what is it?"},"content":"\n\n","type":"content","url":"/notebooks/snowexsql-database#tl-dr-do-less-wrangling-do-more-crunching","position":9},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I get at this magical box of data ?"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-do-i-get-at-this-magical-box-of-data","position":10},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I get at this magical box of data ?"},"content":"SQL\n\nsnowexsql \n\n← 😎","type":"content","url":"/notebooks/snowexsql-database#how-do-i-get-at-this-magical-box-of-data","position":11},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Welcome to API Land","lvl3":"How do I get at this magical box of data ?"},"type":"lvl4","url":"/notebooks/snowexsql-database#welcome-to-api-land","position":12},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Welcome to API Land","lvl3":"How do I get at this magical box of data ?"},"content":"\n\nfrom snowexsql.api import PointMeasurements\n\ndf = PointMeasurements.from_filter(type=\"depth\", instrument='pit ruler', limit=100)\ndf.plot(column='value', cmap='jet', vmin=10, vmax=150)\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#welcome-to-api-land","position":13},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Old Ways / Advanced Users","lvl3":"How do I get at this magical box of data ?"},"type":"lvl4","url":"/notebooks/snowexsql-database#old-ways-advanced-users","position":14},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Old Ways / Advanced Users","lvl3":"How do I get at this magical box of data ?"},"content":"Advanced queries can be made using SQL or SQAlchemy under the hood.\n\nSee previous presentations\n\nEngine objects, session objects, and a crash course in ORM, oh my!\n\nHackweek 2021\n\nHackweek 2022\n\n","type":"content","url":"/notebooks/snowexsql-database#old-ways-advanced-users","position":15},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"How is the Database Structured?"},"type":"lvl2","url":"/notebooks/snowexsql-database#how-is-the-database-structured","position":16},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"How is the Database Structured?"},"content":"The goal of the database is to hold as much of the SnowEx data in one place and make it easier to\ndo research with. With that in mind follow the steps below to see how the the data base is structured.\n\n","type":"content","url":"/notebooks/snowexsql-database#how-is-the-database-structured","position":17},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Where do datasets live (i.e. tables)?","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#where-do-datasets-live-i-e-tables","position":18},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Where do datasets live (i.e. tables)?","lvl2":"How is the Database Structured?"},"content":"Data in the database lives in 1 of 4 places.\n\n\n\nLayout of the database tables\n\nThe 4th table is a table detailing the site information. Lots and lots of metadata for which the API has not been written yet.\n\nSo how does this look in python?\n\nfrom snowexsql.api import PointMeasurements, LayerMeasurements, RasterMeasurements\n\n","type":"content","url":"/notebooks/snowexsql-database#where-do-datasets-live-i-e-tables","position":19},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How are tables structured?","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-are-tables-structured","position":20},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How are tables structured?","lvl2":"How is the Database Structured?"},"content":"Each table consists of rows and columns. Below are the available columns!\n\n# Import the class reflecting the points table in the db\nfrom snowexsql.api import PointMeasurements as measurements\n\n# Grab one measurement to see what attributes are available\ndf = measurements.from_filter(type=\"depth\", limit=1)\n\n# Print out the results nicely\nprint(\"These are the available columns in the table:\\n \\n* {}\\n\".format('\\n* '.join(df.columns)))\n\nTry this: Using what we just did, but swap out PointMeasurements for LayerMeasurements.\n\nQuestion: Did you collect any data? What is it? What table do you think it would go in?\n\nFor more detail, checkout the readthedocs page on \n\ndatabase structure to see how data gets categorized.\n\n","type":"content","url":"/notebooks/snowexsql-database#how-are-tables-structured","position":21},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#bonus-step-learning-to-help-yourself","position":22},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowexsql has a host of resources for you to  help your self. First when you are looking for something be sure to check the snowexsql’s docs.\nThere you will find notes on the database structure. datasets, and of course our new API!","type":"content","url":"/notebooks/snowexsql-database#bonus-step-learning-to-help-yourself","position":23},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Usage/Examples","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl4","url":"/notebooks/snowexsql-database#database-usage-examples","position":24},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Usage/Examples","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowexsql Code\n\nsnowexsql Documentation","type":"content","url":"/notebooks/snowexsql-database#database-usage-examples","position":25},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Building/Notes","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"type":"lvl4","url":"/notebooks/snowexsql-database#database-building-notes","position":26},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Database Building/Notes","lvl3":"Bonus Step: Learning to help yourself","lvl2":"How is the Database Structured?"},"content":"snowex_db Code\n\nsnowex_db Documentation\n\n","type":"content","url":"/notebooks/snowexsql-database#database-building-notes","position":27},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"How is the Database Structured?"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap","position":28},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"How is the Database Structured?"},"content":"You just explored the database structure and discussed how they differ.\n\nYou should know:\n\nWhich table a dataset might live in\n\nWhat columns you can work with (or how to get the available columns)\n\nSome resources to begin helping yourself.\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!\n\n","type":"content","url":"/notebooks/snowexsql-database#recap","position":29},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Forming Queries through the API!"},"type":"lvl2","url":"/notebooks/snowexsql-database#forming-queries-through-the-api","position":30},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Forming Queries through the API!"},"content":"Get familiar with the tools available for querying the database. The simplest way is to use the api classes\n\nsnowexsql.api.PointMeasurements\n\nsnowexsql.api.LayerMeasurements\n\nEach class has to very useful functions\n\nfrom_filter\n\nfrom_area","type":"content","url":"/notebooks/snowexsql-database#forming-queries-through-the-api","position":31},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_filter","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#useful-function-from-filter","position":32},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_filter","lvl2":"Forming Queries through the API!"},"content":"Use the from filter function to find density profiles\n\n# Import in our two classes to access the db\nfrom snowexsql.api import LayerMeasurements\nfrom datetime import datetime \n\n# Find some density pit measurements at the Boise site in december 2019.\ndf = LayerMeasurements.from_filter(\n    type=\"density\",\n    site_name=\"Boise River Basin\",\n    date_less_equal=datetime(2020, 1, 1),\n    date_greater_equal=datetime(2019, 12, 1),\n)\n\n# Plot Example!\ndf.plot()\n\n# Show off the dataframe\ndf\n\n# Analysis Example - Find the bulk density \ndf['value'] = df['value'].astype(float)\nprint(df[['site_id', 'value']].groupby(by='site_id').mean())\n\n","type":"content","url":"/notebooks/snowexsql-database#useful-function-from-filter","position":33},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_area","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#useful-function-from-area","position":34},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Useful Function - from_area","lvl2":"Forming Queries through the API!"},"content":"Find specific surface area within a certain distance of a pit.\n\n# Import our api class\nfrom snowexsql.api import LayerMeasurements\nfrom datetime import datetime\nimport geopandas as gpd \n\n# import some gis functionality \nfrom shapely.geometry import Point \n\n# Find some SSA measurements within a distance of a known point\npnt = Point(740820.624625,4.327326e+06)\ndf = LayerMeasurements.from_area(pt=pnt, crs=26912, buffer=500,\n    type='specific_surface_area')\n\n# plot up the results\nax = df.plot()\n\n# plot the site so we can see how close everything is.\nsite = gpd.GeoDataFrame(geometry=[pnt], crs=26912)\nsite.plot(ax=ax, marker='^', color='magenta')\n\n# show off the dataframe\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#useful-function-from-area","position":35},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#how-do-i-know-what-to-filter-on","position":36},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"content":"We got tools for that! Each class has a host of functions that start with all_* these function return the unique value in that column.\n\nall_types - all the data types e.g. depth, swe, density...\n\nall_instruments - all instruments available in the table\n\nall_dates - all dates listed in the table\n\nall_site_names - all the site names available in the table. e.g. Grand Mesa\n\nfrom snowexsql.api import PointMeasurements\n\n# Instantiate the class to use the properties!\nmeasurements = PointMeasurements()\n\n# Get the unique data names/types in the table\nresults = measurements.all_types\nprint('Available types = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique instrument in the table\nresults = measurements.all_instruments\nprint('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique dates in the table\nresults = measurements.all_dates\nprint('\\nAvailable Dates = {}'.format(', '.join([str(r) for r in results])))\n\n# Get the unique site names in the table\nresults = measurements.all_site_names\nprint('\\nAvailable sites = {}'.format(', '.join([str(r) for r in results])))\n\n","type":"content","url":"/notebooks/snowexsql-database#how-do-i-know-what-to-filter-on","position":37},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"More specific filtering options","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#more-specific-filtering-options","position":38},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"More specific filtering options","lvl3":"How do I know what to filter on?","lvl2":"Forming Queries through the API!"},"content":"Sometimes we need a bit more filtering to know more about what I can filter on. Questions like “What dates was the SMP used?” are a bit more complicated than “Give me all the dates for snowex”\n\nThe good news is, we have tool for that! from_unique_entries is your friend!\n\n# import layer measurements\nfrom snowexsql.api import LayerMeasurements\n\n# Query dates where SMP was used\nLayerMeasurements.from_unique_entries(['date'], instrument='snowmicropen')\n\n","type":"content","url":"/notebooks/snowexsql-database#more-specific-filtering-options","position":39},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#query-nuances","position":40},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"","type":"content","url":"/notebooks/snowexsql-database#query-nuances","position":41},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Limit size","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#limit-size","position":42},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Limit size","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"To avoid accidental large queries, we have added some bumper rails. By default if you ask for more than 1000 records then an error will pop up unless you explicitly say you want more.\n\nTry This: Do a large query. Run the code block below without the limit keyword argument (“kwarg”):\n\n# Import PointMeasurements\nfrom snowexsql.api import PointMeasurements\n\n# Query db using a vague filter or on a huge dataset like GPR but remove the limit kwarg\ndf = PointMeasurements.from_filter(type='two_way_travel', limit=100)\n\n# Show the dataframe\ndf\n\n\n\nWe have added this on the db to allow you to explore without accidentally pulling the entire SnowEx universe down. If you know you want a large query (defined as > 1000) then use the limit = #### option in the from_filter or from_area function.\n\nWarning - It is better to filter using other things besides the limit because the limit is not intelligent. It will simply limit the query by the order of entries that were submitted AND fits your filter. So if you encounter this then consider how to tighten up the filter.","type":"content","url":"/notebooks/snowexsql-database#limit-size","position":43},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"List of Criteria","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#list-of-criteria","position":44},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"List of Criteria","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"You can use lists in your requests too!\n\n# Import layer measurements\nfrom snowexsql.api import LayerMeasurements\n\n# Grab all the data that used the one of these instruments (hint hint SSA)\nssa_instruments = [\"IS3-SP-15-01US\", \"IRIS\",  \"IS3-SP-11-01F\"]\n\n# Query the DB (throw a limit for safety)\nLayerMeasurements.from_filter(instrument=ssa_instruments, limit=100)\n\n","type":"content","url":"/notebooks/snowexsql-database#list-of-criteria","position":45},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Greater than or Less than","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"type":"lvl4","url":"/notebooks/snowexsql-database#greater-than-or-less-than","position":46},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Greater than or Less than","lvl3":"Query Nuances","lvl2":"Forming Queries through the API!"},"content":"Sometimes we want to isolate certain ranges of value or even dates. The greater_equal and less_equal terms can be added on to value or dates.\n\ndate_greater_equal\n\ndate_less_equal\n\nvalue_greater_equal\n\nvalue_less_equal\n\n# Import the point measurements class\nfrom snowexsql.api import PointMeasurements\n\n# Filter values > 100 cm from the pulse ecko GPR\ndf = PointMeasurements.from_filter(value_greater_equal=100, type='depth', instrument='pulse EKKO Pro multi-polarization 1 GHz GPR', limit=100)\n\n# Show off the dataframe\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#greater-than-or-less-than","position":47},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Forming Queries through the API!"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap-1","position":48},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Forming Queries through the API!"},"content":"You just came in contact with the new API tools. We can use each API class to pull from specific tables and filter the data.\nYou should know:\n\nHow to build queries using from_filter, from_area, from_unique_entries\n\nDetermine what values to filter on\n\nManage the limit error\n\nFiltering on greater and less than\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!\n\n","type":"content","url":"/notebooks/snowexsql-database#recap-1","position":49},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl2","url":"/notebooks/snowexsql-database#exercise-visualize-a-manual-depth-spiral","position":50},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"During the SnowEx campaigns a TON of manual snow depths were collected, past surveys for hackweek showed an overhelming interest in the manual\nsnow depths dataset. This tutorial shows how easy it is to get at that data in the database while learning how to build queries\n\nGoal: Visualize a small subset of snow depth, ideally a full spiral (mostly cause they are cool!)\n\nApproach:\n\nDetermine the necessary details for isolating manual depths\n\nFind a pit where many spirals were done.\n\nBuffer on the pit location and grab all manual snow depths\n\n","type":"content","url":"/notebooks/snowexsql-database#exercise-visualize-a-manual-depth-spiral","position":51},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl3","url":"/notebooks/snowexsql-database#process","position":52},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\nfrom snowexsql.api import LayerMeasurements\ndata_type = 'depth'\n\n","type":"content","url":"/notebooks/snowexsql-database#process","position":53},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 1: Find a pit of interest","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-1-find-a-pit-of-interest","position":54},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 1: Find a pit of interest","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# Pick the first one we find\nsite_id = LayerMeasurements().all_site_ids[0]\n\n# Query the database, we only need one point to get a site id and its geometry\nsite_df = LayerMeasurements.from_filter(site_id=site_id, limit=1)\n\n# Print it out \nsite_df\n\n","type":"content","url":"/notebooks/snowexsql-database#step-1-find-a-pit-of-interest","position":55},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 2: Collect Snow Depths","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-2-collect-snow-depths","position":56},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 2: Collect Snow Depths","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# We import the points measurements because snow depths is a single value at single location and date\nfrom snowexsql.api import PointMeasurements \n\n# Filter the results to within 100m within the point from our pit\ndf = PointMeasurements.from_area(pt=site_df.geometry[0], type=data_type, buffer=200)\ndf\n\n","type":"content","url":"/notebooks/snowexsql-database#step-2-collect-snow-depths","position":57},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 3: Plot it!","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl4","url":"/notebooks/snowexsql-database#step-3-plot-it","position":58},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl4":"Step 3: Plot it!","lvl3":"Process","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"\n\n# Get the Matplotlib Axes object from the dataframe object, color the points by snow depth value\nax = df.plot(column='value', legend=True, cmap='PuBu')\nsite_df.plot(ax=ax, marker='^', color='m')\n\n# Use non-scientific notation for x and y ticks\nax.ticklabel_format(style='plain', useOffset=False)\n\n# Set the various plots x/y labels and title.\nax.set_title(f'{len(df.index)} Manual Snow depths collected at {site_id}')\nax.set_xlabel('Easting [m]')\nax.set_ylabel('Northing [m]')\n\n\nTry This:\n\nA. Go back and add a filter to reduce to just one spiral. What would you change to reduce this?\n\nB. Try to filtering to add more spirals. What happens?","type":"content","url":"/notebooks/snowexsql-database#step-3-plot-it","position":59},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"type":"lvl3","url":"/notebooks/snowexsql-database#recap-2","position":60},{"hierarchy":{"lvl1":"SnowExSQL Database","lvl3":"Recap","lvl2":"Exercise: Visualize a Manual Depth Spiral"},"content":"You just plotted snow depths and reduce the scope of the data by using from_area on it\n\nYou should know:\n\nManual depths are neat.\n\nfilter using from area is pretty slick.\n\nWe can use LayerMeasurements to get site details easily.\n\nIf you don’t feel comfortable with these, you are probably not alone, let’s discuss it!","type":"content","url":"/notebooks/snowexsql-database#recap-2","position":61},{"hierarchy":{"lvl1":"Time-lapse Cameras"},"type":"lvl1","url":"/notebooks/timelapse-camera-tutorial","position":0},{"hierarchy":{"lvl1":"Time-lapse Cameras"},"content":"Learning Objectives\n\nAt the conclusion of this tutorial, you will...:\n\nKnow about all the time-lapse images available from the SnowEx 2017 and 2020 field campaigns\n\nView example time-lapse images from SnowEx 2020 and visualize their locations\n\nAccess snow depth measurements extracted from the SnowEx 2020 time-lapse images\n\nCompare snow depths from different SnowEx 2020 time-lapse cameras\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial","position":1},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#time-lapse-cameras-on-grand-mesa-during-snowex-field-campaigns","position":2},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"Time-lapse cameras were installed in both the SnowEx 2017 and 2020 field campaigns on Grand Mesa in similar locations.\n\nSnowEx 2017 Time-lapse Cameras\n\n28 Total Time-lapse Cameras\n\nCapturing the entire winter season (September 2016-June 2017)\n\nTaking 4 photos/day at 8AM, 10AM, 12PM, 2PM, 4PM\n\nAn orange pole was installed in front of 15 cameras for snow depth measurements\n\nTime-lapse images have been submitted to the NSIDC by Mark Raleigh with all the required metadata (e.g., locations, naming convention, etc.) for use.\n\nSnowEx 2020 Time-lapse Cameras\n\n29 Total Time-lapse Cameras\n\nCapturing the entire winter season (September 2019-June 2020)\n\nTaking 3 photos/day at 11AM, 12PM, 1PM or 2 photos/day at 11AM and 12PM\n\nA red pole was installed in front of each camera for snow depth measurements.\n\nCameras were installed on the east and west side of the Grand Mesa, across a vegetation scale of 1-9, using the convention XMR:\n\nX = East (E) or West (W) areas of the Mesa\n\nM = number 1-9, representing 1 (least vegetation) to 9 (most vegetation). Within each vegetation class, there were three sub-classes of snow depths derived from 2017 SnowEx lidar measurements.\n\nR = Replicate of vegetation assignment, either A, B, C, D, or E.\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#time-lapse-cameras-on-grand-mesa-during-snowex-field-campaigns","position":3},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl3","url":"/notebooks/timelapse-camera-tutorial#an-automated-way-of-viewing-and-mapping-time-lapse-photos","position":4},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"\n\nFirst, we will procedurally import the necessary packages to access the data. To access the snow depths at each camera station, we will use the SnowEx database (snowexsql) to access the depths as PointMeasurements.\n\nfrom snowexsql.api import PointMeasurements\n\n# Import information for all point measurement types\nmeasurements = PointMeasurements()\n\n# List unique instruments\nresults = measurements.all_instruments\nprint('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n\n# Packages for data analysis \nimport geopandas as gpd # geopandas library for data analysis and visualization\nimport pandas as pd # pandas as to read csv data and visualize tabular data\nimport numpy as np # numpy for data analysis \n\n# Packages for data visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt # matplotlib.pyplot for plotting images and graphs\n\nplt.rcParams['figure.figsize']  = (10, 4) # figure size\nplt.rcParams['axes.titlesize']  = 14 # title size \nplt.rcParams['axes.labelsize']  = 12 # axes label size \nplt.rcParams['xtick.labelsize'] = 11 # x tick label size \nplt.rcParams['ytick.labelsize'] = 11 # y tick label size \nplt.rcParams['legend.fontsize'] = 11 # legend size \nmpl.rcParams['figure.dpi'] = 100\n\n# Query the database for camera-based snow depths\ncamera_depths = measurements.from_filter(\n    type=\"depth\",\n    site_name=\"Grand Mesa\",\n    instrument=\"camera\",\n    limit = 13371\n)\n\ncamera_depths.head()\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#an-automated-way-of-viewing-and-mapping-time-lapse-photos","position":5},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl4":"Plot the camera locations, using snow pit locations for reference.","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"type":"lvl4","url":"/notebooks/timelapse-camera-tutorial#plot-the-camera-locations-using-snow-pit-locations-for-reference","position":6},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl4":"Plot the camera locations, using snow pit locations for reference.","lvl3":"An automated way of viewing and mapping time-lapse photos","lvl2":"Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns"},"content":"\n\ncamera_depths.explore(tooltip=['equipment','date','latitude','longitude','value','type','units'])\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#plot-the-camera-locations-using-snow-pit-locations-for-reference","position":7},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Viewing the time-lapse photos"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#viewing-the-time-lapse-photos","position":8},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Viewing the time-lapse photos"},"content":"Thanks to the SnowEx database, we were able to easily access snow depths at each site. However, if we wish to examine the camera imagery, we will need to be a bit more creative.\n\nThe images are available through NSIDC, so we will use earthaccess to grab one of the image archives.\n\nEarthdata Login Authentication\n\nThis tutorial requires NASA Earthdata Login credentials to access NSIDC data.\n\nRegister for free if you don’t have an account\n\nOnce you have a username and password, you can either enter these in manually\nin the strategy=\"interactive\" mode (as coded below), or you can configure your\nlocal envrionment as follows:\n\nHere’s how to configure your local system for this to work:\n\nFirst time: Run earthaccess.login() without the strategy parameter to authenticate interactively\n\nThis creates a .netrc file for future sessions\n\nAfter making those changes, you should switch to strategy=\"environment\" below!\n\nimport earthaccess\n\n# Authenticate with Earthdata Login servers\ntry:\n    auth = earthaccess.login(strategy=\"environment\")\n    print(\"✓ Successfully authenticated with Earthdata Login\")\n# Search for camera imagery (only if authenticated)\n    granules = earthaccess.search_data(\n        doi = \"10.5067/WYRNU50R9L5R\"\n    )\n    print(granules[0].data_links())\nexcept Exception as e:\n    print(f\"⚠ Authentication failed: {e}\")\n    print(\"This is expected in automated builds. \\\n           Interactive users should run earthaccess.login() to authenticate.\")\n    granules = None\n\n# Load the files into memory (only if authenticated)\nif granules:\n    files = earthaccess.open(granules)\nelse:\n    print(\"⚠ Skipping remote data access - using local sample data instead\")\n    files = None\n\nLarge Downloads Ahead!\n\nLooking at the above data links, one will notice that the images are saved in .tar.gz format. We can read files through earthaccess in this format, but it will require some more work than simply downloading the data.\n\nUsers may download the files if they wish, but they are on the larger side (900+ Mb). If you wish to avoid large data downloads, then the below code will help with the process. However, be aware that the code can be rather memory intensive. If running this code on CryoCloud, then consider using larger memory allocations (4+ Gb).\n\nHere is how you would read in every file in the large tar.gz from earthaccess into memory:\n\nfile_content = files[0].read()\n\nSimplifying the download for learning purposes\n\nFor the sake of this tutorial we will create a synthetic tar.gz file with just three images we want to show here.\n\nfile_content = 'data/sample-data.tar.gz'\n\n\nimport tarfile\nfrom io import BytesIO\nfrom datetime import datetime\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\njpg_files = []\n# Open the tarfile remotely\nwith tarfile.open(file_content, mode=\"r:gz\") as tar:\n    # Identify contents of tarfile\n    members = tar.getmembers()\n\n    # Loop through tarfile contents for images of interest\n    fig, ax = plt.subplots(1,3, figsize=(12,12))\n    ax.flatten()\n    for member in members:\n        if member.name.lower().endswith('.jpg'):\n            jpg_file = tar.extractfile(member).read()\n            \n            # Estimate datetime from image\n            creationTime = member.mtime\n            dt_c = datetime.fromtimestamp(creationTime)\n            formatted_datetime = dt_c.strftime(\"%m/%d/%Y %H:%M\")\n\n            desired_datetimes = ['09/27/2016 15:13',\n                                 '11/08/2016 14:00',\n                                 '12/10/2016 14:00']\n            \n            # Append files with desired datetime\n            for idx,dt in enumerate(desired_datetimes):\n                if formatted_datetime == dt:\n                    image = Image.open(BytesIO(jpg_file))\n                    ax[idx].imshow(image)\n                    ax[idx].set_title(desired_datetimes[idx])\n                    ax[idx].axis('off')\n\n    plt.tight_layout()\n\n","type":"content","url":"/notebooks/timelapse-camera-tutorial#viewing-the-time-lapse-photos","position":9},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Camera Applications"},"type":"lvl2","url":"/notebooks/timelapse-camera-tutorial#time-lapse-camera-applications","position":10},{"hierarchy":{"lvl1":"Time-lapse Cameras","lvl2":"Time-lapse Camera Applications"},"content":"Installing snow poles in front of time-lapse camera provides low-cost, long-term snow depth timeseries. Snow depths from the 2020 SnowEx time-lapse imagery have been manually processed with estimation of submission to the NSIDC database in summer 2021.\n\nThe snow depth is the difference between the number of pixels in a snow-free image and an image with snow, with a conversion from pixels to centimeters (Figure 1).\n\n\n\nFigure 1: Equation to extract snow depth from camera images. For each image, take the difference in pixels between the length of a snow-free stake and the length of the stake and multiply by length(cm)/pixel. The ratio can be found by dividing the full length of the stake (304.8 cm) by the length of a snow-free stake in pixels.\n\nSnow depth can be obtained in this manner manually, but it is now easier to determine the pixel size of the stakes through machine learning. For the sake of completeness, we will provide a brief example using the camera imagery above. Otherwise, users interested in using the camera imagery with machine learning are encouraged to check out the following resources by Katherine Breen and others:\n\nPublication on methodBreen C. M., W. R. Currier, C. Vuyovich, et al. 2024. “Snow Depth Extraction From Time‐Lapse Imagery Using a Keypoint Deep Learning Model.” Water Resources Research 60 (7): [10.1029/2023wr036682]\n\nGithub page for algorithm\n\nhttps://​github​.com​/catherine​-m​-breen​/snowpoles\n\nIn the example images above, we use the red pole in the fully snow-off and snow-on images for estimation.\n\nFor the snow-off image, the length of the red pole is 136 pixels. If we assume that the pole is 304.8 cm in length, then each pixel is approximately 2.24 cm in length.\n\nFor the snow-on image, the length of the red pole is 72 pixels, much shorter than the snow-off length. So, there is a ~64 pixel difference between the snow-on and snow-off lengths. Using the equation in Figure 1, we can calculate snow depth:\n\nDepth = 2.24 * (136-72) = 143.36 cm\n\nAcknowledgements: Anthony Arendt, Scott Henderson, Micah Johnson, Carrie Vuyovich, Ryan Currier, Megan Mason, Mark Raleigh\n\nAdditional ReferencesDickerson-Lange et al., 2017. Snow disappearance timing is dominated by forest effects on snow accumulation in warm winter climates of the Pacific Northwest, United States. Hydrological Processes. Vol 31, Issue 10. 13 February 2017. \n\nDickerson‐Lange et al. (2017)\n\nRaleigh et al., 2013. Approximating snow surface temperature from standard temperature and humidity data: New possibilities for snow model and remote sensing evaluation. Water Resources Research. Vol 49, Issue 12. 07 November 2013.  \n\nRaleigh et al. (2013)","type":"content","url":"/notebooks/timelapse-camera-tutorial#time-lapse-camera-applications","position":11},{"hierarchy":{"lvl1":"UAVSAR"},"type":"lvl1","url":"/notebooks/uavsar-tutorial","position":0},{"hierarchy":{"lvl1":"UAVSAR"},"content":"\n\nDevelopers: Jack Tarricone, University of Nevada, Reno Zach Keskinen, Boise State University\n\nOther contributors: Ross Palomaki, Montana State UniversityNaheem Adebisi, Boise State University\n\n","type":"content","url":"/notebooks/uavsar-tutorial","position":1},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What is UAVSAR?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-is-uavsar","position":2},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What is UAVSAR?"},"content":"UAVSAR is a low frequency plane-based synthetic aperture radar. UAVSAR stands for “Uninhabited Aerial Vehicle Synthetic Aperture Radar”. It captures imagery using a L-band radar. This low frequency means it can penetrate into and through clouds, vegetation, and snow.\n\nfrequency (cm)\n\nresolution (rng x azi m)\n\nSwath Width (km)\n\nPolarizations\n\nLaunch date\n\nL-band 23\n\n1.8 x 5.5\n\n16\n\nVV, VH, HV, HH\n\n2007","type":"content","url":"/notebooks/uavsar-tutorial#what-is-uavsar","position":3},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"NASA SnowEx 2020 and 2021 UAVSAR Campaigns","lvl3":"What is UAVSAR?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#nasa-snowex-2020-and-2021-uavsar-campaigns","position":4},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"NASA SnowEx 2020 and 2021 UAVSAR Campaigns","lvl3":"What is UAVSAR?"},"content":"During the winter of 2020 and 2021, NASA conducted an L-band InSAR timeseries across the Western US with the goal of tracking changes in SWE. Field teams in 13 different locations in 2020, and in 6 locations in 2021, deployed on the date of the flight to perform calibration and validation observations.\n\nThe site locations from the above map along with the \n\nUAVSAR defined campaign name and currently processed pairs of InSAR images for each site. Note that the image pair count may contain multiple versions of the same image and may increase as more pairs of images are processed by JPL. Also note that the Lowman campaign name is the wrong state when searching.\n\nSite Location\n\nCampaign Name\n\nImage Pairs\n\nGrand Mesa\n\nGrand Mesa, CO\n\n13\n\nBoise River Basin\n\nLowman, CO\n\n17\n\nFrazier Experimental Forest\n\nFraser, CO\n\n16\n\nSenator Beck Basin\n\nIronton, CO\n\n9\n\nEast River\n\nPeeler Peak, CO\n\n4\n\nCameron Pass\n\nRocky Mountains NP, CO\n\n15\n\nReynold Creek\n\nSilver City, ID\n\n1\n\nCentral Agricultral Research Center\n\nUtica, MT\n\n2\n\nLittle Cottonwoody Canyon\n\nSalt Lake City, UT\n\n21\n\nJemez River\n\nLos Alamos, NM\n\n3\n\nAmerican River Basin\n\nEldorado National Forest, CA\n\n4\n\nSagehen Creek\n\nDonner Memorial State Park, CA\n\n4\n\nLakes Basin\n\nSierra National Forest, CA\n\n3\n\n","type":"content","url":"/notebooks/uavsar-tutorial#nasa-snowex-2020-and-2021-uavsar-campaigns","position":5},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Why would I use UAVSAR?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar","position":6},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Why would I use UAVSAR?"},"content":"UAVSAR works with low frequency radar waves. These low frequencies (< 3 GHz) can penetrate clouds and maintain coherence (a measure of radar image quality) over long periods. For these reasons, time series was captured over 13 sites as part of the winter of 2019-2020 and 2020-2021 for snow applications. Additionally the UAVSAR is awesome!\n\n","type":"content","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar","position":7},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Accessing UAVSAR Images"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#accessing-uavsar-images","position":8},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Accessing UAVSAR Images"},"content":"UAVSAR imagery can be downloaded from both the \n\nJPL and \n\nAlaska Satellite Facility. However both provide the imagery in a binary format that is not readily usable or readable by GIS software or python libraries.","type":"content","url":"/notebooks/uavsar-tutorial#accessing-uavsar-images","position":9},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#data-download-and-conversion-with-uavsar-pytools","position":10},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"uavsar_pytools (\n\nGithub) is a Python package developed out of work started at SnowEx Hackweek 2021. It nativiely downloads, formats, and converts this data in analysis ready rasters projected in WSG-84 Lat/Lon (\n\nEPSG:4326. The data traditionally comes in a binary format, which is not injestible by traditional geospatial analysis software (Python, R, QGIS, ArcGIS). It can download and convert either individual images - UavsarScene or entire collections of images - UavsarCollection.","type":"content","url":"/notebooks/uavsar-tutorial#data-download-and-conversion-with-uavsar-pytools","position":11},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Netrc Authorization","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#netrc-authorization","position":12},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Netrc Authorization","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"In order to download uavsar images you will need a \n\nnetrc file that contains your earthdata username and password. If you need to register for a NASA earthdata account use this \n\nlink. A netrc file is a hidden file, it won’t appear in the your file explorer, that is in your home directory and that programs can access to get the appropriate usernames and passwords. While you’ll have already done this for the Hackweek virtual machines, uavsar_pytools has a tool to create this netrc file on a local computer. You only need to create this file once and then it should be permanently stored on your computer.\n\n# ## Creating .netrc file with Earthdata login information\n# from uavsar_pytools.uavsar_tools import create_netrc\n\n# # This will prompt you for your username and password and save this\n# # information into a .netrc file in your home directory. You only need to run\n# # this command once per computer. Then it will be saved.\n# create_netrc()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#netrc-authorization","position":13},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a single UAVSAR interferogram scene","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-single-uavsar-interferogram-scene","position":14},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a single UAVSAR interferogram scene","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"You can find urls for UAVSAR images at the \n\nASF vertex website. Make sure to change the platform to UAVSAR and you may also want to filter to ground projected interferograms.\n\ntry:\n    from uavsar_pytools import UavsarScene\nexcept ModuleNotFoundError:\n    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n\n## This is the directory you want to download and convert the images in.\nwork_dir = '/tmp/uavsar_data'\n\n## This is a url you want to download. Can be obtained from vertex\nurl = 'https://datapool.asf.alaska.edu/INTERFEROMETRY_GRD/UA/\\\nlowman_23205_21009-004_21012-000_0007d_s01_L090_01_int_grd.zip'\n\n## clean = True will delete the binary and zip files leaving only the tiffs\nscene = UavsarScene(url = url, work_dir=work_dir, clean= True)\n\n## After running url_to_tiffs() you will download the zip file, unzip the binary \n## files, and convert them to geotiffs in the directory with the scene name in\n## the work directory. It also generate a .csv pandas dictionary of metadata.\n# scene.url_to_tiffs()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-single-uavsar-interferogram-scene","position":15},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a full UAVSAR collection","lvl3":"Data Download and Conversion with uavsar_pytools"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-full-uavsar-collection","position":16},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Downloading and converting a full UAVSAR collection","lvl3":"Data Download and Conversion with uavsar_pytools"},"content":"If you want to download and convert an entire Uavsar collection for a larger analysis you can use UavsarCollection. The collection names for the SnowEx campaign are listed in the table in the introduction. The UavsarCollection can download either InSAR pairs and PolSAR images.\n\nfrom uavsar_pytools import UavsarCollection\n## Collection name, the SnowEx Collection names are listed above. These are case \n## and space sensitive.\ncollection_name = 'Grand Mesa, CO'\n\n## Directory to save collection into. This will be filled with directory with \n## scene names and tiffs inside of them.\nout_dir = '/tmp/collection_ex/'\n\n## This is optional, but you will generally want to at least limit the date\n## range between 2019 and today.\ndate_range = ('2019-11-01', 'today')\n\n# Keywords: to download incidence angles with each image use `inc = True`\n# For only certain pols use `pols = ['VV','HV']`\n\ncollection = UavsarCollection(collection = collection_name, work_dir = out_dir, dates = date_range)\n\n## You can use this to check how many image pairs have at least one image in\n## the date range.\n\n#collection.find_urls()\n\n## When you are ready to download all the images run:\n\n# collection.collection_to_tiffs()\n\n## This will take a long time and a lot of space, ~1-5 gB and 10 minutes per \n## image pair depending on which scene, so run it if you have the space and time.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#downloading-and-converting-a-full-uavsar-collection","position":17},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"UAVSAR Data Products"},"type":"lvl2","url":"/notebooks/uavsar-tutorial#uavsar-data-products","position":18},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"UAVSAR Data Products"},"content":"UAVSAR has a variety of different type of images:\n\nRepeat Pass Interferometric images contain:\n\nInSAR Data Types\n\nANN file (.ann): a text annotation file with metadata\n\nAMP files (.amp1 and .amp2): amplitude products for flight 1 and flight 2\n\nCOR files (.cor): coherence a measure of the noise level of the phase\n\nINT files (.int): wrapped phase difference between the two images\n\nUNW files (.unw): unwrapped phase difference between the two images\n\nINC files (.inc): incidence angle in radians\n\nHGT file  (.hgt): the DEM that was used in the InSAR processing\n\nUAVSAR repeat pass interferometry uses two images of the same place but separated in time. Phase changes between the two aquistions are calculated,  creating a wrapped interferogram. These phase changes are due to either the wave traveling a longer distance (ground movement or refraction) or change wave speeds (atmospheric water vapor and snow).\n\nGRD files (.grd): products projected to the ground in geographic coordinates (latitude, longitude)\nFinally all images can be in radar slant range or projected into WGS84. Images that have already been projected to ground range will have the extension .grd appended to their file type extension.\n\nFor instance a image of unwrapped phase that has not been georefenced would end with .unw, while one that was georeferenced would end with .unw.grd. You will generally want to use .grd files for most analysis.\n\nPolarimetric PolSAR images contain:\n\nANN file (.ann): a text annotation file with metadata\n\nPolsar file (HHVV.grd): all the rest of the files will be a pair of polarizations pushed together\n\nPolsar files have a pair of polarizations (VV, VH, HV, HH) combined in their file name. These files are the phase difference between polarization XX and polarization YY. For instance HHHV is the phase difference between HH and HV polarizations. HVVV is the phase difference between HV and VV and so one. There are 6 of these pairs since order is irrelevant. These 6 images are combined to calculate various metrics that tell you about the types of scattering occurring.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#uavsar-data-products","position":19},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Import Libraries","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#import-libraries","position":20},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Import Libraries","lvl2":"UAVSAR Data Products"},"content":"\n\ntry:\n    from uavsar_pytools import UavsarScene\n    from uavsar_pytools.snow_depth_inversion import depth_from_phase, phase_from_depth\nexcept ModuleNotFoundError:\n    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n\nimport os\nfrom os.path import join, basename\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport holoviews as hv\nimport rioxarray as rxa\nimport rasterio as rio\nfrom bokeh.plotting import show\nimport datashader as ds\nfrom datashader.mpl_ext import dsshow\nhv.extension('bokeh', logo=False)\nimport earthpy.plot as ep\nimport earthpy.spatial as es\nimport contextily as cx\nfrom datetime import date\nfrom shapely.geometry import box\nimport requests\n%config InlineBackend.figure_format='retina'\n\n# Database imports\nfrom snowexsql.db import get_db\nfrom snowexsql.data import PointData, ImageData, LayerData, SiteData\nfrom snowexsql.conversions import query_to_geopandas\n\nimport warnings\nwarnings.filterwarnings('ignore', category=UserWarning, module='rasterio')\nimport logging\nlogging.getLogger('rasterio._env').setLevel(logging.ERROR)\nlogging.getLogger('rasterio._filepath').setLevel(logging.ERROR)\nos.environ['CPL_CURL_VERBOSE'] = 'NO'\n\n","type":"content","url":"/notebooks/uavsar-tutorial#import-libraries","position":21},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#interferometric-imagery","position":22},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"\n\n","type":"content","url":"/notebooks/uavsar-tutorial#interferometric-imagery","position":23},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Banner Summit","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#banner-summit","position":24},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Banner Summit","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"\n\nIn this section we’ll be plotting and comparing dirrerent types of SAR and InSAR data with optical imagery and a digital elevation model. For this example we’ll be taking a subet of the Lowman flight (Boise, ID) line encompassing Banner Summit.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#banner-summit","position":25},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Access Tutorial Data from S3","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#access-tutorial-data-from-s3","position":26},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Access Tutorial Data from S3","lvl3":"Interferometric Imagery","lvl2":"UAVSAR Data Products"},"content":"The tutorial data is hosted on AWS S3 and can be accessed directly without downloading. The data will be streamed as needed using rioxarray.\n\n# S3 base URL for tutorial data\nS3_BASE_URL = \"https://snowex-uavsar.s3.us-west-2.amazonaws.com/tutorial-data-2022/\"\n\n","type":"content","url":"/notebooks/uavsar-tutorial#access-tutorial-data-from-s3","position":27},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Load in Rasters","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#load-in-rasters","position":28},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Load in Rasters","lvl2":"UAVSAR Data Products"},"content":"Here we’ll load our rasters into the environemtns using rioxarray or rxa, we will then convert to a np.array to be able to use matplotlib.pyplot or plt for plotting\n\n","type":"content","url":"/notebooks/uavsar-tutorial#load-in-rasters","position":29},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Optical Data","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#optical-data","position":30},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Optical Data","lvl2":"UAVSAR Data Products"},"content":"We will be using \n\nHaromized Landsat Sentinel (HLS) dataset from January 13th, 2021. This date was selected because it is mostly cloud free, which is uncommon in mountain environments during the winter.\n\n# Define S3 URLs for the three RGB bands and stack them in memory\nred_path = S3_BASE_URL + 'lowman_red.tif'\ngreen_path = S3_BASE_URL + 'lowman_green.tif'\nblue_path = S3_BASE_URL + 'lowman_blue.tif'\n\n# Load and stack RGB bands directly from S3 (no local files needed)\nimport xarray as xr\nred = rxa.open_rasterio(red_path)\ngreen = rxa.open_rasterio(green_path)\nblue = rxa.open_rasterio(blue_path)\n\n# Stack the bands into a single array\nrgb = xr.concat([red, green, blue], dim='band')\nrgb['band'] = [1, 2, 3]  # Label bands as 1, 2, 3\n\n","type":"content","url":"/notebooks/uavsar-tutorial#optical-data","position":31},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What do we see in this image? Any notable features?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-do-we-see-in-this-image-any-notable-features","position":32},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What do we see in this image? Any notable features?","lvl2":"UAVSAR Data Products"},"content":"\n\n# plot rgb image\nep.plot_rgb(rgb.values,\n            figsize=(15, 15),\n            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n            title = \"HLS Optical 2/18/2021\", \n            stretch=True)\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-do-we-see-in-this-image-any-notable-features","position":33},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"InSAR and SAR Data","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#insar-and-sar-data","position":34},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"InSAR and SAR Data","lvl2":"UAVSAR Data Products"},"content":"Here we’ll be using five different data products related to InSAR and SAR: unwrapped phase (unw), coherence (cor), amplitude (amp), elevation (dem), and incidence angle (inc).\n\n# Open rasters directly from S3 and inspect metadata using xarray\nunw_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_unw.tif')\nunw = unw_rast[0].values # np.array for plotting\n    \n# coherence\ncor_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_cor.tif')\ncor = cor_rast[0].values\n\n# amplitude\namp_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_amb_db.tif')\namp = amp_rast[0].values # np.array for plotting\n\n# dem\ndem_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_dem.tif')\ndem = dem_rast[0].values\n\n# incidence angle\ninc_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_inc_deg.tif')\ninc = inc_rast[0].values # np.array for plotting\n\n# plot unwrapped phase\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"UNW (radians)\", fontsize= 20) #title and font size\nimg = ax.imshow(unw, interpolation = 'nearest', cmap = 'viridis', vmin = -3, vmax = 2)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot coherence\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Coherence\", fontsize= 20) #title and font size\nimg = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot amplitude\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Amplitude (dB)\", fontsize= 20) #title and font size\nimg = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot dem\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Elevation (m)\", fontsize= 20) #title and font size\nimg = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n# plot incidence angle\n\nplt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\nfig, ax = plt.subplots(figsize=(15, 15))\n\nax.set_title(\"Incidence Angle (deg)\", fontsize= 20) #title and font size\nimg = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\n\n# add legend\ncolorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#insar-and-sar-data","position":35},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison Plot","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#comparison-plot","position":36},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison Plot","lvl2":"UAVSAR Data Products"},"content":"\n\n# plot all InSAR products\nfig = plt.figure(figsize=(30,19))\n\nax = fig.add_subplot(1,3,1)\ncax=ax.imshow(unw, cmap='viridis', interpolation = 'nearest', vmin = -3, vmax = 2)\nax.set_title(\"UNW (radians)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[-3,0,2],orientation='horizontal', fraction=0.03, pad=0.04)\ncbar.ax.set_xticklabels([-3,0,2])\n\nax = fig.add_subplot(1,3,2)\ncax = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\nax.set_title(\"Coherence\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[0,.5,1], orientation='horizontal',fraction=0.03, pad=0.04)\n\n\nax = fig.add_subplot(1,3,3)\ncax = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\nax.set_title(\"Amplitude (dB)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[-20,-10,0], orientation='horizontal',fraction=0.03, pad=0.04)\ncbar.ax.set_xticklabels([-20,-10,0])\n\nax = fig.add_subplot(2,3,1)\ncax = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\nax.set_title(\"Incidence Angle (deg)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[20,90], orientation='horizontal', pad=0.07)\ncbar.ax.set_xticklabels([20,90])\n\nax = fig.add_subplot(2,3,2)\ncax = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\nax.set_title(\"Elevation (m)\")\n#ax.set_axis_off()\ncbar = fig.colorbar(cax, ticks=[1800,2800], orientation='horizontal', pad=0.07)\ncbar.ax.set_xticklabels([1800,2800])\n\ndone = None\n\nep.plot_rgb(rgb.values,\n            figsize=(7, 7),\n            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n            title = \"HLS Optical 2/18/2021\", \n            stretch=True)\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#comparison-plot","position":37},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What are some notable similarities between images? Differences?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-are-some-notable-similarities-between-images-differences","position":38},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What are some notable similarities between images? Differences?","lvl2":"UAVSAR Data Products"},"content":"In the next section we’ll go into more detail about the features that impact coherence, phase, and how they’re related\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-are-some-notable-similarities-between-images-differences","position":39},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Sagehen Creek Example","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#sagehen-creek-example","position":40},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Sagehen Creek Example","lvl2":"UAVSAR Data Products"},"content":"\n\n# Load Sagehen Creek data directly from S3\nsage_files = ['cor.tif', 'hgt.tif', 'unw.tif']\nimgs = {}\nfor filename in sage_files:\n    name = filename.split('.')[0]\n    s3_path = S3_BASE_URL + 'sage/' + filename\n    imgs[name] = rxa.open_rasterio(s3_path, parse_coordinates=True, default_name=name)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#sagehen-creek-example","position":41},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What topographic features seem to impact coherence?","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#what-topographic-features-seem-to-impact-coherence","position":42},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"What topographic features seem to impact coherence?","lvl2":"UAVSAR Data Products"},"content":"Take a moment to chat with the people around you about this. Some features to get you thinking:\n\nlakes\n\naspect (south vs north, east vs west)\n\nelevation\n\ntrees\n\nroads\n\nothers?\n\ntiles = hv.element.tiles.EsriUSATopo().opts()\ncor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\nhgt = hv.Image(hv.Dataset(imgs['hgt'], kdims=['x','y'])).opts(cmap = 'terrain', colorbar=True, xaxis = None, yaxis = None, title= 'DEM', alpha = 0.4)\nhgt_trans = hv.Image(hv.Dataset(imgs['hgt'][0,::100,::100], kdims=['x','y'])).opts(alpha = 0, xaxis = None, yaxis = None, title = 'Topo')\ncor_tile = tiles  * cor\nhgt_tile = tiles  * hgt\nimagery = hv.element.tiles.EsriImagery()  * hgt_trans\n\nhv.Layout([cor_tile, hgt_tile, imagery]).opts(width = 400, height = 900)\n\nimport seaborn as sns\nxna = imgs['hgt'].data.ravel()\nyna = imgs['cor'].data.ravel()\nx = xna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\ny = yna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\n\ndf = pd.DataFrame(dict(x=x, y=y))\ndf['x_cat'] = pd.qcut(df.x, q= 6, precision = 0)\nf, ax = plt.subplots(figsize = (12,8))\nsns.violinplot(y = df.y[::100], x = df.x_cat[::100], scale = 'count')\nplt.xlabel('Elevation Bands (m)')\nplt.ylabel('Coherence')\n\n","type":"content","url":"/notebooks/uavsar-tutorial#what-topographic-features-seem-to-impact-coherence","position":43},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"UNW vs. Coherence","lvl2":"UAVSAR Data Products"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#unw-vs-coherence","position":44},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"UNW vs. Coherence","lvl2":"UAVSAR Data Products"},"content":"\n\ntiles = hv.element.tiles.EsriUSATopo().opts()\ncor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\nunw = hv.Image(hv.Dataset(imgs['unw'], kdims=['x','y'])).opts(cmap = 'magma', colorbar=True, xaxis = None, yaxis = None, title= 'Unwrapped Phase', clim = (0, 2*np.pi))\ncor_tile = tiles  * cor\nunw_tile = tiles  * unw\n\nhv.Layout([cor_tile, unw_tile]).opts(width = 400, height = 900)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#unw-vs-coherence","position":45},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl2","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar-for-snow","position":46},{"hierarchy":{"lvl1":"UAVSAR","lvl2":"Why would I use UAVSAR for snow?"},"content":"L-band SAR penetrates through the snowpack. However when it crosses into the snowpack from the air it refracts at an angle, similar to light entering water. This refraction leads to a phase shift relative to an image with no or less snow. Using this difference in phase between two images we can calculate the change in snow height between flights using:\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWhere \\Delta d is the change in snow height, \\Delta \\phi is the phase shift between two SAR images, \\lambda is the radar wavelength, \\alpha is the incidence angle, and \\epsilon_{s} is the dielectric constant of snow which is dependent on the density and liquid water content.\n\n","type":"content","url":"/notebooks/uavsar-tutorial#why-would-i-use-uavsar-for-snow","position":47},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Set variables","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#set-variables","position":48},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Set variables","lvl2":"Why would I use UAVSAR for snow?"},"content":"\n\n# Mesa Lake Snotel Coordinates\nsnotel_coords = (-108.05, 39.05)\n\n","type":"content","url":"/notebooks/uavsar-tutorial#set-variables","position":49},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Phase Change between February 1st and 13th UAVSAR Image Pairs","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#phase-change-between-february-1st-and-13th-uavsar-image-pairs","position":50},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Phase Change between February 1st and 13th UAVSAR Image Pairs","lvl2":"Why would I use UAVSAR for snow?"},"content":"You learned in the first section how to access and download UAVSAR imagery. For this section the data has already been downloaded, converted to GeoTiffs and cropped down to an area of interest that overlaps the main field sites of Grand Mesa. Lets take a look at the coherence and unwrapped phase between these two flights. If you don’t remember what these two represent check out the previous section of this tutorial.\n\n# Create figures and subplots\nfig, axes = plt.subplots(2, 1, figsize = (12,8))\n\n# Select colormap for each image type\nvis_dic = {'cor': 'Blues', 'unw':'magma'}\n\n# Loop through coherence and unwrapped phase images\nfor i, type in enumerate(vis_dic.keys()):\n    # select correct axis\n    ax = axes[i]\n    # open image directly from S3 with rioxarray\n    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n    # calculate visualization parameters\n    vmin, vmax = img.quantile([0.1,0.9])\n    # plot images\n    img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n    # zoom out a bit\n    ax.set_xlim(-108.28,-108)\n    ax.set_ylim(38.98, 39.08)\n    # add topo basemap\n    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n    # turn off labels\n    ax.xaxis.label.set_visible(False)\n    ax.yaxis.label.set_visible(False)\n# set titles\naxes[0].set_title('Coherence')\naxes[1].set_title('Unwrapped Phase Change')\n\nplt.show()\n\nfig, ax = plt.subplots(figsize = (12,8))\n\n# Plot the snotel location\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n\n# Plot bounding box of uavsar - stream from S3\nuavsar_bounds = rxa.open_rasterio(S3_BASE_URL + 'cor.tif').rio.bounds()\nx,y = box(*uavsar_bounds).exterior.xy\nax.plot(x,y, color = 'blue')\n\n# Set overview bounds\nax.set_xlim(-108.4,-107.75)\nax.set_ylim(38.75, 39.3)\n\n# Add background map\ncx.add_basemap(ax, crs='EPSG:4326', alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\nplt.title('Overview Map')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#phase-change-between-february-1st-and-13th-uavsar-image-pairs","position":51},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Using the SnowEx SQL Database to collect snow depth and lidar datasets","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#using-the-snowex-sql-database-to-collect-snow-depth-and-lidar-datasets","position":52},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Using the SnowEx SQL Database to collect snow depth and lidar datasets","lvl2":"Why would I use UAVSAR for snow?"},"content":"Lets explore how many overlapping depth observations we have between these two days.\n\n# This is what you will use for all of hackweek to access the db\ndb_name = 'snow:hackweek@db.snowexdata.org/snowex'\n\n# Using the function get_db, we receive 2 ways to interact with the database\nengine, session = get_db(db_name)\n\n# Its convenient to store a query like the following \nqry = session.query(PointData)\n\n# Filter to snow depths\nqry = qry.filter(PointData.type == 'depth')\nqry = qry.filter(PointData.site_name == 'Grand Mesa')\nqry = qry.filter(PointData.instrument != 'Mala 800 MHz GPR')\n\n# Then filter on it first date. We are gonna get one day either side of our flight date\nqry_feb1 = qry.filter(PointData.date >= date(2020, 1, 31))\nqry_feb1 = qry_feb1.filter(PointData.date <= date(2020, 2, 2))\ndf_feb_1 = query_to_geopandas(qry_feb1, engine)\n\n# Get depths from second flight date\nqry_feb12 = qry.filter(PointData.date >= date(2020, 2, 11))\nqry_feb12 = qry_feb12.filter(PointData.date <= date(2020, 2, 13))\ndf_feb_12 = query_to_geopandas(qry_feb12, engine)\n\n# Get depths that were captured on both days\ndf_both = df_feb_1.overlay(df_feb_12, how = 'intersection')\n\n# Convert crs to match our uavsar images\ndf_both = df_both.to_crs(epsg = 4326)\n\n# Calculate the snow depth change for each point\ndf_both['sd_diff'] = df_both.value_2 - df_both.value_1\n\nfig, ax = plt.subplots(figsize = (12,4))\n\n# Plot depth measurements\ndf_both.plot(ax = ax, column = 'sd_diff', legend = True, legend_kwds = {'label': 'Snow Depth Change [cm]'}, cmap = 'magma')\n\n# Plot the snotel location\nsnotel_coords = (-108.05, 39.05)\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n\n# Plot bounding box of uavsar - stream from S3\nimg = rxa.open_rasterio(S3_BASE_URL + 'cor.tif')\nuavsar_bounds = img.rio.bounds()\nx,y = box(*uavsar_bounds).exterior.xy\nax.plot(x,y, color = 'blue')\n\n# Set same bounds as uavsar image plot\nax.set_xlim(-108.28,-108)\nax.set_ylim(38.98, 39.08)\n\n# Add background map\ncx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\nplt.title('Database Snow Depth Measurements')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#using-the-snowex-sql-database-to-collect-snow-depth-and-lidar-datasets","position":53},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#getting-the-remaining-parameters","position":54},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"","type":"content","url":"/notebooks/uavsar-tutorial#getting-the-remaining-parameters","position":55},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Incidence Angle","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#incidence-angle","position":56},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Incidence Angle","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"We can recall the formula to calculate snow depth change from incidence angle, phase change, and the snow permittivity.\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWe have two of these variables already: incidence angle and phase change.\n\n# Create figures and subplots\nfig, axes = plt.subplots(2, 1, figsize = (12,8))\n\n# Select colormap for each image type\nvis_dic = {'inc': 'Greys', 'unw':'magma'}\n\n# Loop through each image type\nfor i, type in enumerate(vis_dic.keys()):\n    ax = axes[i]\n    # Open image directly from S3 with rioxarray\n    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n    # convert incidence angle from radians to degrees\n    if type == 'inc':\n        img = np.rad2deg(img)\n    # this is a great convenience feature to calculate good visualization levels\n    vmin, vmax = img.quantile([0.1,0.9])\n    # plot the image\n    im = img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n    # Zoom out a big\n    ax.set_xlim(-108.28,-108)\n    ax.set_ylim(38.98, 39.08)\n    # Add a topo basemap\n    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n    # Remove unnecessary 'x' 'y' labels\n    ax.xaxis.label.set_visible(False)\n    ax.yaxis.label.set_visible(False)\n\n# Add titles\naxes[0].set_title('Incidence Angle')\naxes[1].set_title('Unwrapped Phase Change')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#incidence-angle","position":57},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Getting Permittivity","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl4","url":"/notebooks/uavsar-tutorial#getting-permittivity","position":58},{"hierarchy":{"lvl1":"UAVSAR","lvl4":"Getting Permittivity","lvl3":"Getting the remaining parameters","lvl2":"Why would I use UAVSAR for snow?"},"content":"We have two ways of getting the e_{s}, or the real part of the snow’s dielectric permittivity. One is by estimating from the snow density. For dry snow we can estimate the permittivity using the density. There are a number of equations for calculating this value, but we will use the equation from \n\nGuneriussen et al. 2001:e_{s} = 1 + 0.0016 \\rho + 1.8 1\\mathrm{e}{-9} \\rho^{3}\n\nwhere e_{s} is the real part of the snow’s dielectric permittivity and \\rho is the density of the new snow accumulated between the two images in \\frac{kg}{m^{3}}.\n\nThe other method is to use the directly measured values for permittivity from the field and averaging the top layer.\n\n# Its convenient to store a query like the following \nqry = session.query(LayerData)\n\n# Then filter on it first date. We are gonna get one day either side of second flight date\nqry = qry.filter(LayerData.date >= date(2020, 1, 31))\nqry = qry.filter(LayerData.date <= date(2020, 2, 2))\nqry = qry.filter(LayerData.site_name == 'Grand Mesa')\n# Filter to snow density\nqry_p = qry.filter(LayerData.type == 'density')\n# Change the qry to a geopandas dataframe\ndf = query_to_geopandas(qry_p, engine)\n# create a list to hold the density values\np_values = []\n# Loop through each snowpit (each unique site-id is a snowpit) \nfor id in np.unique(df.site_id):\n    sub = df[df.site_id == id]\n    # get the density for the top layer identified in each snowpit\n    p = float(sub.sort_values(by = 'depth', ascending = False).iloc[0]['value'])\n    # add it our list\n    p_values.append(p)\n# calculate the mean density of the top layer for each snowpit\nmean_new_density = np.nanmean(p_values)\n# Use our equation above to estimate our new snow permittivity\nes_estimate = 1 + 0.0016*mean_new_density + 1.8e-09*mean_new_density**3\n\n## We can also use snowpits where permittivity was directly observed to compare to\n# our density estimates\nqry = qry.filter(LayerData.type == 'permittivity')\ndf = query_to_geopandas(qry, engine)\nes_values = []\nfor id in np.unique(df.site_id):\n    sub = df[df.site_id == id]\n    es_str = sub.sort_values(by = 'depth', ascending = False).iloc[0]['value']\n    if es_str != None:\n        es = float(es_str)\n        if es != None:\n            es_values.append(es)\nes_measured = np.nanmean(es_values)\n\nprint(f'New snow measured permittivity: {es_measured}. Permittivity from density: {es_estimate}')\n\n","type":"content","url":"/notebooks/uavsar-tutorial#getting-permittivity","position":59},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Now we have a new snow permittivity (either from density or directly measured) and we can use that along with our unwrapped phase to calculate the Uavsar snow depth change.","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#now-we-have-a-new-snow-permittivity-either-from-density-or-directly-measured-and-we-can-use-that-along-with-our-unwrapped-phase-to-calculate-the-uavsar-snow-depth-change","position":60},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Now we have a new snow permittivity (either from density or directly measured) and we can use that along with our unwrapped phase to calculate the Uavsar snow depth change.","lvl2":"Why would I use UAVSAR for snow?"},"content":"Take a moment to code up the formula for snow depth change from phase and incidence angle:\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n\nWhere \\Delta d is the change in snow height, \\Delta \\phi is the phase shift between two SAR images, \\lambda is the radar wavelength, \\alpha is the incidence angle, and \\epsilon_{s} is the dielectric constant of snow which is dependent on the density and liquid water content.\n\n# Open rasters directly from S3 (unwrapped phase and incidence angle)\nunw = rxa.open_rasterio(S3_BASE_URL + 'unw.tif')\ninc = rxa.open_rasterio(S3_BASE_URL + 'inc.tif')\n\n# This uses the pytool's function to directly give you snow depth change\n# feel free to rerun with this to check your results\n# https://github.com/SnowEx/uavsar_pytools/blob/main/uavsar_pytools/snow_depth_inversion.py\nsd_change = depth_from_phase(unw, inc, density = mean_new_density)\n\n# convert to centimeters from meters\nsd_change = sd_change*100\n\n# Now we can plot the results!\nf, ax = plt.subplots(figsize = (12,8))\n\n# Plot our uavsar snow depth change\nsd_change.plot(ax = ax, cmap = 'Blues', vmin = -10, vmax = 10)\n# plot black shadow for field observations\ndf_both.plot(ax = ax, color = 'black', markersize = 90)\n# plot field observed snow depth difference\ndf_both.plot(ax = ax, column = 'sd_diff', legend = True, cmap = 'Blues', vmin = -10, vmax = 10)\n# add snotel coordinates\nax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n# turn off labels\nax.xaxis.label.set_visible(False)\nax.yaxis.label.set_visible(False)\n# set title\nax.set_title('Uavsar Snow Depth Inversion vs Field Observations')\n\n## Uncomment this to zoom in on the measured results\n# ax.set_xlim(-108.14, -108.23)\n# ax.set_ylim(39, 39.05)\n\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#now-we-have-a-new-snow-permittivity-either-from-density-or-directly-measured-and-we-can-use-that-along-with-our-unwrapped-phase-to-calculate-the-uavsar-snow-depth-change","position":61},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Numerical Comparison","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#numerical-comparison","position":62},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Numerical Comparison","lvl2":"Why would I use UAVSAR for snow?"},"content":"We can now extract the snow depth change at each measured point and compare them\nto the pit values of snow depth change.\n\n# Sample UAVSAR snow depth change at field measurement points (in memory, no file I/O)\ncoord_list = [(x, y) for x, y in zip(df_both['geometry'].x, df_both['geometry'].y)]\n\n# Use rioxarray to sample values directly from the in-memory array\nfrom rasterio.transform import rowcol\ndf_both['uavsar_sd'] = [\n    float(sd_change.sel(x=x, y=y, method='nearest').values) \n    for x, y in coord_list\n]\n\nf, ax = plt.subplots(figsize = (12,8))\ndf_both['geometry-str'] = df_both['geometry'].astype(str)\ndf_dis = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'mean', 'uavsar_sd': 'mean'})\nfield_sd_std = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'std'})['sd_diff'].values\nax.errorbar(x = df_dis.uavsar_sd, y = df_dis.sd_diff, yerr = field_sd_std, fmt=\"o\")\n\nlims = [\n    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n]\ndef rmse(predictions, targets):\n    return np.sqrt(((predictions - targets) ** 2).mean())\nrmse_sd = rmse(df_both['sd_diff'], df_both['uavsar_sd'])\nprint(f'RMSE between uavsar and field observations is {rmse_sd} cm')\n\n# now plot both limits against each other\nax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\nax.set_xlabel('Uavsar Snow Depth Change')\nax.set_ylabel('Field Measured Snow Depth Change')\nplt.show()\n\n","type":"content","url":"/notebooks/uavsar-tutorial#numerical-comparison","position":63},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison to Lidar","lvl2":"Why would I use UAVSAR for snow?"},"type":"lvl3","url":"/notebooks/uavsar-tutorial#comparison-to-lidar","position":64},{"hierarchy":{"lvl1":"UAVSAR","lvl3":"Comparison to Lidar","lvl2":"Why would I use UAVSAR for snow?"},"content":"\n\n# Create figures and subplots\nfig, axes = plt.subplots(3, 1, figsize = (12,8))\n\n# Load lidar data from S3\nlidar = rxa.open_rasterio(S3_BASE_URL + 'sd_lidar.tif')\n\ndiff = lidar.copy()\ndiff = diff - sd_change\n\nvmin, vmax = sd_change.quantile([0.1,0.9])\nsd_change_masked = sd_change.copy()\nsd_change_masked.data[np.isnan(lidar).data] = np.nan\nsd_change_masked.plot(ax = axes[0], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\nlidar.plot(ax = axes[1], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\ndiff.plot(ax = axes[2], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\n\nfor ax in axes:\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n\naxes[0].set_title('Uavsar Snow Depth Change')\naxes[1].set_title('Lidar Snow Depth Change')\naxes[2].set_title('Snow Depth Difference')\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize = (12,8))\ndiffs = diff.values.ravel()\ndiffs = diffs[diffs < 100]\ndiffs = diffs[diffs > -100]\nplt.hist(diffs, bins = 100, density = True, label = 'Uavsar sd change')\n# plt.axvline(sd_change_masked.mean().values, label = 'Uavsar Mean Snow Depth Change', color = 'green')\nlidar_vals = lidar.astype(np.float64).values[~lidar.isnull().values]\nlidar_vals = lidar_vals[lidar_vals < 100]\nlidar_vals = lidar_vals[lidar_vals > -100]\nmean_lidar = np.nanmean(lidar_vals)\nplt.axvline(mean_lidar, color = 'red', linewidth = 5, label = 'mean lidar sd change')\n# plt.axvline(mean_lidar, label = 'Lidar Mean Snow Depth Change', color = 'red')\nrmse = np.sqrt(((diffs) ** 2).mean())\nprint(f'Lidar mean depth change: {sd_change_masked.mean().values} cm, uavsar mean depth change: {mean_lidar} cm')\nprint(f'Mean difference: {np.nanmean(diffs)} cm, rmse = {rmse} cm')\nplt.legend(loc = 'lower left')\nplt.xlabel('Snow Depth Change (cm)')\nplt.show()","type":"content","url":"/notebooks/uavsar-tutorial#comparison-to-lidar","position":65}]}