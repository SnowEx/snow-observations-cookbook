{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnowExSQL Database \n",
    "\n",
    " \n",
    "__Tutorial Author Micah'__: [Micah Sandusky](https://github.com/micah-prime)\n",
    "\n",
    "__Tutorial Author Micah_o__: [Micah Johnson](https://github.com/micahjohnson150)\n",
    "\n",
    "[SnowEx](https://snow.nasa.gov/campaigns/snowex) has introduced a unique opportunity to study SWE in a way that's unprecedented, but with more data comes new challenges. \n",
    "\n",
    "![examples](./images/snowex_database/data_examples.png)\n",
    "\n",
    "\n",
    "<!-- \n",
    "<img src=\"https://snowexsql.readthedocs.io/en/latest/_images/gallery_overview_example_12_0.png\" alt=\"Grand Mesa Overview\" width=\"1000px\"> -->\n",
    "\n",
    "**The SnowEx database is a resource that shortcuts the time it takes to ask cross dataset questions**\n",
    "\n",
    "      \n",
    "- Standardizing diverse data\n",
    "- Cross referencing data\n",
    "- Provenance!\n",
    "- Added GIS functionality\n",
    "- Connect w/ ArcGIS or QGIS!\n",
    "- **CITABLE** \n",
    "\n",
    "    * [*2022- Estimating snow accumulation and ablation with L-band interferometric synthetic aperture radar (InSAR)*](https://tc.copernicus.org/articles/17/1997/2023/tc-17-1997-2023-discussion.html)\n",
    "    * [*2024 - Thermal infrared shadow-hiding in GOES-R ABI imagery: snow and forest temperature observations from the SnowEx 2020 Grand Mesa field campaign*](https://tc.copernicus.org/articles/18/2257/2024/)\n",
    "      \n",
    "      \n",
    "\n",
    "## What's in it?\n",
    "\n",
    "* Snow pits - Density, hardness profiles, grain types + sizes\n",
    "* Manual snow depths - TONS of depths (Can you say spirals?)\n",
    "* Snow Micropenetrometer (SMP) profiles - (Subsampled to every 100th)\n",
    "* Snow depth + SWE rasters from ASO Inc.\n",
    "* GPR\n",
    "* Pit site notes\n",
    "* Camera Derived snow depths\n",
    "* Snow off DEM from USGS 3DEP \n",
    "* And almost all the associated metadata\n",
    "\n",
    "## Technically, what is it?\n",
    "\n",
    "* PostgreSQL database\n",
    "* PostGIS extension\n",
    "* Supports vector and raster data\n",
    "* And a host of GIS operations\n",
    "* AND NOW WITH API!\n",
    "\n",
    "\n",
    "### So what's the catch?\n",
    "New tech can create barriers...\n",
    "\n",
    "```{figure} ./images/snowex_database/pits_not_bits.jpg\n",
    ":scale: 20 %\n",
    ":alt: pits not bits\n",
    "```\n",
    "\n",
    "### TL;DR Do less wrangling, do more crunching. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I get at this magical box of data ?\n",
    "* [SQL](https://www.postgresql.org/docs/13/tutorial-sql.html) \n",
    "* [snowexsql](https://github.com/SnowEx/snowexsql/) <span style=\"font-size:20pt;\"> **&#8592; ðŸ˜Ž**</span>\n",
    "\n",
    "\n",
    "### Welcome to API Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.api import PointMeasurements\n",
    "\n",
    "df = PointMeasurements.from_filter(type=\"depth\", instrument='pit ruler', limit=100)\n",
    "df.plot(column='value', cmap='jet', vmin=10, vmax=150)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Ways / Advanced Users \n",
    "Advanced queries can be made using SQL or SQAlchemy under the hood. \n",
    "\n",
    "See previous presentations\n",
    "\n",
    "Engine objects, session objects, and a crash course in ORM, oh my! \n",
    "* [Hackweek 2021](https://snowex-2021.hackweek.io/tutorials/database/index.html)\n",
    "* [Hackweek 2022](https://snowex-2022.hackweek.io/tutorials/database/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d563d3c",
   "metadata": {},
   "source": [
    "# How is the Database Structured?\n",
    "\n",
    "The goal of the database is to hold as much of the SnowEx data in one place and make it easier to \n",
    "do research with. With that in mind follow the steps below to see how the the data base is structured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0a9c7",
   "metadata": {},
   "source": [
    "## Where do datasets live (i.e. tables)?\n",
    "\n",
    "Data in the database lives in 1 of 4 places. \n",
    "\n",
    "\n",
    "```{figure} ./images/snowex_database/structure.png\n",
    ":scale: 50 %\n",
    ":alt: Structure of the snowex db\n",
    "\n",
    "Layout of the database tables\n",
    "\n",
    "```\n",
    "\n",
    "The 4th table is a table detailing the site information. Lots and lots of metadata for which the API has not been written yet.\n",
    "\n",
    "So how does this look in python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979fad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.api import PointMeasurements, LayerMeasurements, RasterMeasurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf71eb",
   "metadata": {},
   "source": [
    "## How are tables structured?\n",
    "Each table consists of rows and columns. Below are the available columns!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class reflecting the points table in the db\n",
    "from snowexsql.api import PointMeasurements as measurements\n",
    "\n",
    "# Grab one measurement to see what attributes are available\n",
    "df = measurements.from_filter(type=\"depth\", limit=1)\n",
    "\n",
    "# Print out the results nicely\n",
    "print(\"These are the available columns in the table:\\n \\n* {}\\n\".format('\\n* '.join(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2df485",
   "metadata": {},
   "source": [
    "**Try this:** Using what we just did, but swap out PointMeasurements for LayerMeasurements.\n",
    "\n",
    "\n",
    "**Question:** Did you collect any data? What is it? What table do you think it would go in?\n",
    "\n",
    "For more detail, checkout the readthedocs page on [database structure](https://snowexsql.readthedocs.io/en/latest/database_structure.html) to see how data gets categorized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d106e6e",
   "metadata": {},
   "source": [
    "## Bonus Step: Learning to help yourself\n",
    "[snowexsql](https://github.com/SnowEx/snowexsql/) has a host of resources for you to  help your self. First when you are looking for something be sure to check the snowexsql's docs.\n",
    "There you will find notes on the database structure. datasets, and of course our new API! \n",
    "\n",
    "### Database Usage/Examples\n",
    "* [snowexsql Code](https://github.com/SnowEx/snowexsql/) \n",
    "* [snowexsql Documentation](https://snowexsql.readthedocs.io/en/latest/) \n",
    "\n",
    "### Database Building/Notes\n",
    "* [snowex_db Code](https://github.com/SnowEx/snowex_db/) \n",
    "* [snowex_db Documentation](https://snowex_db.readthedocs.io/en/latest/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9ae13",
   "metadata": {},
   "source": [
    "## Recap \n",
    "You just explored the database structure and discussed how they differ.\n",
    "\n",
    "**You should know:**\n",
    "* Which table a dataset might live in\n",
    "* What columns you can work with (or how to get the available columns)\n",
    "* Some resources to begin helping yourself.\n",
    "\n",
    "If you don't feel comfortable with these, you are probably not alone, let's discuss it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forming Queries through the API!\n",
    "\n",
    "Get familiar with the tools available for querying the database. The simplest way is to use the api classes \n",
    "* [`snowexsql.api.PointMeasurements`](https://github.com/SnowEx/snowexsql/blob/830fa76de8cf13c5101e1b4b663c1b399f81d7e6/snowexsql/api.py#L185)\n",
    "* [`snowexsql.api.LayerMeasurements`](https://github.com/SnowEx/snowexsql/blob/830fa76de8cf13c5101e1b4b663c1b399f81d7e6/snowexsql/api.py#L262)\n",
    "\n",
    "* Each class has to very useful functions\n",
    "  1. [`from_filter`](https://github.com/SnowEx/snowexsql/blob/830fa76de8cf13c5101e1b4b663c1b399f81d7e6/snowexsql/api.py#L192)\n",
    "  2. [`from_area`](https://github.com/SnowEx/snowexsql/blob/830fa76de8cf13c5101e1b4b663c1b399f81d7e6/snowexsql/api.py#L210)\n",
    "\n",
    "## Useful Function - `from_filter`\n",
    "\n",
    "Use the from filter function to find density profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import in our two classes to access the db\n",
    "from snowexsql.api import LayerMeasurements\n",
    "from datetime import datetime \n",
    "\n",
    "# Find some density pit measurements at the Boise site in december 2019.\n",
    "df = LayerMeasurements.from_filter(\n",
    "    type=\"density\",\n",
    "    site_name=\"Boise River Basin\",\n",
    "    date_less_equal=datetime(2020, 1, 1),\n",
    "    date_greater_equal=datetime(2019, 12, 1),\n",
    ")\n",
    "\n",
    "# Plot Example!\n",
    "df.plot()\n",
    "\n",
    "# Show off the dataframe\n",
    "df\n",
    "\n",
    "# Analysis Example - Find the bulk density \n",
    "df['value'] = df['value'].astype(float)\n",
    "print(df[['site_id', 'value']].groupby(by='site_id').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Function - `from_area`\n",
    "Find specific surface area within a certain distance of a pit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our api class\n",
    "from snowexsql.api import LayerMeasurements\n",
    "from datetime import datetime\n",
    "import geopandas as gpd \n",
    "\n",
    "# import some gis functionality \n",
    "from shapely.geometry import Point \n",
    "\n",
    "# Find some SSA measurements within a distance of a known point\n",
    "pnt = Point(740820.624625,4.327326e+06)\n",
    "df = LayerMeasurements.from_area(pt=pnt, crs=26912, buffer=500,\n",
    "    type='specific_surface_area')\n",
    "\n",
    "# plot up the results\n",
    "ax = df.plot()\n",
    "\n",
    "# plot the site so we can see how close everything is.\n",
    "site = gpd.GeoDataFrame(geometry=[pnt], crs=26912)\n",
    "site.plot(ax=ax, marker='^', color='magenta')\n",
    "\n",
    "# show off the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I know what to filter on?\n",
    "We got tools for that! Each class has a host of functions that start with `all_*` these function return the unique value in that column. \n",
    "\n",
    " * `all_types` - all the data types e.g. depth, swe, density...\n",
    " * `all_instruments` - all instruments available in the table\n",
    " * `all_dates` - all dates listed in the table\n",
    " * `all_site_names` - all the site names available in the table. e.g. Grand Mesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.api import PointMeasurements\n",
    "\n",
    "# Instantiate the class to use the properties!\n",
    "measurements = PointMeasurements()\n",
    "\n",
    "# Get the unique data names/types in the table\n",
    "results = measurements.all_types\n",
    "print('Available types = {}'.format(', '.join([str(r) for r in results])))\n",
    "\n",
    "# Get the unique instrument in the table\n",
    "results = measurements.all_instruments\n",
    "print('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))\n",
    "\n",
    "# Get the unique dates in the table\n",
    "results = measurements.all_dates\n",
    "print('\\nAvailable Dates = {}'.format(', '.join([str(r) for r in results])))\n",
    "\n",
    "# Get the unique site names in the table\n",
    "results = measurements.all_site_names\n",
    "print('\\nAvailable sites = {}'.format(', '.join([str(r) for r in results])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More specific filtering options\n",
    "Sometimes we need a bit more filtering to know more about what I can filter on. Questions like \"What dates was the SMP used?\" are a bit more complicated than \"Give me all the dates for snowex\"\n",
    "\n",
    "The good news is, we have tool for that! `from_unique_entries` is your friend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import layer measurements\n",
    "from snowexsql.api import LayerMeasurements\n",
    "\n",
    "# Query dates where SMP was used\n",
    "LayerMeasurements.from_unique_entries(['date'], instrument='snowmicropen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Nuances\n",
    "### Limit size \n",
    "To avoid accidental large queries, we have added some bumper rails. By default if you ask for more than 1000 records then an error will pop up unless you explicitly say you want more. \n",
    "\n",
    "**Try This**: Do a large query. Run the code block below without the limit keyword argument (\"kwarg\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PointMeasurements\n",
    "from snowexsql.api import PointMeasurements\n",
    "\n",
    "# Query db using a vague filter or on a huge dataset like GPR but remove the limit kwarg\n",
    "df = PointMeasurements.from_filter(type='two_way_travel', limit=100)\n",
    "\n",
    "# Show the dataframe\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have added this on the db to allow you to explore without accidentally pulling the entire SnowEx universe down. If you know you want a large query (defined as > 1000) then use the `limit = ####` option in the `from_filter` or `from_area` function.\n",
    "\n",
    "**Warning** - It is better to filter using other things besides the limit because the limit is not intelligent. It will simply limit the query by the order of entries that were submitted AND fits your filter. So if you encounter this then consider how to tighten up the filter.\n",
    "\n",
    "### List of Criteria\n",
    "You can use lists in your requests too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import layer measurements\n",
    "from snowexsql.api import LayerMeasurements\n",
    "\n",
    "# Grab all the data that used the one of these instruments (hint hint SSA)\n",
    "ssa_instruments = [\"IS3-SP-15-01US\", \"IRIS\",  \"IS3-SP-11-01F\"]\n",
    "\n",
    "# Query the DB (throw a limit for safety)\n",
    "LayerMeasurements.from_filter(instrument=ssa_instruments, limit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greater than or Less than\n",
    "Sometimes we want to isolate certain ranges of value or even dates. The `greater_equal` and `less_equal` terms can be added on to `value` or `dates`. \n",
    "\n",
    "* `date_greater_equal`\n",
    "* `date_less_equal`\n",
    "* `value_greater_equal`\n",
    "* `value_less_equal`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the point measurements class\n",
    "from snowexsql.api import PointMeasurements\n",
    "\n",
    "# Filter values > 100 cm from the pulse ecko GPR\n",
    "df = PointMeasurements.from_filter(value_greater_equal=100, type='depth', instrument='pulse EKKO Pro multi-polarization 1 GHz GPR', limit=100)\n",
    "\n",
    "# Show off the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap \n",
    "You just came in contact with the new API tools. We can use each API class to pull from specific tables and filter the data. \n",
    "**You should know:**\n",
    "* How to build queries using `from_filter`, `from_area`, `from_unique_entries`\n",
    "* Determine what values to filter on\n",
    "* Manage the limit error\n",
    "* Filtering on greater and less than\n",
    "  \n",
    "If you don't feel comfortable with these, you are probably not alone, let's discuss it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Visualize a Manual Depth Spiral\n",
    "\n",
    "During the SnowEx campaigns a TON of manual snow depths were collected, past surveys for hackweek showed an overhelming interest in the manual \n",
    "snow depths dataset. This tutorial shows how easy it is to get at that data in the database while learning how to build queries\n",
    "\n",
    "**Goal**: Visualize a small subset of snow depth, ideally a full spiral (mostly cause they are cool!)\n",
    "\n",
    "**Approach**: \n",
    "1. Determine the necessary details for isolating manual depths\n",
    "2. Find a pit where many spirals were done. \n",
    "3. Buffer on the pit location and grab all manual snow depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.api import LayerMeasurements\n",
    "data_type = 'depth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find a pit of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first one we find\n",
    "site_id = LayerMeasurements().all_site_ids[0]\n",
    "\n",
    "# Query the database, we only need one point to get a site id and its geometry\n",
    "site_df = LayerMeasurements.from_filter(site_id=site_id, limit=1)\n",
    "\n",
    "# Print it out \n",
    "site_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Collect Snow Depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the points measurements because snow depths is a single value at single location and date\n",
    "from snowexsql.api import PointMeasurements \n",
    "\n",
    "# Filter the results to within 100m within the point from our pit\n",
    "df = PointMeasurements.from_area(pt=site_df.geometry[0], type=data_type, buffer=200)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-gallery",
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the Matplotlib Axes object from the dataframe object, color the points by snow depth value\n",
    "ax = df.plot(column='value', legend=True, cmap='PuBu')\n",
    "site_df.plot(ax=ax, marker='^', color='m')\n",
    "\n",
    "# Use non-scientific notation for x and y ticks\n",
    "ax.ticklabel_format(style='plain', useOffset=False)\n",
    "\n",
    "# Set the various plots x/y labels and title.\n",
    "ax.set_title(f'{len(df.index)} Manual Snow depths collected at {site_id}')\n",
    "ax.set_xlabel('Easting [m]')\n",
    "ax.set_ylabel('Northing [m]');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try This:**\n",
    "\n",
    "A. Go back and add a filter to reduce to just one spiral. What would you change to reduce this?\n",
    "\n",
    "B. Try to filtering to add more spirals. What happens?\n",
    "\n",
    "\n",
    "## Recap \n",
    "You just plotted snow depths and reduce the scope of the data by using `from_area` on it\n",
    "\n",
    "**You should know:**\n",
    "\n",
    "* Manual depths are neat.\n",
    "* filter using from area is pretty slick.\n",
    "* We can use LayerMeasurements to get site details easily. \n",
    "\n",
    "\n",
    "If you don't feel comfortable with these, you are probably not alone, let's discuss it!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-observations-cookbook-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
