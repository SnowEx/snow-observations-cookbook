{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAVSAR\n",
    "\n",
    "<img src=\"./images/uavsar/sthelens.jpeg\" width=\"50%\">\n",
    "\n",
    "*Developers: \\\n",
    "Jack Tarricone, University of Nevada, Reno \\\n",
    "Zach Keskinen, Boise State University*\n",
    "\n",
    "*Other contributors: \\\n",
    "Ross Palomaki, Montana State University\\\n",
    "Naheem Adebisi, Boise State University*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is UAVSAR?\n",
    "\n",
    "[UAVSAR](https://uavsar.jpl.nasa.gov/education/what-is-uavsar.html) is a low frequency plane-based synthetic aperture radar. UAVSAR stands for \"Uninhabited Aerial Vehicle Synthetic Aperture Radar\". It captures imagery using a L-band radar. This low frequency means it can penetrate into and through clouds, vegetation, and snow.\n",
    "\n",
    "| frequency (cm) | resolution (rng x azi m) | Swath Width (km) | Polarizations | Launch date |\n",
    "| - | - | - | - | - |\n",
    "| L-band 23| 1.8 x 5.5 | 16 | VV, VH, HV, HH | 2007 |\n",
    "\n",
    "### NASA SnowEx 2020 and 2021 UAVSAR Campaigns\n",
    "\n",
    "During the winter of 2020 and 2021, NASA conducted an L-band InSAR timeseries across the Western US with the goal of tracking changes in SWE. Field teams in 13 different locations in 2020, and in 6 locations in 2021, deployed on the date of the flight to perform calibration and validation observations.\n",
    "\n",
    "---\n",
    "\n",
    "The site locations from the above map along with the [UAVSAR defined campaign name](https://api.daac.asf.alaska.edu/services/utils/mission_list) and currently processed pairs of InSAR images for each site. Note that the image pair count may contain multiple versions of the same image and may increase as more pairs of images are processed by JPL. Also note that the Lowman campaign name is the wrong state when searching.\n",
    "\n",
    "| Site Location | Campaign Name | Image Pairs |\n",
    "| - | - | - |\n",
    "| Grand Mesa | Grand Mesa, CO | 13 |\n",
    "| Boise River Basin | Lowman, CO | 17 |\n",
    "| Frazier Experimental Forest | Fraser, CO | 16 |\n",
    "| Senator Beck Basin | Ironton, CO | 9 |\n",
    "| East River | Peeler Peak, CO | 4 |\n",
    "| Cameron Pass | Rocky Mountains NP, CO | 15 |\n",
    "| Reynold Creek | Silver City, ID | 1 |\n",
    "| Central Agricultral Research Center | Utica, MT | 2 |\n",
    "| Little Cottonwoody Canyon | Salt Lake City, UT | 21 |\n",
    "| Jemez River | Los Alamos, NM | 3 |\n",
    "| American River Basin | Eldorado National Forest, CA | 4 |\n",
    "| Sagehen Creek | Donner Memorial State Park, CA | 4 |\n",
    "| Lakes Basin | Sierra National Forest, CA | 3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why would I use UAVSAR?\n",
    "\n",
    "UAVSAR works with low frequency radar waves. These low frequencies (< 3 GHz) can penetrate clouds and maintain coherence (a measure of radar image quality) over long periods. For these reasons, time series was captured over 13 sites as part of the winter of 2019-2020 and 2020-2021 for snow applications. Additionally the UAVSAR is awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing UAVSAR Images\n",
    "\n",
    "UAVSAR imagery can be downloaded from both the [JPL](https://uavsar.jpl.nasa.gov/cgi-bin/data.pl) and [Alaska Satellite Facility](https://search.asf.alaska.edu/#/?dataset=UAVSAR). However both provide the imagery in a binary format that is not readily usable or readable by GIS software or python libraries. \n",
    "\n",
    "## Data Download and Conversion with ```uavsar_pytools```\n",
    "```uavsar_pytools``` ([Github](https://github.com/SnowEx/uavsar_pytools)) is a Python package developed out of work started at SnowEx Hackweek 2021. It nativiely downloads, formats, and converts this data in analysis ready rasters projected in WSG-84 Lat/Lon ([EPSG:4326](https://epsg.io/4326). The data traditionally comes in a binary format, which is not injestible by traditional geospatial analysis software (Python, R, QGIS, ArcGIS). It can download and convert either individual images - `UavsarScene` or entire collections of images - `UavsarCollection`.\n",
    "\n",
    "### Netrc Authorization\n",
    "\n",
    "In order to download uavsar images you will need a [netrc file](https://www.gnu.org/software/inetutils/manual/html_node/The-_002enetrc-file.html) that contains your earthdata username and password. If you need to register for a NASA earthdata account use this [link](https://urs.earthdata.nasa.gov/). A netrc file is a hidden file, it won't appear in the your file explorer, that is in your home directory and that programs can access to get the appropriate usernames and passwords. While you'll have already done this for the Hackweek virtual machines, ```uavsar_pytools``` has a tool to create this netrc file on a local computer. You only need to create this file once and then it should be permanently stored on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Creating .netrc file with Earthdata login information\n",
    "# from uavsar_pytools.uavsar_tools import create_netrc\n",
    "\n",
    "# # This will prompt you for your username and password and save this\n",
    "# # information into a .netrc file in your home directory. You only need to run\n",
    "# # this command once per computer. Then it will be saved.\n",
    "# create_netrc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and converting a single UAVSAR interferogram scene\n",
    "\n",
    "You can find urls for UAVSAR images at the [ASF vertex website](https://search.asf.alaska.edu/#/?dataset=UAVSAR). Make sure to change the platform to UAVSAR and you may also want to filter to ground projected interferograms.\n",
    "\n",
    "![](./images/uavsar/vertex_example.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from uavsar_pytools import UavsarScene\n",
    "except ModuleNotFoundError:\n",
    "    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n",
    "\n",
    "## This is the directory you want to download and convert the images in.\n",
    "work_dir = '/tmp/uavsar_data'\n",
    "\n",
    "## This is a url you want to download. Can be obtained from vertex\n",
    "url = 'https://datapool.asf.alaska.edu/INTERFEROMETRY_GRD/UA/\\\n",
    "lowman_23205_21009-004_21012-000_0007d_s01_L090_01_int_grd.zip'\n",
    "\n",
    "## clean = True will delete the binary and zip files leaving only the tiffs\n",
    "scene = UavsarScene(url = url, work_dir=work_dir, clean= True)\n",
    "\n",
    "## After running url_to_tiffs() you will download the zip file, unzip the binary \n",
    "## files, and convert them to geotiffs in the directory with the scene name in\n",
    "## the work directory. It also generate a .csv pandas dictionary of metadata.\n",
    "# scene.url_to_tiffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and converting a full UAVSAR collection\n",
    "\n",
    "If you want to download and convert an entire Uavsar collection for a larger analysis you can use `UavsarCollection`. The collection names for the SnowEx campaign are listed in the table in the introduction. The `UavsarCollection` can download either InSAR pairs and PolSAR images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uavsar_pytools import UavsarCollection\n",
    "## Collection name, the SnowEx Collection names are listed above. These are case \n",
    "## and space sensitive.\n",
    "collection_name = 'Grand Mesa, CO'\n",
    "\n",
    "## Directory to save collection into. This will be filled with directory with \n",
    "## scene names and tiffs inside of them.\n",
    "out_dir = '/tmp/collection_ex/'\n",
    "\n",
    "## This is optional, but you will generally want to at least limit the date\n",
    "## range between 2019 and today.\n",
    "date_range = ('2019-11-01', 'today')\n",
    "\n",
    "# Keywords: to download incidence angles with each image use `inc = True`\n",
    "# For only certain pols use `pols = ['VV','HV']`\n",
    "\n",
    "collection = UavsarCollection(collection = collection_name, work_dir = out_dir, dates = date_range)\n",
    "\n",
    "## You can use this to check how many image pairs have at least one image in\n",
    "## the date range.\n",
    "\n",
    "#collection.find_urls()\n",
    "\n",
    "## When you are ready to download all the images run:\n",
    "\n",
    "# collection.collection_to_tiffs()\n",
    "\n",
    "## This will take a long time and a lot of space, ~1-5 gB and 10 minutes per \n",
    "## image pair depending on which scene, so run it if you have the space and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAVSAR Data Products\n",
    "\n",
    "UAVSAR has a variety of different type of images:\n",
    "\n",
    "[Repeat Pass Interferometric](https://uavsar.jpl.nasa.gov/science/documents/rpi-format.html) images contain:\n",
    "```{admonition} InSAR Data Types\n",
    ":class: InSAR Data Types\n",
    "- ANN file (.ann): a text annotation file with metadata\n",
    "- AMP files (.amp1 and .amp2): amplitude products for flight 1 and flight 2\n",
    "- COR files (.cor): coherence a measure of the noise level of the phase\n",
    "- INT files (.int): wrapped phase difference between the two images\n",
    "- UNW files (.unw): unwrapped phase difference between the two images\n",
    "- INC files (.inc): incidence angle in radians\n",
    "- HGT file  (.hgt): the DEM that was used in the InSAR processing\n",
    "```\n",
    "\n",
    "UAVSAR repeat pass interferometry uses two images of the same place but separated in time. Phase changes between the two aquistions are calculated,  creating a wrapped interferogram. These phase changes are due to either the wave traveling a longer distance (ground movement or refraction) or change wave speeds (atmospheric water vapor and snow).\n",
    "\n",
    "- GRD files (.grd): products projected to the ground in geographic coordinates (latitude, longitude)\n",
    "Finally all images can be in radar slant range or projected into WGS84. Images that have already been projected to ground range will have the extension .grd appended to their file type extension. \n",
    "\n",
    "For instance a image of unwrapped phase that has not been georefenced would end with .unw, while one that was georeferenced would end with .unw.grd. You will generally want to use .grd files for most analysis.\n",
    "\n",
    "\n",
    "[Polarimetric PolSAR](https://uavsar.jpl.nasa.gov/science/documents/polsar-format.html) images contain:\n",
    "- ANN file (.ann): a text annotation file with metadata\n",
    "- Polsar file (_HHVV_.grd): all the rest of the files will be a pair of polarizations pushed together\n",
    "\n",
    "Polsar files have a pair of polarizations (VV, VH, HV, HH) combined in their file name. These files are the phase difference between polarization XX and polarization YY. For instance HHHV is the phase difference between HH and HV polarizations. HVVV is the phase difference between HV and VV and so one. There are 6 of these pairs since order is irrelevant. These 6 images are combined to calculate various metrics that tell you about the types of scattering occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arendta/miniforge3/envs/snow-observations-cookbook-test/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.8.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.8.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.1.min.js\", \"https://cdn.holoviz.org/panel/1.8.3/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='106d157d-08d6-4d6e-8c41-01e33562d8f5'>\n",
       "  <div id=\"ac2f271c-890a-480b-8f11-e1c4cf69ded5\" data-root-id=\"106d157d-08d6-4d6e-8c41-01e33562d8f5\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"eea572eb-dbca-452d-bead-23e2bd5b6d94\":{\"version\":\"3.8.1\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"26fa1e3b-2b70-4f17-95e8-d800b7e8d30b\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"bdfcdb6e-afe8-44e8-9220-a8ce396c6cc8\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"106d157d-08d6-4d6e-8c41-01e33562d8f5\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"49fa1680-315e-4ff8-bf1c-7e49198283bb\",\"attributes\":{\"plot_id\":\"106d157d-08d6-4d6e-8c41-01e33562d8f5\",\"comm_id\":\"c21a14731c934b62acdce2f8f3f1eb7a\",\"client_comm_id\":\"b05eda93799f4cd9bfef65c32099d9da\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"start\",\"kind\":\"Any\",\"default\":0},{\"name\":\"end\",\"kind\":\"Any\",\"default\":100},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"eea572eb-dbca-452d-bead-23e2bd5b6d94\",\"roots\":{\"106d157d-08d6-4d6e-8c41-01e33562d8f5\":\"ac2f271c-890a-480b-8f11-e1c4cf69ded5\"},\"root_ids\":[\"106d157d-08d6-4d6e-8c41-01e33562d8f5\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "106d157d-08d6-4d6e-8c41-01e33562d8f5"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arendta/miniforge3/envs/snow-observations-cookbook-test/lib/python3.12/site-packages/earthpy/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_string\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from uavsar_pytools import UavsarScene\n",
    "    from uavsar_pytools.snow_depth_inversion import depth_from_phase, phase_from_depth\n",
    "except ModuleNotFoundError:\n",
    "    print('Install uavsar_pytools with `pip install uavsar_pytools`')\n",
    "\n",
    "import os\n",
    "from os.path import join, basename\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import holoviews as hv\n",
    "import rioxarray as rxa\n",
    "import rasterio as rio\n",
    "from bokeh.plotting import show\n",
    "import datashader as ds\n",
    "from datashader.mpl_ext import dsshow\n",
    "hv.extension('bokeh', logo=False)\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import contextily as cx\n",
    "from datetime import date\n",
    "from shapely.geometry import box\n",
    "import requests\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# Database imports\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, ImageData, LayerData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='rasterio')\n",
    "import logging\n",
    "logging.getLogger('rasterio._env').setLevel(logging.ERROR)\n",
    "logging.getLogger('rasterio._filepath').setLevel(logging.ERROR)\n",
    "os.environ['CPL_CURL_VERBOSE'] = 'NO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interferometric Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banner Summit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll be plotting and comparing dirrerent types of SAR and InSAR data with optical imagery and a digital elevation model. For this example we'll be taking a subet of the Lowman flight (Boise, ID) line encompassing Banner Summit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Tutorial Data from S3\n",
    "\n",
    "The tutorial data is hosted on AWS S3 and can be accessed directly without downloading. The data will be streamed as needed using `rioxarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 base URL for tutorial data\n",
    "S3_BASE_URL = \"https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Rasters\n",
    "Here we'll load our rasters into the environemtns using ```rioxarray``` or ```rxa```, we will then convert to a ```np.array``` to be able to use ```matplotlib.pyplot``` or ```plt``` for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Data\n",
    "\n",
    "We will be using [Haromized Landsat Sentinel (HLS)](https://hls.gsfc.nasa.gov/) dataset from January 13th, 2021. This date was selected because it is mostly cloud free, which is uncommon in mountain environments during the winter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning 1: HTTP response code on https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/lowman_red.tif.msk: 403\n",
      "Warning 1: HTTP response code on https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/lowman_red.tif.MSK: 403\n",
      "Warning 1: HTTP response code on https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/lowman_green.tif.msk: 403\n",
      "Warning 1: HTTP response code on https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/lowman_green.tif.MSK: 403\n",
      "Warning 1: HTTP response code on https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/lowman_blue.tif.msk: 403\n",
      "Warning 1: HTTP response code on https://snowex-tutorials.s3.us-west-2.amazonaws.com/uavsar/lowman_blue.tif.MSK: 403\n"
     ]
    }
   ],
   "source": [
    "# Define S3 URLs for the three RGB bands and stack them in memory\n",
    "red_path = S3_BASE_URL + 'lowman_red.tif'\n",
    "green_path = S3_BASE_URL + 'lowman_green.tif'\n",
    "blue_path = S3_BASE_URL + 'lowman_blue.tif'\n",
    "\n",
    "# Load and stack RGB bands directly from S3 (no local files needed)\n",
    "import xarray as xr\n",
    "red = rxa.open_rasterio(red_path)\n",
    "green = rxa.open_rasterio(green_path)\n",
    "blue = rxa.open_rasterio(blue_path)\n",
    "\n",
    "# Stack the bands into a single array\n",
    "rgb = xr.concat([red, green, blue], dim='band')\n",
    "rgb['band'] = [1, 2, 3]  # Label bands as 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we see in this image? Any notable features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rgb image\n",
    "ep.plot_rgb(rgb.values,\n",
    "            figsize=(15, 15),\n",
    "            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n",
    "            title = \"HLS Optical 2/18/2021\", \n",
    "            stretch=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InSAR and SAR Data\n",
    "\n",
    "Here we'll be using five different data products related to InSAR and SAR: unwrapped phase (```unw```), coherence (```cor```), amplitude (```amp```), elevation (```dem```), and incidence angle (```inc```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open rasters directly from S3 and inspect metadata using xarray\n",
    "unw_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_unw.tif')\n",
    "unw = unw_rast[0].values # np.array for plotting\n",
    "    \n",
    "# coherence\n",
    "cor_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_cor.tif')\n",
    "cor = cor_rast[0].values\n",
    "\n",
    "# amplitude\n",
    "amp_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_amb_db.tif')\n",
    "amp = amp_rast[0].values # np.array for plotting\n",
    "\n",
    "# dem\n",
    "dem_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_dem.tif')\n",
    "dem = dem_rast[0].values\n",
    "\n",
    "# incidence angle\n",
    "inc_rast  = rxa.open_rasterio(S3_BASE_URL + 'lowman_inc_deg.tif')\n",
    "inc = inc_rast[0].values # np.array for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot unwrapped phase\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ax.set_title(\"UNW (radians)\", fontsize= 20) #title and font size\n",
    "img = ax.imshow(unw, interpolation = 'nearest', cmap = 'viridis', vmin = -3, vmax = 2)\n",
    "\n",
    "# add legend\n",
    "colorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coherence\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ax.set_title(\"Coherence\", fontsize= 20) #title and font size\n",
    "img = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\n",
    "\n",
    "# add legend\n",
    "colorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot amplitude\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ax.set_title(\"Amplitude (dB)\", fontsize= 20) #title and font size\n",
    "img = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\n",
    "\n",
    "# add legend\n",
    "colorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dem\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ax.set_title(\"Elevation (m)\", fontsize= 20) #title and font size\n",
    "img = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\n",
    "\n",
    "# add legend\n",
    "colorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot incidence angle\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) # increase plot font size for larger plot\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "ax.set_title(\"Incidence Angle (deg)\", fontsize= 20) #title and font size\n",
    "img = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\n",
    "\n",
    "# add legend\n",
    "colorbar = fig.colorbar(img, ax=ax, fraction=0.03, pad=0.04) # add color bar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all InSAR products\n",
    "fig = plt.figure(figsize=(30,19))\n",
    "\n",
    "ax = fig.add_subplot(1,3,1)\n",
    "cax=ax.imshow(unw, cmap='viridis', interpolation = 'nearest', vmin = -3, vmax = 2)\n",
    "ax.set_title(\"UNW (radians)\")\n",
    "#ax.set_axis_off()\n",
    "cbar = fig.colorbar(cax, ticks=[-3,0,2],orientation='horizontal', fraction=0.03, pad=0.04)\n",
    "cbar.ax.set_xticklabels([-3,0,2])\n",
    "\n",
    "ax = fig.add_subplot(1,3,2)\n",
    "cax = ax.imshow(cor, cmap = 'magma', vmin = 0, vmax = 1)\n",
    "ax.set_title(\"Coherence\")\n",
    "#ax.set_axis_off()\n",
    "cbar = fig.colorbar(cax, ticks=[0,.5,1], orientation='horizontal',fraction=0.03, pad=0.04)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1,3,3)\n",
    "cax = ax.imshow(amp, cmap = 'Greys_r', vmin = -20, vmax = 0)\n",
    "ax.set_title(\"Amplitude (dB)\")\n",
    "#ax.set_axis_off()\n",
    "cbar = fig.colorbar(cax, ticks=[-20,-10,0], orientation='horizontal',fraction=0.03, pad=0.04)\n",
    "cbar.ax.set_xticklabels([-20,-10,0])\n",
    "\n",
    "ax = fig.add_subplot(2,3,1)\n",
    "cax = ax.imshow(inc, cmap = 'Spectral_r', vmin = 20, vmax = 90)\n",
    "ax.set_title(\"Incidence Angle (deg)\")\n",
    "#ax.set_axis_off()\n",
    "cbar = fig.colorbar(cax, ticks=[20,90], orientation='horizontal', pad=0.07)\n",
    "cbar.ax.set_xticklabels([20,90])\n",
    "\n",
    "ax = fig.add_subplot(2,3,2)\n",
    "cax = ax.imshow(dem, cmap = 'terrain', vmin = 1800, vmax = 2800)\n",
    "ax.set_title(\"Elevation (m)\")\n",
    "#ax.set_axis_off()\n",
    "cbar = fig.colorbar(cax, ticks=[1800,2800], orientation='horizontal', pad=0.07)\n",
    "cbar.ax.set_xticklabels([1800,2800])\n",
    "\n",
    "done = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.plot_rgb(rgb.values,\n",
    "            figsize=(7, 7),\n",
    "            rgb = [0,1,2], # plot the red, green, and blue bands in that order\n",
    "            title = \"HLS Optical 2/18/2021\", \n",
    "            stretch=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some notable similarities between images? Differences?\n",
    "\n",
    "In the next section we'll go into more detail about the features that impact coherence, phase, and how they're related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagehen Creek Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sagehen Creek data directly from S3\n",
    "sage_files = ['cor.tif', 'hgt.tif', 'unw.tif']\n",
    "imgs = {}\n",
    "for filename in sage_files:\n",
    "    name = filename.split('.')[0]\n",
    "    s3_path = S3_BASE_URL + 'sage/' + filename\n",
    "    imgs[name] = rxa.open_rasterio(s3_path, parse_coordinates=True, default_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What topographic features seem to impact coherence?\n",
    "\n",
    "Take a moment to chat with the people around you about this. Some features to get you thinking:\n",
    "\n",
    "- lakes\n",
    "- aspect (south vs north, east vs west)\n",
    "- elevation\n",
    "- trees\n",
    "- roads\n",
    "- others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = hv.element.tiles.EsriUSATopo().opts()\n",
    "cor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\n",
    "hgt = hv.Image(hv.Dataset(imgs['hgt'], kdims=['x','y'])).opts(cmap = 'terrain', colorbar=True, xaxis = None, yaxis = None, title= 'DEM', alpha = 0.4)\n",
    "hgt_trans = hv.Image(hv.Dataset(imgs['hgt'][0,::100,::100], kdims=['x','y'])).opts(alpha = 0, xaxis = None, yaxis = None, title = 'Topo')\n",
    "cor_tile = tiles  * cor\n",
    "hgt_tile = tiles  * hgt\n",
    "imagery = hv.element.tiles.EsriImagery()  * hgt_trans\n",
    "\n",
    "hv.Layout([cor_tile, hgt_tile, imagery]).opts(width = 400, height = 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "xna = imgs['hgt'].data.ravel()\n",
    "yna = imgs['cor'].data.ravel()\n",
    "x = xna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\n",
    "y = yna[(~np.isnan(xna)) & (~np.isnan(yna))][::100]\n",
    "\n",
    "df = pd.DataFrame(dict(x=x, y=y))\n",
    "df['x_cat'] = pd.qcut(df.x, q= 6, precision = 0)\n",
    "f, ax = plt.subplots(figsize = (12,8))\n",
    "sns.violinplot(y = df.y[::100], x = df.x_cat[::100], scale = 'count')\n",
    "plt.xlabel('Elevation Bands (m)')\n",
    "plt.ylabel('Coherence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNW vs. Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = hv.element.tiles.EsriUSATopo().opts()\n",
    "cor = hv.Image(hv.Dataset(imgs['cor'], kdims=['x','y'])).opts(cmap = 'gray', colorbar=True, xaxis = None, yaxis = None, title = 'Coherence')\n",
    "unw = hv.Image(hv.Dataset(imgs['unw'], kdims=['x','y'])).opts(cmap = 'magma', colorbar=True, xaxis = None, yaxis = None, title= 'Unwrapped Phase', clim = (0, 2*np.pi))\n",
    "cor_tile = tiles  * cor\n",
    "unw_tile = tiles  * unw\n",
    "\n",
    "hv.Layout([cor_tile, unw_tile]).opts(width = 400, height = 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why would I use UAVSAR for snow?\n",
    "\n",
    "L-band SAR penetrates through the snowpack. However when it crosses into the snowpack from the air it refracts at an angle, similar to light entering water. This refraction leads to a phase shift relative to an image with no or less snow. Using this difference in phase between two images we can calculate the change in snow height between flights using:\n",
    "\n",
    "$$\n",
    "\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n",
    "$$\n",
    "\n",
    "Where $\\Delta$ d is the change in snow height, $\\Delta \\phi$ is the phase shift between two SAR images, $\\lambda$ is the radar wavelength, $\\alpha$ is the incidence angle, and $\\epsilon_{s}$ is the dielectric constant of snow which is dependent on the density and liquid water content.\n",
    "\n",
    "![](./images/uavsar/conceptual.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesa Lake Snotel Coordinates\n",
    "snotel_coords = (-108.05, 39.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Change between February 1st and 13th UAVSAR Image Pairs\n",
    "\n",
    "You learned in the first section how to access and download UAVSAR imagery. For this section the data has already been downloaded, converted to GeoTiffs and cropped down to an area of interest that overlaps the main field sites of Grand Mesa. Lets take a look at the coherence and unwrapped phase between these two flights. If you don't remember what these two represent check out the previous section of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures and subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize = (12,8))\n",
    "\n",
    "# Select colormap for each image type\n",
    "vis_dic = {'cor': 'Blues', 'unw':'magma'}\n",
    "\n",
    "# Loop through coherence and unwrapped phase images\n",
    "for i, type in enumerate(vis_dic.keys()):\n",
    "    # select correct axis\n",
    "    ax = axes[i]\n",
    "    # open image directly from S3 with rioxarray\n",
    "    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n",
    "    # calculate visualization parameters\n",
    "    vmin, vmax = img.quantile([0.1,0.9])\n",
    "    # plot images\n",
    "    img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n",
    "    # zoom out a bit\n",
    "    ax.set_xlim(-108.28,-108)\n",
    "    ax.set_ylim(38.98, 39.08)\n",
    "    # add topo basemap\n",
    "    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n",
    "    # turn off labels\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.yaxis.label.set_visible(False)\n",
    "# set titles\n",
    "axes[0].set_title('Coherence')\n",
    "axes[1].set_title('Unwrapped Phase Change')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "\n",
    "# Plot the snotel location\n",
    "ax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n",
    "\n",
    "# Plot bounding box of uavsar - stream from S3\n",
    "uavsar_bounds = rxa.open_rasterio(S3_BASE_URL + 'cor.tif').rio.bounds()\n",
    "x,y = box(*uavsar_bounds).exterior.xy\n",
    "ax.plot(x,y, color = 'blue')\n",
    "\n",
    "# Set overview bounds\n",
    "ax.set_xlim(-108.4,-107.75)\n",
    "ax.set_ylim(38.75, 39.3)\n",
    "\n",
    "# Add background map\n",
    "cx.add_basemap(ax, crs='EPSG:4326', alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\n",
    "plt.title('Overview Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the SnowEx SQL Database to collect snow depth and lidar datasets\n",
    "\n",
    "Lets explore how many overlapping depth observations we have between these two days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what you will use for all of hackweek to access the db\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n",
    "\n",
    "# Using the function get_db, we receive 2 ways to interact with the database\n",
    "engine, session = get_db(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its convenient to store a query like the following \n",
    "qry = session.query(PointData)\n",
    "\n",
    "# Filter to snow depths\n",
    "qry = qry.filter(PointData.type == 'depth')\n",
    "qry = qry.filter(PointData.site_name == 'Grand Mesa')\n",
    "qry = qry.filter(PointData.instrument != 'Mala 800 MHz GPR')\n",
    "\n",
    "# Then filter on it first date. We are gonna get one day either side of our flight date\n",
    "qry_feb1 = qry.filter(PointData.date >= date(2020, 1, 31))\n",
    "qry_feb1 = qry_feb1.filter(PointData.date <= date(2020, 2, 2))\n",
    "df_feb_1 = query_to_geopandas(qry_feb1, engine)\n",
    "\n",
    "# Get depths from second flight date\n",
    "qry_feb12 = qry.filter(PointData.date >= date(2020, 2, 11))\n",
    "qry_feb12 = qry_feb12.filter(PointData.date <= date(2020, 2, 13))\n",
    "df_feb_12 = query_to_geopandas(qry_feb12, engine)\n",
    "\n",
    "# Get depths that were captured on both days\n",
    "df_both = df_feb_1.overlay(df_feb_12, how = 'intersection')\n",
    "\n",
    "# Convert crs to match our uavsar images\n",
    "df_both = df_both.to_crs(epsg = 4326)\n",
    "\n",
    "# Calculate the snow depth change for each point\n",
    "df_both['sd_diff'] = df_both.value_2 - df_both.value_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,4))\n",
    "\n",
    "# Plot depth measurements\n",
    "df_both.plot(ax = ax, column = 'sd_diff', legend = True, legend_kwds = {'label': 'Snow Depth Change [cm]'}, cmap = 'magma')\n",
    "\n",
    "# Plot the snotel location\n",
    "snotel_coords = (-108.05, 39.05)\n",
    "ax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n",
    "\n",
    "# Plot bounding box of uavsar - stream from S3\n",
    "img = rxa.open_rasterio(S3_BASE_URL + 'cor.tif')\n",
    "uavsar_bounds = img.rio.bounds()\n",
    "x,y = box(*uavsar_bounds).exterior.xy\n",
    "ax.plot(x,y, color = 'blue')\n",
    "\n",
    "# Set same bounds as uavsar image plot\n",
    "ax.set_xlim(-108.28,-108)\n",
    "ax.set_ylim(38.98, 39.08)\n",
    "\n",
    "# Add background map\n",
    "cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USImageryTopo)\n",
    "plt.title('Database Snow Depth Measurements')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the remaining parameters\n",
    "\n",
    "### Incidence Angle\n",
    "\n",
    "We can recall the formula to calculate snow depth change from incidence angle, phase change, and the snow permittivity. \n",
    "\n",
    "$$\n",
    "\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n",
    "$$\n",
    "\n",
    "We have two of these variables already: incidence angle and phase change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures and subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize = (12,8))\n",
    "\n",
    "# Select colormap for each image type\n",
    "vis_dic = {'inc': 'Greys', 'unw':'magma'}\n",
    "\n",
    "# Loop through each image type\n",
    "for i, type in enumerate(vis_dic.keys()):\n",
    "    ax = axes[i]\n",
    "    # Open image directly from S3 with rioxarray\n",
    "    img = rxa.open_rasterio(S3_BASE_URL + f'{type}.tif')\n",
    "    # convert incidence angle from radians to degrees\n",
    "    if type == 'inc':\n",
    "        img = np.rad2deg(img)\n",
    "    # this is a great convenience feature to calculate good visualization levels\n",
    "    vmin, vmax = img.quantile([0.1,0.9])\n",
    "    # plot the image\n",
    "    im = img.plot(ax = ax, vmin = vmin, vmax = vmax, cmap = vis_dic[type], zorder = 1, alpha = 0.7)\n",
    "    # Zoom out a big\n",
    "    ax.set_xlim(-108.28,-108)\n",
    "    ax.set_ylim(38.98, 39.08)\n",
    "    # Add a topo basemap\n",
    "    cx.add_basemap(ax, crs=img.rio.crs, alpha = 0.8, source = cx.providers.USGS.USTopo)\n",
    "    # Remove unnecessary 'x' 'y' labels\n",
    "    ax.xaxis.label.set_visible(False)\n",
    "    ax.yaxis.label.set_visible(False)\n",
    "\n",
    "# Add titles\n",
    "axes[0].set_title('Incidence Angle')\n",
    "axes[1].set_title('Unwrapped Phase Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Permittivity\n",
    "\n",
    "We have two ways of getting the $e_{s}$, or the real part of the snow's dielectric permittivity. One is by estimating from the snow density. For dry snow we can estimate the permittivity using the density. There are a number of equations for calculating this value, but we will use the equation from [Guneriussen et al. 2001](https://ieeexplore.ieee.org/document/957273):\n",
    "\n",
    "$$\n",
    "e_{s} = 1 + 0.0016 \\rho + 1.8 1\\mathrm{e}{-9} \\rho^{3}\n",
    "$$\n",
    "\n",
    "where $e_{s}$ is the real part of the snow's dielectric permittivity and $\\rho$ is the density of the new snow accumulated between the two images in $\\frac{kg}{m^{3}}$.\n",
    "\n",
    "The other method is to use the directly measured values for permittivity from the field and averaging the top layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its convenient to store a query like the following \n",
    "qry = session.query(LayerData)\n",
    "\n",
    "# Then filter on it first date. We are gonna get one day either side of second flight date\n",
    "qry = qry.filter(LayerData.date >= date(2020, 1, 31))\n",
    "qry = qry.filter(LayerData.date <= date(2020, 2, 2))\n",
    "qry = qry.filter(LayerData.site_name == 'Grand Mesa')\n",
    "# Filter to snow density\n",
    "qry_p = qry.filter(LayerData.type == 'density')\n",
    "# Change the qry to a geopandas dataframe\n",
    "df = query_to_geopandas(qry_p, engine)\n",
    "# create a list to hold the density values\n",
    "p_values = []\n",
    "# Loop through each snowpit (each unique site-id is a snowpit) \n",
    "for id in np.unique(df.site_id):\n",
    "    sub = df[df.site_id == id]\n",
    "    # get the density for the top layer identified in each snowpit\n",
    "    p = float(sub.sort_values(by = 'depth', ascending = False).iloc[0]['value'])\n",
    "    # add it our list\n",
    "    p_values.append(p)\n",
    "# calculate the mean density of the top layer for each snowpit\n",
    "mean_new_density = np.nanmean(p_values)\n",
    "# Use our equation above to estimate our new snow permittivity\n",
    "es_estimate = 1 + 0.0016*mean_new_density + 1.8e-09*mean_new_density**3\n",
    "\n",
    "## We can also use snowpits where permittivity was directly observed to compare to\n",
    "# our density estimates\n",
    "qry = qry.filter(LayerData.type == 'permittivity')\n",
    "df = query_to_geopandas(qry, engine)\n",
    "es_values = []\n",
    "for id in np.unique(df.site_id):\n",
    "    sub = df[df.site_id == id]\n",
    "    es_str = sub.sort_values(by = 'depth', ascending = False).iloc[0]['value']\n",
    "    if es_str != None:\n",
    "        es = float(es_str)\n",
    "        if es != None:\n",
    "            es_values.append(es)\n",
    "es_measured = np.nanmean(es_values)\n",
    "\n",
    "print(f'New snow measured permittivity: {es_measured}. Permittivity from density: {es_estimate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have a new snow permittivity (either from density or directly measured) and we can use that along with our unwrapped phase to calculate the Uavsar snow depth change.\n",
    "\n",
    "Take a moment to code up the formula for snow depth change from phase and incidence angle:\n",
    "\n",
    "\n",
    "$$\n",
    "\\Delta d = - \\frac{\\Delta \\phi \\lambda}{4 \\pi} \\frac{1}{\\cos^{ } \\alpha - \\sqrt{\\epsilon_{s} - \\sin^{2} \\alpha}}\n",
    "$$\n",
    "\n",
    "Where $\\Delta$ d is the change in snow height, $\\Delta \\phi$ is the phase shift between two SAR images, $\\lambda$ is the radar wavelength, $\\alpha$ is the incidence angle, and $\\epsilon_{s}$ is the dielectric constant of snow which is dependent on the density and liquid water content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open rasters directly from S3 (unwrapped phase and incidence angle)\n",
    "unw = rxa.open_rasterio(S3_BASE_URL + 'unw.tif')\n",
    "inc = rxa.open_rasterio(S3_BASE_URL + 'inc.tif')\n",
    "\n",
    "# This uses the pytool's function to directly give you snow depth change\n",
    "# feel free to rerun with this to check your results\n",
    "# https://github.com/SnowEx/uavsar_pytools/blob/main/uavsar_pytools/snow_depth_inversion.py\n",
    "sd_change = depth_from_phase(unw, inc, density = mean_new_density)\n",
    "\n",
    "# convert to centimeters from meters\n",
    "sd_change = sd_change*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot the results!\n",
    "f, ax = plt.subplots(figsize = (12,8))\n",
    "\n",
    "# Plot our uavsar snow depth change\n",
    "sd_change.plot(ax = ax, cmap = 'Blues', vmin = -10, vmax = 10)\n",
    "# plot black shadow for field observations\n",
    "df_both.plot(ax = ax, color = 'black', markersize = 90)\n",
    "# plot field observed snow depth difference\n",
    "df_both.plot(ax = ax, column = 'sd_diff', legend = True, cmap = 'Blues', vmin = -10, vmax = 10)\n",
    "# add snotel coordinates\n",
    "ax.scatter(x = snotel_coords[0], y = snotel_coords[1], marker = 'x', color = 'black')\n",
    "# turn off labels\n",
    "ax.xaxis.label.set_visible(False)\n",
    "ax.yaxis.label.set_visible(False)\n",
    "# set title\n",
    "ax.set_title('Uavsar Snow Depth Inversion vs Field Observations')\n",
    "\n",
    "## Uncomment this to zoom in on the measured results\n",
    "# ax.set_xlim(-108.14, -108.23)\n",
    "# ax.set_ylim(39, 39.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Comparison\n",
    "\n",
    "We can now extract the snow depth change at each measured point and compare them\n",
    "to the pit values of snow depth change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample UAVSAR snow depth change at field measurement points (in memory, no file I/O)\n",
    "coord_list = [(x, y) for x, y in zip(df_both['geometry'].x, df_both['geometry'].y)]\n",
    "\n",
    "# Use rioxarray to sample values directly from the in-memory array\n",
    "from rasterio.transform import rowcol\n",
    "df_both['uavsar_sd'] = [\n",
    "    float(sd_change.sel(x=x, y=y, method='nearest').values) \n",
    "    for x, y in coord_list\n",
    "]\n",
    "\n",
    "f, ax = plt.subplots(figsize = (12,8))\n",
    "df_both['geometry-str'] = df_both['geometry'].astype(str)\n",
    "df_dis = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'mean', 'uavsar_sd': 'mean'})\n",
    "field_sd_std = df_both.dissolve('geometry-str', aggfunc={'sd_diff': 'std'})['sd_diff'].values\n",
    "ax.errorbar(x = df_dis.uavsar_sd, y = df_dis.sd_diff, yerr = field_sd_std, fmt=\"o\")\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "rmse_sd = rmse(df_both['sd_diff'], df_both['uavsar_sd'])\n",
    "print(f'RMSE between uavsar and field observations is {rmse_sd} cm')\n",
    "\n",
    "# now plot both limits against each other\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "ax.set_xlabel('Uavsar Snow Depth Change')\n",
    "ax.set_ylabel('Field Measured Snow Depth Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figures and subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize = (12,8))\n",
    "\n",
    "# Load lidar data from S3\n",
    "lidar = rxa.open_rasterio(S3_BASE_URL + 'sd_lidar.tif')\n",
    "\n",
    "diff = lidar.copy()\n",
    "diff = diff - sd_change\n",
    "\n",
    "vmin, vmax = sd_change.quantile([0.1,0.9])\n",
    "sd_change_masked = sd_change.copy()\n",
    "sd_change_masked.data[np.isnan(lidar).data] = np.nan\n",
    "sd_change_masked.plot(ax = axes[0], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\n",
    "lidar.plot(ax = axes[1], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\n",
    "diff.plot(ax = axes[2], vmin = vmin, vmax = vmax, cmap = 'Blues', zorder = 1, alpha = 0.7)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "\n",
    "axes[0].set_title('Uavsar Snow Depth Change')\n",
    "axes[1].set_title('Lidar Snow Depth Change')\n",
    "axes[2].set_title('Snow Depth Difference')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "diffs = diff.values.ravel()\n",
    "diffs = diffs[diffs < 100]\n",
    "diffs = diffs[diffs > -100]\n",
    "plt.hist(diffs, bins = 100, density = True, label = 'Uavsar sd change')\n",
    "# plt.axvline(sd_change_masked.mean().values, label = 'Uavsar Mean Snow Depth Change', color = 'green')\n",
    "lidar_vals = lidar.astype(np.float64).values[~lidar.isnull().values]\n",
    "lidar_vals = lidar_vals[lidar_vals < 100]\n",
    "lidar_vals = lidar_vals[lidar_vals > -100]\n",
    "mean_lidar = np.nanmean(lidar_vals)\n",
    "plt.axvline(mean_lidar, color = 'red', linewidth = 5, label = 'mean lidar sd change')\n",
    "# plt.axvline(mean_lidar, label = 'Lidar Mean Snow Depth Change', color = 'red')\n",
    "rmse = np.sqrt(((diffs) ** 2).mean())\n",
    "print(f'Lidar mean depth change: {sd_change_masked.mean().values} cm, uavsar mean depth change: {mean_lidar} cm')\n",
    "print(f'Mean difference: {np.nanmean(diffs)} cm, rmse = {rmse} cm')\n",
    "plt.legend(loc = 'lower left')\n",
    "plt.xlabel('Snow Depth Change (cm)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-observations-cookbook-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
