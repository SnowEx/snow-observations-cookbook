{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d36864",
   "metadata": {},
   "source": [
    "# Introduction to AVIRIS-NG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b3503",
   "metadata": {},
   "source": [
    "<img alt=\"AVIRIS Logo\" src=\"images/aviris-ng/Aviris.png\" style=\"margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d5e34",
   "metadata": {},
   "source": [
    "<br><b>Contributors:</b> Joachim Meyer<sup>1</sup>, Chelsea Ackroyd<sup>1</sup>, McKenzie Skiles<sup>1</sup>, Phil Dennison<sup>1</sup>, Keely Roth<sup>1</sup>\n",
    "<br>\n",
    "<sup>1</sup>University of Utah\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d9d3d",
   "metadata": {},
   "source": [
    "```{admonition} Learning Objectives\n",
    "\n",
    "* Become familiar with hyperspectral data, including data orginiating from AVIRIS-NG\n",
    "* Understand the fundamental methods for displaying and exploring hyperspectral data in Python\n",
    "* Identify the amount of ice in a given pixel using spectral feature fitting methodology\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52afa68",
   "metadata": {},
   "source": [
    "## Review of Hyperspectral Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d56572",
   "metadata": {},
   "source": [
    "Incoming solar radiation is either reflected, absorbed, or transmitted (or a combination of all three) depending on the surface material. This spectral response allows us to identify varying surface types (e.g. vegetation, snow, water, etc.) in a remote sensing image. The <b>spectral resolution</b>, or the wavelength interval, determines the amount of detail recorded in the spectral response: finer spectral resolutions have bands with narrow wavelength intervals, while coarser spectral resolutions have bands with larger wavelength intervals, and therefore, less detail in the spectral response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c9a223",
   "metadata": {},
   "source": [
    "![NEON Tutorial](https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/dev-aten/graphics/hyperspectral-general/spectrumZoomed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad8a55",
   "metadata": {},
   "source": [
    "![NEON FWHM](https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/dev-aten/graphics/hyperspectral-general/FWHM2.png)\n",
    "\n",
    "https://www.neonscience.org/resources/learning-hub/tutorials/hyper-spec-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e70ae2",
   "metadata": {},
   "source": [
    "### Multispectral vs. Hyperspectral Data\n",
    "\n",
    "Multispectral instruments have larger spectral resolutions with fewer bands. This level of detail can be limiting in distinguishing between surface types. Hyperspectral instruments, in comparison, typically have hundreds of bands with relatively narrow wavelength intervals. The image below illustrates the difference in spectral responses between a multispectral (Landsat 8 OLI) and a hyperspectral (AVIRIS) sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2f415",
   "metadata": {},
   "source": [
    "<img alt=\"AVIRIS Logo\" src=\"images/aviris-ng/Hyper_vs_Multispectral.png\" style=\"margin:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972f34f",
   "metadata": {},
   "source": [
    "## Computing environment\n",
    "\n",
    "We'll be using the following open source Python libraries in this notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab0adc",
   "metadata": {},
   "source": [
    "## SnowEx21 Spectral Reflectance Dataset\n",
    "\n",
    "The data were collected using an airborne imaging spectrometer, AVIRIS-NG can be downloaded from here, https://nsidc.org/data/snex21_ssr/versions/1.\n",
    "- Reflectance is provided at 5 nm spectral resolution with a range of 380-2500 nm\n",
    "\n",
    "- For this dataset, the pixel resolution is 4 m\n",
    "\n",
    "- Data span from 19 March 2021 to 29 April 2021, and were collected in two snow-covered environments in Colorado: Senator Beck Basin and Grand Mesa\n",
    "\n",
    "- Each file will have a \"__.img__\" and \"__.hdr__\". You need to have both of these in the same directory to open data.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://avirisng.jpl.nasa.gov/img/rmotc_large.png\" />\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b08791",
   "metadata": {},
   "source": [
    "## Accessing AVIRIS-NG Data from S3\n",
    "\n",
    "For this tutorial, we've hosted the AVIRIS-NG data on AWS S3 for easy access. The data is streamed directly from the cloud, so **no downloads are required**!\n",
    "\n",
    "The data is stored in a public S3 bucket in the `us-west-2` region:\n",
    "- **Bucket**: `s3://snowex-tutorials/aviris-ng/`\n",
    "- **Region**: us-west-2 (Oregon)\n",
    "\n",
    "We'll use `rasterio` to read ENVI format files directly from S3. This approach:\n",
    "- Works with the original ENVI format (no conversion needed)\n",
    "- Streams data on-demand (only reads what you need)\n",
    "- Requires no authentication for public buckets\n",
    "- Enables cloud-native workflows\n",
    "\n",
    "```{note}\n",
    "If you want to use your own local AVIRIS-NG files instead, simply replace the S3 paths with local file paths.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4553cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc5cc7e",
   "metadata": {},
   "source": [
    "## Loading AVIRIS-NG data with rasterio\n",
    "\n",
    "We'll use `rasterio` to open and read the AVIRIS-NG ENVI files directly from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 paths for AVIRIS-NG data (public bucket, no auth required)\n",
    "s3_bucket = \"snowex-tutorials\"\n",
    "s3_prefix = \"aviris-ng\"\n",
    "# ENVI format requires opening the .img data file (not .hdr)\n",
    "reflectance_file = \"SNEX21_SSR_ang20210429t191025_SBB_rfl_v2z1a_subset.img\"\n",
    "\n",
    "print(f\"Data source: s3://{s3_bucket}/{s3_prefix}/{reflectance_file}\")\n",
    "print(f\"Region: us-west-2\")\n",
    "print(f\"\\nNote: This data is publicly accessible, no AWS credentials needed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure rasterio to access S3 with anonymous (no-auth) access\n",
    "os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\n",
    "os.environ['AWS_REGION'] = 'us-west-2'\n",
    "\n",
    "# For ENVI files on S3, we need to use GDAL's virtual file system\n",
    "vsi_path = f\"/vsis3/{s3_bucket}/{s3_prefix}/{reflectance_file}\"\n",
    "\n",
    "# Open the AVIRIS-NG ENVI subset file from S3\n",
    "with rasterio.Env(AWS_NO_SIGN_REQUEST='YES', AWS_REGION='us-west-2'):\n",
    "    with rasterio.open(vsi_path) as src:\n",
    "        print(f\"Dataset dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"Number of bands: {src.count}\")\n",
    "        print(f\"Data type: {src.dtypes[0]}\")\n",
    "        print(f\"CRS: {src.crs}\")\n",
    "        print(f\"\\nReading reflectance data from S3...\")\n",
    "        print(f\"  (Streaming ~21 MB - tutorial subset)\")\n",
    "        \n",
    "        # Read all data from the subset\n",
    "        rfl_array = src.read()\n",
    "\n",
    "print(f\"\\nReflectance data shape: {rfl_array.shape}\")\n",
    "print(f\"Shape interpretation: ({rfl_array.shape[0]} bands, {rfl_array.shape[1]} rows, {rfl_array.shape[2]} columns)\")\n",
    "print(f\"\\nData successfully loaded from S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract wavelength information from the ENVI header metadata\n",
    "vsi_path = f\"/vsis3/{s3_bucket}/{s3_prefix}/{reflectance_file}\"\n",
    "\n",
    "with rasterio.Env(AWS_NO_SIGN_REQUEST='YES', AWS_REGION='us-west-2'):\n",
    "    with rasterio.open(vsi_path) as src:\n",
    "        # Get wavelength metadata from ENVI header\n",
    "        metadata = src.tags()\n",
    "        \n",
    "        # ENVI headers store wavelengths as a comma-separated string\n",
    "        if 'wavelength' in metadata:\n",
    "            wavelength_str = metadata['wavelength'].strip('{}')\n",
    "            bands = np.array([float(w.strip()) for w in wavelength_str.split(',')])\n",
    "            print(f\"Extracted {len(bands)} wavelength values\")\n",
    "            print(f\"Wavelength range: {bands.min():.1f} - {bands.max():.1f} nm\")\n",
    "            print(f\"\\nFirst 10 wavelengths (nm): {bands[:10]}\")\n",
    "        else:\n",
    "            print(\"Warning: Wavelength metadata not found in ENVI header\")\n",
    "            # Create default band indices if wavelengths aren't available\n",
    "            bands = np.arange(1, rfl_array.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a single pixel's spectral signature\n",
    "# Note: rasterio uses (bands, rows, cols) indexing, different from (rows, cols, bands)\n",
    "i = 125  # row index (middle of subset)\n",
    "j = 125  # column index (middle of subset)\n",
    "\n",
    "# Extract pixel spectrum across all bands\n",
    "pixel = rfl_array[:, i, j]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "ax.scatter(bands, pixel, color='blue', s=20)\n",
    "ax.set_xlabel('Wavelength [nm]')\n",
    "ax.set_ylabel('Reflectance')\n",
    "ax.set_title(f'Spectral signature at pixel ({i}, {j})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f806a4b5",
   "metadata": {},
   "source": [
    "## Working with Terrain Data\n",
    "\n",
    "```{note}\n",
    "Terrain and illumination data (*obs_ort files) for this flightline are not yet available in the S3 bucket. Once uploaded, they can be accessed the same way as the reflectance data shown above.\n",
    "\n",
    "To obtain terrain data:\n",
    "1. Visit https://search.earthdata.nasa.gov/\n",
    "2. Search for \"AVIRIS-NG L1B Calibrated Radiance, Facility Instrument Collection, V1\"\n",
    "3. Look for granules matching timestamp `ang20210429t191025` with `*obs_ort*` in the filename\n",
    "4. The obs_ort files contain 11 bands with terrain and illumination information\n",
    "```\n",
    "\n",
    "### Terrain bands (when available):\n",
    "- Band 1: Path length (m)\n",
    "- Band 2: To sensor azimuth\n",
    "- Band 3: To sensor zenith\n",
    "- Band 4: To sun azimuth\n",
    "- Band 5: To sun zenith\n",
    "- Band 6: Solar phase\n",
    "- Band 7: Slope\n",
    "- Band 8: Aspect\n",
    "- Band 9: cosine(i) (local solar illumination angle)\n",
    "- Band 10: UTC Time\n",
    "- Band 11: Earth-sun distance (AU)\n",
    "\n",
    "**Important note:** Aspect follows convention from $-\\pi$ to $\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef02d71",
   "metadata": {},
   "source": [
    "Note this tutorial is incomplete. Additional content to be added from here: https://snowex-2022.hackweek.io/tutorials/aviris-ng/AVIRIS-NG_Tutorial.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-observations-cookbook-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
