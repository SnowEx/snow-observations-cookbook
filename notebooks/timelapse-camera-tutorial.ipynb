{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "authentic-device",
   "metadata": {},
   "source": [
    "# Time-lapse Cameras\n",
    "\n",
    ":::{admonition} Learning Objectives\n",
    "\n",
    "**At the conclusion of this tutorial, you will...:**\n",
    "- Know about all the time-lapse images available from the SnowEx 2017 and 2020 field campaigns \n",
    "- View example time-lapse images from SnowEx 2020 and visualize their locations\n",
    "- Access snow depth measurements extracted from the SnowEx 2020 time-lapse images \n",
    "- Compare snow depths from different SnowEx 2020 time-lapse cameras \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-teens",
   "metadata": {},
   "source": [
    "## Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns\n",
    "Time-lapse cameras were installed in both the SnowEx 2017 and 2020 field campaigns on Grand Mesa in similar locations. \n",
    "\n",
    "**SnowEx 2017 Time-lapse Cameras** \n",
    "* 28 Total Time-lapse Cameras\n",
    "* Capturing the entire winter season (September 2016-June 2017)\n",
    "* Taking 4 photos/day at 8AM, 10AM, 12PM, 2PM, 4PM\n",
    "* An orange pole was installed in front of 15 cameras for snow depth measurements\n",
    "* Time-lapse images have been submitted to the NSIDC by Mark Raleigh with all the required metadata (e.g., locations, naming convention, etc.) for use. \n",
    "\n",
    "**SnowEx 2020 Time-lapse Cameras**\n",
    "* 29 Total Time-lapse Cameras\n",
    "* Capturing the entire winter season (September 2019-June 2020)\n",
    "* Taking 3 photos/day at 11AM, 12PM, 1PM or 2 photos/day at 11AM and 12PM\n",
    "* A red pole was installed in front of each camera for snow depth measurements.\n",
    "* Cameras were installed on the east and west side of the Grand Mesa, across a vegetation scale of 1-9, using the convention __XMR__:\n",
    "    * **X** = East (E) or West (W) areas of the Mesa\n",
    "    * **M** = number 1-9, representing 1 (least vegetation) to 9 (most vegetation). Within each vegetation class, there were three sub-classes of snow depths derived from 2017 SnowEx lidar measurements. \n",
    "    * **R** = Replicate of vegetation assignment, either A, B, C, D, or E. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-edwards",
   "metadata": {},
   "source": [
    "### An automated way of viewing and mapping time-lapse photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-bahamas",
   "metadata": {},
   "source": [
    "First, we will procedurally import the necessary packages to access the data. To access the snow depths at each camera station, we will use the SnowEx database (`snowexsql`) to access the depths as `PointMeasurements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3532c1-9e34-4650-9203-9ccd0a3e2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.api import PointMeasurements\n",
    "\n",
    "# Import information for all point measurement types\n",
    "measurements = PointMeasurements()\n",
    "\n",
    "# List unique instruments\n",
    "results = measurements.all_instruments\n",
    "print('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for data analysis \n",
    "import geopandas as gpd # geopandas library for data analysis and visualization\n",
    "import pandas as pd # pandas as to read csv data and visualize tabular data\n",
    "import numpy as np # numpy for data analysis \n",
    "\n",
    "# Packages for data visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt # matplotlib.pyplot for plotting images and graphs\n",
    "\n",
    "plt.rcParams['figure.figsize']  = (10, 4) # figure size\n",
    "plt.rcParams['axes.titlesize']  = 14 # title size \n",
    "plt.rcParams['axes.labelsize']  = 12 # axes label size \n",
    "plt.rcParams['xtick.labelsize'] = 11 # x tick label size \n",
    "plt.rcParams['ytick.labelsize'] = 11 # y tick label size \n",
    "plt.rcParams['legend.fontsize'] = 11 # legend size \n",
    "mpl.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f7c6f-0fe2-4bb3-b0c6-9283d039799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the database for camera-based snow depths\n",
    "camera_depths = measurements.from_filter(\n",
    "    type=\"depth\",\n",
    "    site_name=\"Grand Mesa\",\n",
    "    instrument=\"camera\",\n",
    "    limit = 13371\n",
    ")\n",
    "\n",
    "camera_depths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-airport",
   "metadata": {},
   "source": [
    "#### Plot the camera locations, using snow pit locations for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058b412-44b5-4606-bdeb-fe1d495048db",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_depths.explore(tooltip=['equipment','date','latitude','longitude','value','type','units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-revolution",
   "metadata": {},
   "source": [
    "## Viewing the time-lapse photos\n",
    "Thanks to the SnowEx database, we were able to easily access snow depths at each site. However, if we wish to examine the camera imagery, we will need to be a bit more creative.\n",
    "\n",
    "The images are available through NSIDC, so we will use `earthaccess` to grab one of the image archives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fda666",
   "metadata": {},
   "source": [
    ":::{note} Earthdata Login Authentication\n",
    "\n",
    "This tutorial requires NASA Earthdata Login credentials to access NSIDC data.\n",
    "\n",
    "[Register for free](https://urs.earthdata.nasa.gov/) if you don't have an account\n",
    "\n",
    "Once you have a username and password, you can either enter these in manually \n",
    "in the `strategy=\"interactive\"` mode (as coded below), or you can configure your\n",
    "local envrionment as follows:\n",
    "\n",
    "**Here's how to configure your local system for this to work:**\n",
    "- First time: Run `earthaccess.login()` without the strategy parameter to authenticate interactively\n",
    "- This creates a `.netrc` file for future sessions\n",
    "\n",
    "After making those changes, you should switch to `strategy=\"environment\"` below!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a81e7-9e75-433c-9c2b-fa2c37116f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "\n",
    "# Authenticate with Earthdata Login servers\n",
    "try:\n",
    "    auth = earthaccess.login(strategy=\"environment\")\n",
    "    print(\"✓ Successfully authenticated with Earthdata Login\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Authentication failed: {e}\")\n",
    "    print(\"This is expected in automated builds. Interactive users should run earthaccess.login() to authenticate.\")\n",
    "    auth = None\n",
    "    results = None\n",
    "\n",
    "# Search for camera imagery (only if authenticated)\n",
    "if auth:\n",
    "    results = earthaccess.search_data(\n",
    "        doi = \"10.5067/WYRNU50R9L5R\"\n",
    "    )\n",
    "    print(results[0].data_links())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc2ecd-cee4-40d3-8c97-55a0f6dd1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files into memory (only if authenticated)\n",
    "if results:\n",
    "    files = earthaccess.open(results)\n",
    "else:\n",
    "    print(\"⚠ Skipping remote data access - using local sample data instead\")\n",
    "    files = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e67ff2-b409-41c4-811f-12bdda6bb65f",
   "metadata": {},
   "source": [
    ":::{warning} Large Downloads Ahead!\n",
    "\n",
    "Looking at the above data links, one will notice that the images are saved in `.tar.gz` format. We can read files through `earthaccess` in this format, but it will require some more work than simply downloading the data.\n",
    "\n",
    "Users may download the files if they wish, but they are on the larger side (900+ Mb). If you wish to avoid large data downloads, then the below code will help with the process. However, be aware that the code can be rather memory intensive. If running this code on CryoCloud, then consider using larger memory allocations (4+ Gb).\n",
    "\n",
    ":::\n",
    "\n",
    "Here is how you would read in every file in the large `tar.gz` from earthaccess into memory:\n",
    "\n",
    "`file_content = files[0].read()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea402d",
   "metadata": {},
   "source": [
    ":::{tip} Simplifying the download for learning purposes\n",
    "\n",
    "For the sake of this tutorial we will create a synthetic tar.gz file with just three images we want to show here.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b338c89-deaf-4e8f-935e-3c1ccdbec5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = './data/sample-data.tar.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3e972-74c5-4cca-8f6d-d9cbf116299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jpg_files = []\n",
    "# Open the tarfile remotely\n",
    "with tarfile.open(file_content, mode=\"r:gz\") as tar:\n",
    "    # Identify contents of tarfile\n",
    "    members = tar.getmembers()\n",
    "\n",
    "    # Loop through tarfile contents for images of interest\n",
    "    fig, ax = plt.subplots(1,3, figsize=(12,12))\n",
    "    ax.flatten()\n",
    "    for member in members:\n",
    "        if member.name.lower().endswith('.jpg'):\n",
    "            jpg_file = tar.extractfile(member).read()\n",
    "            \n",
    "            # Estimate datetime from image\n",
    "            creationTime = member.mtime\n",
    "            dt_c = datetime.fromtimestamp(creationTime)\n",
    "            formatted_datetime = dt_c.strftime(\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "            desired_datetimes = ['09/27/2016 15:13',\n",
    "                                 '11/08/2016 14:00',\n",
    "                                 '12/10/2016 14:00']\n",
    "            \n",
    "            # Append files with desired datetime\n",
    "            for idx,dt in enumerate(desired_datetimes):\n",
    "                if formatted_datetime == dt:\n",
    "                    image = Image.open(BytesIO(jpg_file))\n",
    "                    ax[idx].imshow(image)\n",
    "                    ax[idx].set_title(desired_datetimes[idx])\n",
    "                    ax[idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-provider",
   "metadata": {},
   "source": [
    "## Time-lapse Camera Applications\n",
    "\n",
    "Installing snow poles in front of time-lapse camera provides low-cost, long-term snow depth timeseries. Snow depths from the 2020 SnowEx time-lapse imagery have been manually processed with estimation of submission to the NSIDC database in summer 2021. \n",
    "\n",
    "The snow depth is the difference between the number of pixels in a snow-free image and an image with snow, with a conversion from pixels to centimeters (**Figure 1**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-mayor",
   "metadata": {},
   "source": [
    "![equation](./images/time-lapse-camera/timelapse-camera-tutorial_27_0.png)\n",
    "\n",
    "**Figure 1: Equation to extract snow depth from camera images. For each image, take the difference in pixels between the length of a snow-free stake and the length of the stake and multiply by length(cm)/pixel. The ratio can be found by dividing the full length of the stake (304.8 cm) by the length of a snow-free stake in pixels.**\n",
    "\n",
    "Snow depth can be obtained in this manner manually, but it is now easier to determine the pixel size of the stakes through machine learning. For the sake of completeness, we will provide a brief example using the camera imagery above. Otherwise, users interested in using the camera imagery with machine learning are encouraged to check out the following resources by Katherine Breen and others:\n",
    "\n",
    "**Publication on method**  \n",
    "Breen C. M., W. R. Currier, C. Vuyovich, et al. 2024. \"Snow Depth Extraction From Time‐Lapse Imagery Using a Keypoint Deep Learning Model.\" Water Resources Research 60 (7): [10.1029/2023wr036682]\n",
    "\n",
    "**Github page for algorithm**  \n",
    "https://github.com/catherine-m-breen/snowpoles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36ce93-f6be-4a0e-a89a-b187f3a54e16",
   "metadata": {},
   "source": [
    "In the example images above, we use the red pole in the fully snow-off and snow-on images for estimation.\n",
    "\n",
    "For the snow-off image, the length of the red pole is **136 pixels**. If we assume that the pole is 304.8 cm in length, then each pixel is approximately **2.24 cm** in length.\n",
    "\n",
    "For the snow-on image, the length of the red pole is **72 pixels**, much shorter than the snow-off length. So, there is a **~64 pixel** difference between the snow-on and snow-off lengths. Using the equation in Figure 1, we can calculate snow depth:\n",
    "\n",
    "Depth = 2.24 * (136-72) = **143.36 cm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-reviewer",
   "metadata": {},
   "source": [
    "*Acknowledgements: Anthony Arendt, Scott Henderson, Micah Johnson, Carrie Vuyovich, Ryan Currier, Megan Mason, Mark Raleigh*\n",
    "\n",
    "**Additional References**\\\n",
    "Dickerson-Lange et al., 2017. *Snow disappearance timing is dominated by forest effects on snow accumulation in warm winter climates of the Pacific Northwest, United States.* Hydrological Processes. Vol 31, Issue 10. 13 February 2017. https://doi.org/10.1002/hyp.11144\n",
    "\n",
    "Raleigh et al., 2013. *Approximating snow surface temperature from standard temperature and humidity data: New possibilities for snow model and remote sensing evaluation*. Water Resources Research. Vol 49, Issue 12. 07 November 2013.  https://doi.org/10.1002/2013WR013958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e629a55-56be-4c80-91a8-40ccd16638e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-observations-cookbook-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
